{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bonvech/MSU-AI/blob/main/EX13_Generative_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQl5xdUAIuYO"
      },
      "source": [
        "# Вспомогательный код"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9QljqHNIuYQ"
      },
      "source": [
        "Установка необходимых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SxjhExrIuYR"
      },
      "outputs": [],
      "source": [
        "!pip install -q torchmetrics[image]\n",
        "!pip install -q lightning tbparse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL3tidyKIuYU"
      },
      "source": [
        "Зафиксируем начальные значения генераторов случайных чисел для воспроизводимости результатов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEkwsvrfIuYU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import lightning as L\n",
        "\n",
        "\n",
        "# basic random seed\n",
        "def seed_basic(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "\n",
        "# torch random seed\n",
        "def seed_torch(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "# basic + torch + lightning\n",
        "def seed_everything(seed=42):\n",
        "    seed_basic(seed)\n",
        "    seed_torch(seed)\n",
        "    L.seed_everything(seed)\n",
        "\n",
        "\n",
        "seed_everything()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xl_rYBStIuYV"
      },
      "outputs": [],
      "source": [
        "from warnings import simplefilter\n",
        "\n",
        "simplefilter(\"ignore\", RuntimeWarning)\n",
        "simplefilter(\"ignore\", UserWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kg02znkIuYW"
      },
      "source": [
        "# Задание 1. GAN для генерации точек"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В этом задании вам предлагается попрактиковаться в обучении генеративно-состязательных нейронных сетей на простом примере генерации точек на плоскости.\n",
        "\n",
        "В лекции был рассмотрен пример генерации точек, лежащих на параболе, при **нормальном** входном распределении $Z$. В задании требуется провести эксперимент с генерацией точек на параболе при **равномерном** входном распределении $Z$.\n",
        "\n",
        "Далее в качестве дополнительного задания предлагается реализовать генерацию точек на плоскости, образующих какую-либо другую фигуру (например, круг или спираль)."
      ],
      "metadata": {
        "id": "hELgBnD6DrTQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nfSg0cpIuYW"
      },
      "source": [
        "## Формат результата"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSWngVHmIuYW"
      },
      "source": [
        "1. Результаты экспериментов с изменением распределения входного латентного пространства и вывод по ним.\n",
        "2. *Дополнительно: модель, обученная для генерации выбранной вами фигуры, например, круга.\n",
        "\n",
        "Пример генерации:\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/Exercises/EX13/result_1_task_ex13.png\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR5HugbjIuYX"
      },
      "source": [
        "Импорт необходимых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7H5RRacLIuYX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch.nn as nn\n",
        "import lightning as L\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tbparse import SummaryReader\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Модели генератора и дискриминатора"
      ],
      "metadata": {
        "id": "co9J3aUhm54S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgJrKxJjIuYX"
      },
      "source": [
        "Определяем модели генератора и дискриминатора:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swIIg6peIuYY"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_space, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_space, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 2),\n",
        "        )  # x,y\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(2, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 1),  # real/fake\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0qYsm7gIuYY"
      },
      "source": [
        "## Датасет"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-RnTkhQIuYY"
      },
      "source": [
        "Создадим датасет, который при инициализации генерирует точки параболы:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRfbpVNbIuYY"
      },
      "outputs": [],
      "source": [
        "class ParabolaDataset(Dataset):\n",
        "    def __init__(self, n_samples=1000, noise=0.0):\n",
        "        self.n_samples = n_samples\n",
        "        self.noise = noise\n",
        "        self.x = torch.FloatTensor(np.random.uniform(-1, 1, size=(n_samples)))\n",
        "        self.y = torch.pow(self.x, 2) + torch.randn(n_samples) * noise\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.stack((self.x[idx], self.y[idx]), 0), 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGJ_Gt6uIuYZ"
      },
      "source": [
        "Сгенерируем точки, посмотрим на них:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kzWa3XMIuYZ"
      },
      "outputs": [],
      "source": [
        "parabola = ParabolaDataset(n_samples=100000, noise=0)\n",
        "plt.scatter(parabola.x, parabola.y, alpha=0.01)\n",
        "plt.title(\"Random dots on parabola,\\nwhich will use like a dataset.\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1n86bjsIuYZ"
      },
      "outputs": [],
      "source": [
        "parabola[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvmE2eX_IuYZ"
      },
      "source": [
        "## Код обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjlfz595IuYZ"
      },
      "source": [
        "Возьмем код визуализации из лекции:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPM4UouAIuYZ"
      },
      "outputs": [],
      "source": [
        "def test_image(pair_gen, pairs, figsize=(12, 3)):\n",
        "    # equalizing lengths for better visualization\n",
        "    if len(pair_gen) > len(pairs):\n",
        "        pair_gen = pair_gen[: len(pairs)]\n",
        "    else:\n",
        "        pairs = pairs[: len(pair_gen)]\n",
        "\n",
        "    df = pd.DataFrame(data=np.concatenate([pairs, pair_gen]), columns=[\"x\", \"y\"])\n",
        "    df[\"label\"] = [\"real\"] * len(pairs) + [\"generated\"] * len(pair_gen)\n",
        "\n",
        "    plot = sns.jointplot(data=df, x=\"x\", y=\"y\", hue=\"label\")\n",
        "    sns.move_legend(plot.ax_joint, \"lower left\")\n",
        "    if figsize:\n",
        "        plot.fig.set_size_inches(figsize)\n",
        "    plt.axis([-1.1, 1.1, -0.1, 1.1])\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def tbparse_visual(log_dir, figsize=(12, 3)):\n",
        "    # visualization without TensorBoard for TensorBoard logs\n",
        "    clear_output()\n",
        "    reader = SummaryReader(log_dir)\n",
        "    df = reader.scalars\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    for tag in df.tag.unique():\n",
        "        if \"loss\" in tag:\n",
        "            tag_data = df.query(\"`tag` == @tag\").sort_values(by=\"step\")\n",
        "            plt.plot(tag_data.step, tag_data.value, label=tag)\n",
        "    plt.xlabel(\"step\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.grid()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjoXCYK6IuYa"
      },
      "source": [
        "Код обучения модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfWMsrUPIuYa"
      },
      "outputs": [],
      "source": [
        "class GAN(L.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        generator,\n",
        "        discriminator,\n",
        "        lr=3e-4,\n",
        "        betas=(0.9, 0.999),\n",
        "        noise_function=torch.randn,\n",
        "        latent_dim=5,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.automatic_optimization = False  # for hand made settings\n",
        "\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.real_label = 1.0\n",
        "        self.fake_label = 0.0\n",
        "        self.lr = lr\n",
        "        self.betas = betas\n",
        "        self.noise_function = noise_function\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        opt_gen = torch.optim.Adam(\n",
        "            self.generator.parameters(),\n",
        "            lr=self.lr,\n",
        "            betas=self.betas,\n",
        "        )\n",
        "        opt_disc = torch.optim.Adam(\n",
        "            self.discriminator.parameters(),\n",
        "            lr=self.lr,\n",
        "            betas=self.betas,\n",
        "        )\n",
        "        return [opt_gen, opt_disc], []\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        self.real_items, _ = batch\n",
        "        noises = self.noise_function(\n",
        "            (self.real_items.shape[0], self.latent_dim),\n",
        "            dtype=torch.float32,\n",
        "        ).to(self.device)\n",
        "\n",
        "        opt_gen, opt_disc = self.optimizers()\n",
        "        # ---------------------\n",
        "        # Train discriminator\n",
        "        # ---------------------\n",
        "        self.discriminator.zero_grad()\n",
        "        # 1. discriminator on real items\n",
        "        real_label = torch.full(\n",
        "            size=(self.real_items.shape[0], 1),\n",
        "            fill_value=self.real_label,\n",
        "            dtype=torch.float,\n",
        "        ).to(self.device)\n",
        "        disc_label = self.discriminator(self.real_items)\n",
        "        loss_disc_real = self.criterion(disc_label, real_label)\n",
        "        loss_disc_real.backward()\n",
        "\n",
        "        # 2. discriminator on fake items\n",
        "        fake_label = torch.full(\n",
        "            size=(self.real_items.shape[0], 1),\n",
        "            fill_value=self.fake_label,\n",
        "            dtype=torch.float,\n",
        "        ).to(self.device)\n",
        "        self.fake_items = self.generator(noises)\n",
        "        disc_label = self.discriminator(self.fake_items)\n",
        "        loss_disc_fake = self.criterion(disc_label, fake_label)\n",
        "        loss_disc_fake.backward()\n",
        "\n",
        "        # 3. discriminator optimizer step (on real and fake items)\n",
        "        opt_disc.step()\n",
        "        loss_disc = 0.5 * loss_disc_real + 0.5 * loss_disc_fake\n",
        "        self.log(\"loss/disc\", loss_disc, on_epoch=False, on_step=True)\n",
        "\n",
        "        # ---------------------\n",
        "        # Train generator\n",
        "        # ---------------------\n",
        "        self.generator.zero_grad()\n",
        "        self.fake_items = self.generator(noises)\n",
        "        disc_label = self.discriminator(self.fake_items)\n",
        "        loss_gen = self.criterion(disc_label, real_label)\n",
        "        loss_gen.backward()\n",
        "\n",
        "        opt_gen.step()\n",
        "        self.log(\"loss/gen\", loss_gen, on_epoch=False, on_step=True)\n",
        "\n",
        "        if (batch_idx + 1) % 1000 == 0:\n",
        "            tbparse_visual(self.logger.log_dir)\n",
        "            test_image(\n",
        "                self.fake_items.detach().cpu().numpy(),\n",
        "                self.real_items.detach().cpu().numpy(),\n",
        "                figsize=(12, 3.5),\n",
        "            )\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        tbparse_visual(self.logger.log_dir)\n",
        "        test_image(\n",
        "            self.fake_items.detach().cpu().numpy(),\n",
        "            self.real_items.detach().cpu().numpy(),\n",
        "            figsize=(12, 3.5),\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wozCT3EMIuYb"
      },
      "source": [
        "## Изменение входного распределения"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "У Lightning-модуля GAN, данного выше, есть атрибут `noise_function`, который задает функцию, с помощью которой будут сэмплироваться случайные входные вектора. По умолчанию используется нормальное распределение `torch.randn`."
      ],
      "metadata": {
        "id": "1DGIFaqGKJKk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGe-Qe9YIuYb"
      },
      "outputs": [],
      "source": [
        "latent_dim = 5\n",
        "batch_size = 32\n",
        "hidden_dim = 50\n",
        "epochs = 4\n",
        "\n",
        "train_loader = DataLoader(parabola, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "generator = Generator(latent_dim, hidden_dim=hidden_dim)\n",
        "discriminator = Discriminator(hidden_dim=hidden_dim)\n",
        "\n",
        "pl_model = GAN(generator, discriminator, latent_dim=latent_dim, noise_function=torch.randn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfe6sJBtIuYb"
      },
      "source": [
        "Обучите GAN\n",
        "(менять ничего не надо):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrxQeEmrIuYc"
      },
      "outputs": [],
      "source": [
        "trainer = L.Trainer(\n",
        "    max_epochs=epochs,\n",
        "    logger=L.pytorch.loggers.TensorBoardLogger(save_dir=\"./z1/parabola/gaus/\"),\n",
        ")\n",
        "\n",
        "trainer.fit(model=pl_model, train_dataloaders=train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60ojkN39IuYc"
      },
      "source": [
        "Попробуйте поменять распределение входного латентного пространства на **равномерное** и обучить модель.\n",
        "\n",
        "**Совет:** Не забудьте заново инициализировать модели перед обучением.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmayJKxEIuYc"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeQIFVc0IuYc"
      },
      "source": [
        "Напишите вывод о зависимости генерации от входного распределения.\n",
        "\n",
        "**Вывод:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P25jw7xHIuYc"
      },
      "source": [
        "## *Дополнительно: Изменение генерируемых данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd8VG7LmIuYd"
      },
      "source": [
        "Сделайте генерацию фигуры более сложной формы (например, круга)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaPbS34xIuYd"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCEyEA3SIuYd"
      },
      "source": [
        "# Задание 2. This Galaxy doesn't exist (Conditional GAN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYWOQc7cIuYd"
      },
      "source": [
        "В этом задании мы используем Conditional GAN для того, чтобы создавать изображения галактик, которых никогда не существовало. Для этого воспользуемся датасетом [Galaxy10 🛠️[doc]](https://astronn.readthedocs.io/en/latest/galaxy10sdss.html). Galaxy10 — датасет, содержащий 21785 центрированных цветных (RGB) изображений галактик с размерами 207×207, разделенных на 10 классов.\n",
        "\n",
        "Выбор архитектуры генератора и дискриминатора — ресурсоемкая задача, поэтому этот код за вас написан. Ваша задача — дописать код обучения Conditional GAN и получить реалистичные изображения, а также оценить качество генерации по метрике Inception Score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT72kB1QIuYe"
      },
      "source": [
        "## Формат результата"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSJ65swMIuYe"
      },
      "source": [
        "- Сгенерированные галактики\n",
        "- Значения `InceptionScore`\n",
        "- Вывод\n",
        "\n",
        "Пример генерации:\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/Exercises/EX13/result_2_task_ex13.png\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zras95kxIuYe"
      },
      "source": [
        "Установка и импорт необходимых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUGx60QNIuYf"
      },
      "outputs": [],
      "source": [
        "!pip install -q astronn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iObErVWwIuYf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import lightning as L\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from tbparse import SummaryReader\n",
        "from torchvision.utils import make_grid\n",
        "from torch.nn.utils import spectral_norm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchmetrics.image.inception import InceptionScore\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from astroNN.datasets import load_galaxy10\n",
        "from astroNN.datasets.galaxy10 import Galaxy10Class\n",
        "from astroNN.datasets.galaxy10 import galaxy10cls_lookup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrphLbcdIuYg"
      },
      "source": [
        "## Датасет"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIQ8cYZkIuYg"
      },
      "outputs": [],
      "source": [
        "from astroNN.datasets import load_galaxy10\n",
        "from astroNN.datasets.galaxy10 import galaxy10cls_lookup\n",
        "\n",
        "\n",
        "images, labels = load_galaxy10()\n",
        "\n",
        "train_idx, test_idx = train_test_split(np.arange(labels.shape[0]), test_size=0.1)\n",
        "train_images, train_labels = (\n",
        "    images[train_idx],\n",
        "    labels[train_idx],\n",
        ")\n",
        "test_images, test_labels = images[test_idx], labels[test_idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGG28hOIIuYg"
      },
      "source": [
        "В датасете Galaxy10 есть 10 классов изображений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NihdY26XIuYg"
      },
      "outputs": [],
      "source": [
        "from astroNN.datasets.galaxy10 import Galaxy10Class\n",
        "\n",
        "print(Galaxy10Class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6sYNNgmIuYg"
      },
      "source": [
        " Выведем по одному изображению из каждого класса:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5w_H455OIuYh"
      },
      "outputs": [],
      "source": [
        "def show_samples(images, titles=[]):\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=len(images), figsize=(25, 15))\n",
        "    for i, img in enumerate(images):\n",
        "        ax[i].imshow(img)\n",
        "        if len(titles) > i:\n",
        "            ax[i].set_title(titles[i])\n",
        "        ax[i].axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "# Get fist image in class along with class index\n",
        "class_num, first_indx = np.unique(labels, return_index=True)\n",
        "samples = images[first_indx]\n",
        "class_names = list(Galaxy10Class.values())\n",
        "show_samples(samples, class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haow8G3hIuYh"
      },
      "source": [
        "Cоберем датасет из этих изображений:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tWXfUkaIuYh"
      },
      "outputs": [],
      "source": [
        "class GalaxyDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform):\n",
        "        super().__init__()\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, indx):\n",
        "        image = self.images[indx]\n",
        "        label = self.labels[indx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqLuNPj0IuYh"
      },
      "source": [
        "## Предобработка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_XwmjvYIuYi"
      },
      "source": [
        "RGB-каналы изображений принимают значения **от 0 до 1**. Мы можем обеспечить этот диапазон значений, разместив на выходе генератора **сигмоиду**.\n",
        "\n",
        "При этом на **дискриминатор**, который является классификатором, лучше подавать **нормализованные изображения**.\n",
        "\n",
        "Посчитаем статистику по RGB-каналам. Считать std как среднее от стандартных отклонений по batch-ам некорректно. Поэтому используем [источник ✏️[blog]](https://stackoverflow.com/questions/10365119/mean-value-and-standard-deviation-of-a-very-huge-data-set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1XCPX-SIuYi"
      },
      "outputs": [],
      "source": [
        "def get_mean_and_std(dataset):\n",
        "    loader = DataLoader(dataset, batch_size=512 * 4, shuffle=False)\n",
        "    sum_channel = 0\n",
        "    squared_sum_channel = 0\n",
        "    n = len(dataset) * dataset[0][0].shape[1] * dataset[0][0].shape[2]\n",
        "    for images, labels in tqdm(loader):\n",
        "        # sum of values\n",
        "        sum_channel += images.sum(dim=(0, 2, 3))\n",
        "        # sum of squared values\n",
        "        squared_sum_channel += images.pow(exponent=2).sum(dim=(0, 2, 3))\n",
        "    mean = sum_channel / n  # E[x]\n",
        "    std = (squared_sum_channel / n - mean**2).sqrt()  # E[x^2] - (E[X])^2\n",
        "    return mean.numpy(), std.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_BVpT9BIuYi"
      },
      "source": [
        "Мы будем генерировать изображения 64×64. Сделаем Resize и добавим случайные повороты на количество градусов, кратное 90."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFU_B37KIuYj"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize(64, antialias=True),\n",
        "    ]\n",
        ")\n",
        "\n",
        "dataset = GalaxyDataset(train_images, train_labels, transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r1FE644IuYj"
      },
      "source": [
        "Посчитаем статистику для нормализации для дискриминатора (поворот на нее не влияет) и создадим нормализатор."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYK-DwzIIuYj"
      },
      "outputs": [],
      "source": [
        "mean, std = get_mean_and_std(dataset)\n",
        "normalize = transforms.Normalize(mean, std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRfhO_j2IuYk"
      },
      "source": [
        "Обновим преобразования:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er-aj7-YIuYk"
      },
      "outputs": [],
      "source": [
        "mean, std = get_mean_and_std(dataset)\n",
        "normalize = transforms.Normalize(mean, std)\n",
        "\n",
        "dataset.transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize(64, antialias=True),\n",
        "        normalize,\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.RandomVerticalFlip(0.5),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Условный генератор"
      ],
      "metadata": {
        "id": "b796ujEVtKhd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPYXftWiIuYk"
      },
      "source": [
        "Чтобы из обычного GANа сделать cGAN, нам нужно как-то подмешать в латентный вектор метку класса. Для этого нужно преобразовать метки классов `labels` в вид, с которым умеет работать нейросеть, и, сформировав `embedding`, подмешать в `inputs`.\n",
        "\n",
        "Код для вас уже написан. Изучите его, обратив внимание на размерность входов и размерность и диапазон выходных значений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "274MllCXIuYk"
      },
      "outputs": [],
      "source": [
        "class CGenerator(nn.Module):\n",
        "    \"\"\"\n",
        "    Conditional Generator\n",
        "    Args:\n",
        "        latent_dim (int): latent space size\n",
        "        image_size (int): size of the image\n",
        "        channels (int): channels of the image\n",
        "        num_classes (int): number of classes for dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        latent_dim: int = 10,\n",
        "        image_size: int = 64,\n",
        "        channels: int = 3,\n",
        "        num_classes: int = 10,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.image_size = image_size\n",
        "        self.channels = channels\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        # noise transform\n",
        "        self.init_size = self.image_size // 4\n",
        "        self.noise_transform = nn.Linear(latent_dim, 128 * self.init_size**2)\n",
        "\n",
        "        # embedding for condition\n",
        "        self.label_embedding = nn.Embedding(num_classes, 128 * self.init_size**2)\n",
        "\n",
        "        # convolution part\n",
        "        self.main = nn.Sequential(\n",
        "            nn.InstanceNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(256, 128, 3, stride=1, padding=1),\n",
        "            nn.InstanceNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor, labels: list = None) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs (tensor): input tensor into the calculation.\n",
        "            labels (tensor):  input tensor label.\n",
        "        Returns:\n",
        "            A four-dimensional tensor (batch*C*H*W).\n",
        "        \"\"\"\n",
        "\n",
        "        inputs = self.noise_transform(inputs)  # [batch x 127*init_size*init_size]\n",
        "        labels = labels.type(torch.LongTensor).to(inputs.device)\n",
        "\n",
        "        embedding = self.label_embedding(labels.view((-1, 1))).view(\n",
        "            -1, 128 * self.init_size**2\n",
        "        )  # [batch x 128*init_size*init_size]\n",
        "\n",
        "        inputs = torch.cat((inputs, embedding), dim=1).view(\n",
        "            (-1, 256, self.init_size, self.init_size)\n",
        "            # [batch x (128+128) x init_size x init_size]\n",
        "        )\n",
        "        return self.main(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTqSgy6eIuYl"
      },
      "source": [
        "Быстрый тест:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKrv8olkIuYl"
      },
      "outputs": [],
      "source": [
        "net_g = CGenerator()\n",
        "noise = torch.randn(1, 10)\n",
        "label = torch.tensor([0])\n",
        "img = net_g(noise, label)\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Условный дискриминатор"
      ],
      "metadata": {
        "id": "6Q8GLXRetdnt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EeOlGIVIuYl"
      },
      "source": [
        "В классическом cGAN метку класса подмешивают и к дискриминатору.\n",
        "\n",
        "Код для вас уже написан, изучите его, обратив внимание на размерность входов и размерность и диапазон выходных значений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97nbsp7xIuYm"
      },
      "outputs": [],
      "source": [
        "class CDiscriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    Conditional Discriminator\n",
        "    Args:\n",
        "        image_size (int): size of the image\n",
        "        channels (int): channels of the image\n",
        "        num_classes (int): number of classes for dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, image_size: int = 64, channels: int = 3, num_classes: int = 10\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding_size = image_size // 16\n",
        "        self.label_embedding = nn.Embedding(num_classes, self.embedding_size**2)\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters):\n",
        "            block = nn.Sequential(\n",
        "                nn.Conv2d(in_filters, out_filters, 3, 2, 1),\n",
        "                nn.LeakyReLU(0.2, inplace=True),\n",
        "                nn.BatchNorm2d(out_filters, 0.8),\n",
        "            )\n",
        "            return block\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            discriminator_block(channels, 16),\n",
        "            discriminator_block(16, 32),\n",
        "            discriminator_block(32, 64),\n",
        "            discriminator_block(64, 127),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128 * self.embedding_size**2, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor, labels: list = None) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Defines the computation performed at every call\n",
        "        Args:\n",
        "            inputs (tensor): input tensor into the calculation\n",
        "            labels (tensor): input tensor label\n",
        "        Returns:\n",
        "            A 2-dimensional tensor [batch x 1]\n",
        "        \"\"\"\n",
        "        inputs = self.main(inputs)  # [batch x 127*embedding_size**2]\n",
        "        labels = labels.type(torch.LongTensor).to(inputs.device)\n",
        "        embedding = self.label_embedding(labels.view((-1, 1))).view(\n",
        "            (-1, self.embedding_size**2)\n",
        "        )  # [batch x 1*embedding_size**2]\n",
        "\n",
        "        inputs = torch.cat(\n",
        "            (inputs, embedding), dim=1\n",
        "        )  # [batch x 128*embedding_size**2]\n",
        "        return self.classifier(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77dtsY_7IuYm"
      },
      "source": [
        "Быстрый тест:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xjr-KlHlIuYm"
      },
      "outputs": [],
      "source": [
        "net_d = CDiscriminator()\n",
        "img = torch.randn(1, 3, 64, 64)\n",
        "label = torch.tensor([0])\n",
        "ans = net_d(img, label)\n",
        "print(ans.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQQYp27UIuYm"
      },
      "source": [
        "## Обучение\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avogpy3wIuYn"
      },
      "outputs": [],
      "source": [
        "def test_image(fake_items, real_items, figsize=(5, 5)):\n",
        "    grid_fake = (\n",
        "        make_grid(torch.tensor(fake_items[:10]), nrow=10, normalize=True)\n",
        "        .permute(1, 2, 0)\n",
        "        .numpy()\n",
        "    )\n",
        "\n",
        "    grid_real = (\n",
        "        make_grid(torch.tensor(real_items[:10]), nrow=10, normalize=True)\n",
        "        .permute(1, 2, 0)\n",
        "        .numpy()\n",
        "    )\n",
        "\n",
        "    fig, ax = plt.subplots(2, 1, figsize=figsize)\n",
        "    ax[0].imshow(grid_fake)\n",
        "    ax[0].set_axis_off()\n",
        "    ax[1].imshow(grid_real)\n",
        "    ax[1].set_axis_off()\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gav9bYI-IuYn"
      },
      "source": [
        "Вам необходимо реализовать код для обучения.\n",
        "\n",
        "**Совет:**\n",
        "- Обратите внимание, что генератор выдает значения от 0 до 1. В то время `Dataset` выдает нормализованные значения. Чтобы корректно обучить модель, используйте `self.normalize`.\n",
        "- Обратите внимание, что вам нужно использовать 2 вида меток:\n",
        " * метки real/fake для расчета Loss функции,\n",
        " * метки классов, которые подаются в генератор и дискриминатор (для real объектов — приходят из датасета, для fake — можно брать те же, что для real, или генерировать случайно).\n",
        "\n",
        " Не путайте их!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDkcYSVGIuYn"
      },
      "outputs": [],
      "source": [
        "class СGAN(GAN):\n",
        "    def __init__(\n",
        "        self,\n",
        "        generator,\n",
        "        discriminator,\n",
        "        lr=3e-4,\n",
        "        betas=(0.5, 0.999),\n",
        "        noise_function=torch.randn,\n",
        "        latent_dim=10,\n",
        "        normalize=normalize,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            generator, discriminator, lr, betas, noise_function, latent_dim\n",
        "        )\n",
        "\n",
        "        self.normalize = normalize\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # Your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ScIPwhRIuYn"
      },
      "outputs": [],
      "source": [
        "seed_everything()\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Тест"
      ],
      "metadata": {
        "id": "mfOBXpIIughk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z17rlt-MIuYo"
      },
      "source": [
        "Рассчитайте  `InceptionScore` для отложенной (тестовой) выборки и сгенерированных данных.\n",
        "\n",
        "**Совет:** обратите внимание, что генератор возвращает данные от 0 до 1 (не нужно денормализовать). При написании датасета, чтобы данные были в одном диапазоне и не нужно было проводить нормализацию-денормализацию, можно убрать нормализацию из преобразований."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uCp1ArlIuYo"
      },
      "outputs": [],
      "source": [
        "class RunMetric(L.LightningModule):\n",
        "    def __init__(self, generator, noise_function=torch.randn, latent_dim=10):\n",
        "        super().__init__()\n",
        "        # model\n",
        "        self.generator = generator\n",
        "        self.noise_function = noise_function\n",
        "        self.latent_dim = latent_dim\n",
        "        # metrics\n",
        "        self.is_real = InceptionScore()\n",
        "        self.is_fake = InceptionScore()\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        # Your code here\n",
        "\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        # Your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGMjQ58OIuYo"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkGoRbozIuYo"
      },
      "source": [
        "Является ли  `InceptionScore` “из коробки” хорошей метрикой для датасета Galaxy10? Что можно сделать для улучшения метрики?\n",
        "\n",
        "**Напишите вывод** с ответом на вопросы выше:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arjg3UZZIuYo"
      },
      "source": [
        "# Задание 3. Условная генерация с помощью диффузионной модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBqf9RRIuYp"
      },
      "source": [
        "В ходе лекции мы рассмотрели диффузионную модель генерации изображений галактик. В рамках данного задания вам предлагается попробовать сделать модель \"условной\", то есть научиться генерировать при помощи диффузионных моделей объекты определенного класса.\n",
        "\n",
        "Существуют различные подходы к добавлению \"условия\" в диффузионную модель. Реализуем наиболее простой подход, связанный с добавлением метки класса в модель предсказания шума."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYsk8TwVIuYp"
      },
      "source": [
        "## Формат результата\n",
        "\n",
        "Набор чисел от 0 до 9, сгенерированных моделью.\n",
        "\n",
        "Пример генерации:\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/Exercises/EX13/result_3_task_ex13.png\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfQKigctIuYq"
      },
      "source": [
        "Импорт необходимых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIF8j9ToIuYq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import lightning as L\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from torchvision import transforms\n",
        "from torch.nn import functional as F\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhSH41l3IuYq"
      },
      "source": [
        "## Датасет"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqCRQRgqIuYq"
      },
      "source": [
        "Как известно, диффузионные модели требуют большого количества вычислительных ресурсов для обучения. Попробуем упростить задачу, взяв в качестве датасета сравнительно простой MNIST:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIIgSBqFIuYq"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import MNIST\n",
        "\n",
        "root = \"./data\"\n",
        "\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "dataset = MNIST(root=root, train=True, transform=transform, download=True)\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZkZC2gtIuYr"
      },
      "source": [
        "## Структурные блоки\n",
        "\n",
        "Структурные блоки возьмем из лекции (для экономии времени на обучение мы уберем блоки `SelfAttention`):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcbeLohbIuYr"
      },
      "outputs": [],
      "source": [
        "class ResNetBlock(nn.Module):\n",
        "    def __init__(self, in_features, out_features, mid_features=None, residual=False):\n",
        "        super().__init__()\n",
        "        self.residual = residual\n",
        "        if not mid_features:\n",
        "            mid_features = out_features\n",
        "        self.conv_stack = nn.Sequential(\n",
        "            nn.Conv2d(in_features, mid_features, kernel_size=3, padding=1, bias=False),\n",
        "            nn.GroupNorm(1, mid_features),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(mid_features, out_features, kernel_size=3, padding=1, bias=False),\n",
        "            nn.GroupNorm(1, out_features),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.residual:\n",
        "            return F.gelu(x + self.conv_stack(x))\n",
        "        else:\n",
        "            return self.conv_stack(x)\n",
        "\n",
        "\n",
        "class ResizeBlock(nn.Module):\n",
        "    def __init__(self, in_features, out_features, emb_dim):\n",
        "        super().__init__()\n",
        "        # defines non-linear map from time embedding features to conv features\n",
        "        self.emb_projection = nn.Sequential(\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(emb_dim, out_features),\n",
        "        )\n",
        "\n",
        "    def add_emb(self, x, t_vector):\n",
        "        # [batch_size, time_embedding_dim] -> [batch_size, out_features]\n",
        "        emb = self.emb_projection(t_vector)\n",
        "        # [batch_size, out_features] - > [batch_size, out_features, H, W]\n",
        "        emb = emb[:, :, None, None].repeat(1, 1, x.shape[-2], x.shape[-1])\n",
        "        return x + emb\n",
        "\n",
        "    def forward(self, x):\n",
        "        pass\n",
        "\n",
        "\n",
        "class Down(ResizeBlock):\n",
        "    def __init__(self, in_features, out_features, emb_dim=256):\n",
        "        super().__init__(in_features, out_features, emb_dim)\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            ResNetBlock(in_features, in_features, residual=True),\n",
        "            ResNetBlock(in_features, out_features),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        x = self.maxpool_conv(x)\n",
        "        x = self.add_emb(x, t)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Up(ResizeBlock):\n",
        "    def __init__(self, in_features, out_features, emb_dim=256):\n",
        "        super().__init__(in_features, out_features, emb_dim)\n",
        "\n",
        "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
        "        self.conv = nn.Sequential(\n",
        "            ResNetBlock(in_features, in_features, residual=True),\n",
        "            ResNetBlock(in_features, out_features, in_features // 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, skip_x, t):\n",
        "        x = self.up(x)\n",
        "        x = torch.cat([skip_x, x], dim=1)\n",
        "        x = self.conv(x)\n",
        "        x = self.add_emb(x, t)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqYblCfBIuYt"
      },
      "source": [
        "## Conditional denoising U-Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6QcaImTIuYu"
      },
      "source": [
        "Процедура добавления меток классов для диффузионных моделей подробно рассмотрена в [данной публикации 🎓[arxiv]](https://arxiv.org/pdf/2207.12598.pdf). Она сводится к следующим пунктам. Мы постараемся максимально упростить архитектуру, чтобы обучить модель в рамках семинара. Основные отличия модели:\n",
        "\n",
        "- Модель определения шума принимает не только батч изображений и батч индексов времени диффузионного процесса, но и метки класса.\n",
        "\n",
        "  То есть исходное описание класса:\n",
        "  ```\n",
        "  class UNet(nn.Module):\n",
        "\n",
        "    ...\n",
        "    def forward(self, x, t):\n",
        "       ...\n",
        "\n",
        "  ```\n",
        "  \n",
        "  заменено на:\n",
        "```\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    ...\n",
        "    def forward(self, x, t, y=None):\n",
        "       ...\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JRXgjRMIuYu"
      },
      "source": [
        "- Во время обучения условной модели мы хотим подавать в неё батчи как с метками класса, так и без них. Чтобы добиться этого, рекомендуем использовать блок `nn.Embedding`, установив размерность выхода равной `time_embed_dim`. Выход `nn.Embedding` должен суммироваться с `pos_encoding`, когда `y` не `None`. Реализуйте это на месте `# Your code here`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfajfDzdIuYu"
      },
      "source": [
        "Для ускорения процесса обучения мы упростили модель \"расшумляющего U-Net\". Вы не ограничены в выборе только описанной в лекции модели и можете реализовать собственную архитектуру на базе U-Net или воспользоваться этой."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mT_in8mqIuYu"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    r\"\"\"\n",
        "    Denoising U-Net model implementation based on arXiv:2006.11239 [cs.LG]\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_channels=1, img_size=28, time_embed_dim=256):\n",
        "        super().__init__()\n",
        "        self.num_channels = num_channels\n",
        "        self.time_dim = time_embed_dim\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # class embedding\n",
        "        # Your code here\n",
        "\n",
        "        # Downsample and enlarge feature dim\n",
        "        self.inc = ResNetBlock(num_channels, 16)\n",
        "        self.down1 = Down(16, 32)\n",
        "        self.down2 = Down(32, 32)\n",
        "\n",
        "        # Keep spatial dim constant\n",
        "        self.conv_bottleneck = nn.Sequential(\n",
        "                ResNetBlock(32, 64),\n",
        "                ResNetBlock(64, 32)\n",
        "        )\n",
        "\n",
        "        # Upsample and reduce feature dim\n",
        "        # 256=128+128 from conv_bottleneck and sa2\n",
        "        self.up1 = Up(64, 16)\n",
        "        # 128=64+64 from sa4 and sa1\n",
        "        self.up2 = Up(32, 16)\n",
        "        self.outc = nn.Conv2d(16, num_channels, kernel_size=1)\n",
        "\n",
        "    def pos_encoding(self, t):\n",
        "        r\"\"\"\n",
        "        Returns embedding vector for given integer time index.\n",
        "\n",
        "        We adopt 1d Positional Encoding form arXiv:1706.03762 [cs.CL]\n",
        "        see 3.5 for more details.\n",
        "\n",
        "        PE(x,2i) = sin(x/10000^(2i/D))\n",
        "        PE(x,2i+1) = cos(x/10000^(2i/D))\n",
        "\n",
        "        Where:\n",
        "        x is a point in 1d space\n",
        "        i is an integer in [0, D/2), where D is the size of the feature dimension\n",
        "\n",
        "        Args:\n",
        "            t: Tensor, shape ``[batch_size, 1]``\n",
        "        Returns:\n",
        "            pe: Tensor, shape ``[batch_size, time_embedding_dim]``\n",
        "        \"\"\"\n",
        "\n",
        "        # placeholder for diffusion time encoding vector\n",
        "        pe = torch.zeros(t.shape[0], self.time_dim).to(t)\n",
        "\n",
        "        # factor 1/10000^(2i/D)\n",
        "        div_factors = torch.exp(\n",
        "        torch.arange(0, self.time_dim, 2)\n",
        "        * (-torch.log(torch.as_tensor(10000.0)) / self.time_dim)\n",
        "        ).to(t)\n",
        "\n",
        "        # repeat t index for each feature\n",
        "        x = t.repeat(1, self.time_dim // 2)\n",
        "\n",
        "        # sin(x/10000^(2i/D)) for even features\n",
        "        pe[:, 0::2] = torch.sin(x * div_factors)\n",
        "        # cos(x/10000^(2i/D)) for odd features\n",
        "        pe[:, 1::2] = torch.cos(x * div_factors)\n",
        "\n",
        "        return pe\n",
        "\n",
        "    def forward(self, x, t, y=None):\n",
        "        t = t.unsqueeze(-1).type(torch.float).to(x)\n",
        "        t = self.pos_encoding(t)\n",
        "\n",
        "        if y is not None:\n",
        "          # Your code here\n",
        "\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1, t)\n",
        "        x3 = self.down2(x2, t)\n",
        "\n",
        "        x3 = self.conv_bottleneck(x3)\n",
        "\n",
        "        x = self.up1(x3, x2, t)\n",
        "        x = self.up2(x, x1, t)\n",
        "        output = self.outc(x)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_Vumrm9IuYu"
      },
      "source": [
        "## Обучение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGetWp0GIuYu"
      },
      "source": [
        "Во время обучения нам необходимо увеличивать количество батчей данных, где мы учитываем метки класса. На первой эпохе обучения необходимо показывать модели метки класса с вероятностью $0$, а на последней эпохе обучения, наоборот, все метки классов должны быть переданы модели. Для этого нам нужно модифицировать класс диффузионной модели, добавив методу шага обучения возможность передавать или не передавать метки класса в модель."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предлагаем линейно увеличивать вероятность добавления метки класса от $0$ до $1$ от эпохи к эпохе. Для этого вам может пригодиться функция `np.random.choice`, информация о текущей эпохе `self.current_epoch` и информация о максимальном количестве эпох `self.trainer.max_epochs`. Реализуйте код в точке `# Your code here`."
      ],
      "metadata": {
        "id": "WOAVOGPfxE88"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpPWzzMzIuYv"
      },
      "outputs": [],
      "source": [
        "class DiffusionGenerativeModel(L.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        path,\n",
        "        num_noise_steps=1000,\n",
        "        beta_start=1e-4,\n",
        "        beta_end=0.02,\n",
        "        img_size=28,\n",
        "        lr=0.001,\n",
        "        save_images=False,\n",
        "        save_progress=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.path = Path(path)\n",
        "        self.num_noise_steps = num_noise_steps\n",
        "        self.beta_start = beta_start\n",
        "        self.beta_end = beta_end\n",
        "        self.img_size = img_size\n",
        "        self.lr = lr\n",
        "        self.save_images = save_images\n",
        "        self.save_progress = save_progress\n",
        "\n",
        "        # diffusion process linear noise schedule\n",
        "        self.beta = self._get_noise_schedule()\n",
        "        self.alpha = 1.0 - self.beta\n",
        "        # \\hat{\\alpha}_{i-1} = \\prod_{j=0}^{i-1} \\alpha_j\n",
        "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
        "\n",
        "        # init optimizer and loss for training\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr)\n",
        "        return optimizer\n",
        "\n",
        "    def _get_noise_schedule(self):\n",
        "        return torch.linspace(self.beta_start, self.beta_end, self.num_noise_steps)\n",
        "\n",
        "    def _noise_images_batch(self, x, t):\n",
        "        # \\mu_i = \\sqrt{\\hat{\\alpha}_i}\n",
        "        mu = torch.sqrt(self.alpha_hat[t])[:, None, None, None].to(self.device)\n",
        "        # \\sigma_i = \\sqrt{1 - \\hat{\\alpha}_i}\n",
        "        sigma = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None].to(self.device)\n",
        "\n",
        "        standard_normal_noise = torch.randn_like(x).to(self.device)\n",
        "        noised_image_batch = mu * x + sigma * standard_normal_noise\n",
        "        return noised_image_batch, standard_normal_noise\n",
        "\n",
        "    def _get_timestams_batch(self):\n",
        "        return torch.randint(low=1, high=self.num_noise_steps, size=(self.batch_size,))\n",
        "\n",
        "    def generate_images_batch(self, labels=None):\n",
        "        # start from pure noise batch\n",
        "        x = torch.randn((self.batch_size, 1, self.img_size, self.img_size)).to(\n",
        "            self.device\n",
        "        )\n",
        "        # and apply self.num_noise_steps denoising steps with model\n",
        "        for t_i in tqdm(reversed(range(0, self.num_noise_steps)), position=0):\n",
        "            # Build tensor with timestamp index. Same for each element in batch\n",
        "            t = torch.full((self.batch_size,), t_i).long().to(self.device)\n",
        "            if labels is None:\n",
        "                labels = (\n",
        "                    torch.randint(low=0, high=10, size=(self.batch_size,))\n",
        "                    .long()\n",
        "                    .to(self.device)\n",
        "                )\n",
        "            else:\n",
        "                labels = labels.long()\n",
        "            # predict noise on current timestamp\n",
        "            with torch.inference_mode():\n",
        "                pred_noise = self.model(x, t, labels).detach()\n",
        "\n",
        "            # restore noise parametrs on current timestamp\n",
        "            alpha = self.alpha[t.to(\"cpu\")][:, None, None, None].to(self.device)\n",
        "            alpha_hat = self.alpha_hat[t.to(\"cpu\")][:, None, None, None].to(self.device)\n",
        "            beta = self.beta[t.to(\"cpu\")][:, None, None, None].to(self.device)\n",
        "\n",
        "            # partialy denoise batch of images\n",
        "            x = x - (1.0 - alpha) / (1 - alpha_hat).sqrt() * pred_noise\n",
        "            x = (1 / alpha.sqrt()) * x\n",
        "\n",
        "            if self.save_progress and t_i % 20 == 0:\n",
        "                prog_x = x.clamp(0, 1)\n",
        "                prog_x = (prog_x * 255).type(torch.uint8)\n",
        "                self._save_img(imgs=prog_x, path=self.path / \"progress\" / f\"{t_i}.jpg\")\n",
        "            # add appropriate amount of noise for next step if any\n",
        "            if t_i > 0:\n",
        "                z = torch.randn_like(x).to(self.device)\n",
        "                x = x + beta.sqrt() * z\n",
        "\n",
        "        # clip x to valid 0..255 image range\n",
        "        x = x.clamp(0, 1)\n",
        "        x = (x * 255).type(torch.uint8)\n",
        "        if self.save_progress:\n",
        "            self._save_img(imgs=x, path=self.path / \"progress\" / f\"{t_i}.jpg\")\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # unpack data\n",
        "        images, labels = batch\n",
        "        self.batch_size = images.shape[0]\n",
        "        t = self._get_timestams_batch()\n",
        "\n",
        "        labels = labels.long()\n",
        "        # prep batch of noised images\n",
        "        noised_images, target_noise = self._noise_images_batch(images, t)\n",
        "\n",
        "        # estimate noise with U-Net\n",
        "        # Your code here\n",
        "\n",
        "        # optimize model to fit target noise\n",
        "        loss = self.criterion(predicted_noise, target_noise)\n",
        "        self.log(\"loss\", loss, prog_bar=True, on_epoch=True, on_step=False)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def _save_img(self, imgs, path):\n",
        "        image_grid = make_grid(imgs)\n",
        "        # convert to numpy\n",
        "        ndarr = image_grid.permute(1, 2, 0).to(\"cpu\").numpy()\n",
        "        # and save\n",
        "        im = Image.fromarray(ndarr)\n",
        "        im.save(path)\n",
        "        plt.imshow(ndarr)\n",
        "        plt.show()\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        if self.save_images:\n",
        "            generated_images = self.generate_images_batch()\n",
        "            self._save_img(\n",
        "                imgs=generated_images,\n",
        "                path=self.path / f\"model_{self.current_epoch}.jpg\",\n",
        "            )\n",
        "\n",
        "    def predict_step(self, batch, batch_idx, dataloader_idx=0, labels=None):\n",
        "        images, labels = batch\n",
        "        self.batch_size = images.shape[0]\n",
        "        return self.generate_images_batch(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8jkOlFLIuYv"
      },
      "source": [
        "И обучите модель:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDvMT2fNIuYv"
      },
      "outputs": [],
      "source": [
        "seed_everything()\n",
        "path = \"/content/diffusion/\"\n",
        "batch_size = 128\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=2\n",
        ")\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath=path,\n",
        "    save_last=True,\n",
        "    every_n_epochs=1,\n",
        "    save_top_k=1,\n",
        "    monitor=\"loss\",\n",
        "    filename=\"best\",\n",
        "    mode=\"min\",\n",
        ")\n",
        "\n",
        "model = UNet()\n",
        "ddpm = DiffusionGenerativeModel(\n",
        "    model,\n",
        "    path,\n",
        "    save_images=False,\n",
        "    save_progress=False,\n",
        ")\n",
        "\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=20,\n",
        "    callbacks=[checkpoint_callback],\n",
        "    log_every_n_steps=100,\n",
        "    logger=L.pytorch.loggers.TensorBoardLogger(save_dir=path),\n",
        ")\n",
        "\n",
        "trainer.fit(model=ddpm, train_dataloaders=train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb3nWPfxIuYv"
      },
      "source": [
        "Будем считать, что задание выполнено успешно, если мы научились задавать метки классов (даже если результат генерации не идеален из-за простой модели и короткого обучения). Посмотрим, как модель генерирует числа от $0$ до $9$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "504EBqq8IuYw"
      },
      "outputs": [],
      "source": [
        "labels = torch.arange(start=0, end=10, step=1)\n",
        "\n",
        "damp_set = torch.utils.data.TensorDataset(labels, labels)\n",
        "\n",
        "gen_loader = torch.utils.data.DataLoader(\n",
        "    damp_set, batch_size=10, shuffle=False, num_workers=2\n",
        ")  # just for image num\n",
        "\n",
        "generated_images = trainer.predict(ddpm, gen_loader)[0]\n",
        "\n",
        "image_grid = make_grid(generated_images, nrow=10)\n",
        "# convert to numpy\n",
        "ndarr = image_grid.permute(1, 2, 0).to(\"cpu\").numpy()\n",
        "# and show\n",
        "image = Image.fromarray(ndarr)\n",
        "\n",
        "fig = plt.figure(figsize=(14, 5))\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AMOvLs1IuYw"
      },
      "source": [
        "# Дополнительно\n",
        "\n",
        "Можете попробовать генерацию с помощью библиотеки [Diffusers 🛠️[doc]](https://huggingface.co/docs/diffusers/index) и порадовать преподавателя результатами генерации."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}