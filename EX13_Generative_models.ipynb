{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bonvech/MSU-AI/blob/main/EX13_Generative_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQl5xdUAIuYO"
      },
      "source": [
        "# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –∫–æ–¥"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9QljqHNIuYQ"
      },
      "source": [
        "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SxjhExrIuYR"
      },
      "outputs": [],
      "source": [
        "!pip install -q torchmetrics[image]\n",
        "!pip install -q lightning tbparse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL3tidyKIuYU"
      },
      "source": [
        "–ó–∞—Ñ–∏–∫—Å–∏—Ä—É–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEkwsvrfIuYU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import lightning as L\n",
        "\n",
        "\n",
        "# basic random seed\n",
        "def seed_basic(seed=42):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "\n",
        "# torch random seed\n",
        "def seed_torch(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "# basic + torch + lightning\n",
        "def seed_everything(seed=42):\n",
        "    seed_basic(seed)\n",
        "    seed_torch(seed)\n",
        "    L.seed_everything(seed)\n",
        "\n",
        "\n",
        "seed_everything()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xl_rYBStIuYV"
      },
      "outputs": [],
      "source": [
        "from warnings import simplefilter\n",
        "\n",
        "simplefilter(\"ignore\", RuntimeWarning)\n",
        "simplefilter(\"ignore\", UserWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kg02znkIuYW"
      },
      "source": [
        "# –ó–∞–¥–∞–Ω–∏–µ 1. GAN –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ—á–µ–∫"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–í —ç—Ç–æ–º –∑–∞–¥–∞–Ω–∏–∏ –≤–∞–º –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –ø–æ–ø—Ä–∞–∫—Ç–∏–∫–æ–≤–∞—Ç—å—Å—è –≤ –æ–±—É—á–µ–Ω–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω–æ-—Å–æ—Å—Ç—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –Ω–∞ –ø—Ä–æ—Å—Ç–æ–º –ø—Ä–∏–º–µ—Ä–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ—á–µ–∫ –Ω–∞ –ø–ª–æ—Å–∫–æ—Å—Ç–∏.\n",
        "\n",
        "–í –ª–µ–∫—Ü–∏–∏ –±—ã–ª —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω –ø—Ä–∏–º–µ—Ä –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ—á–µ–∫, –ª–µ–∂–∞—â–∏—Ö –Ω–∞ –ø–∞—Ä–∞–±–æ–ª–µ, –ø—Ä–∏ **–Ω–æ—Ä–º–∞–ª—å–Ω–æ–º** –≤—Ö–æ–¥–Ω–æ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ $Z$. –í –∑–∞–¥–∞–Ω–∏–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Å—Ç–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π —Ç–æ—á–µ–∫ –Ω–∞ –ø–∞—Ä–∞–±–æ–ª–µ –ø—Ä–∏ **—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–º** –≤—Ö–æ–¥–Ω–æ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ $Z$.\n",
        "\n",
        "–î–∞–ª–µ–µ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç–æ—á–µ–∫ –Ω–∞ –ø–ª–æ—Å–∫–æ—Å—Ç–∏, –æ–±—Ä–∞–∑—É—é—â–∏—Ö –∫–∞–∫—É—é-–ª–∏–±–æ –¥—Ä—É–≥—É—é —Ñ–∏–≥—É—Ä—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫—Ä—É–≥ –∏–ª–∏ —Å–ø–∏—Ä–∞–ª—å)."
      ],
      "metadata": {
        "id": "hELgBnD6DrTQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nfSg0cpIuYW"
      },
      "source": [
        "## –§–æ—Ä–º–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSWngVHmIuYW"
      },
      "source": [
        "1. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ —Å –∏–∑–º–µ–Ω–µ–Ω–∏–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –∏ –≤—ã–≤–æ–¥ –ø–æ –Ω–∏–º.\n",
        "2. *–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –º–æ–¥–µ–ª—å, –æ–±—É—á–µ–Ω–Ω–∞—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –≤–∞–º–∏ —Ñ–∏–≥—É—Ä—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä, –∫—Ä—É–≥–∞.\n",
        "\n",
        "–ü—Ä–∏–º–µ—Ä –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/Exercises/EX13/result_1_task_ex13.png\" width=\"1000\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR5HugbjIuYX"
      },
      "source": [
        "–ò–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7H5RRacLIuYX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch.nn as nn\n",
        "import lightning as L\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tbparse import SummaryReader\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  –ú–æ–¥–µ–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –∏ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞"
      ],
      "metadata": {
        "id": "co9J3aUhm54S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgJrKxJjIuYX"
      },
      "source": [
        "–û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–æ–¥–µ–ª–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –∏ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swIIg6peIuYY"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_space, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_space, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 2),\n",
        "        )  # x,y\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(2, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 1),  # real/fake\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0qYsm7gIuYY"
      },
      "source": [
        "## –î–∞—Ç–∞—Å–µ—Ç"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-RnTkhQIuYY"
      },
      "source": [
        "–°–æ–∑–¥–∞–¥–∏–º –¥–∞—Ç–∞—Å–µ—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–æ—á–∫–∏ –ø–∞—Ä–∞–±–æ–ª—ã:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRfbpVNbIuYY"
      },
      "outputs": [],
      "source": [
        "class ParabolaDataset(Dataset):\n",
        "    def __init__(self, n_samples=1000, noise=0.0):\n",
        "        self.n_samples = n_samples\n",
        "        self.noise = noise\n",
        "        self.x = torch.FloatTensor(np.random.uniform(-1, 1, size=(n_samples)))\n",
        "        self.y = torch.pow(self.x, 2) + torch.randn(n_samples) * noise\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.stack((self.x[idx], self.y[idx]), 0), 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGJ_Gt6uIuYZ"
      },
      "source": [
        "–°–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–æ—á–∫–∏, –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –Ω–∏—Ö:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kzWa3XMIuYZ"
      },
      "outputs": [],
      "source": [
        "parabola = ParabolaDataset(n_samples=100000, noise=0)\n",
        "plt.scatter(parabola.x, parabola.y, alpha=0.01)\n",
        "plt.title(\"Random dots on parabola,\\nwhich will use like a dataset.\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1n86bjsIuYZ"
      },
      "outputs": [],
      "source": [
        "parabola[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvmE2eX_IuYZ"
      },
      "source": [
        "## –ö–æ–¥ –æ–±—É—á–µ–Ω–∏—è"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjlfz595IuYZ"
      },
      "source": [
        "–í–æ–∑—å–º–µ–º –∫–æ–¥ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∏–∑ –ª–µ–∫—Ü–∏–∏:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPM4UouAIuYZ"
      },
      "outputs": [],
      "source": [
        "def test_image(pair_gen, pairs, figsize=(12, 3)):\n",
        "    # equalizing lengths for better visualization\n",
        "    if len(pair_gen) > len(pairs):\n",
        "        pair_gen = pair_gen[: len(pairs)]\n",
        "    else:\n",
        "        pairs = pairs[: len(pair_gen)]\n",
        "\n",
        "    df = pd.DataFrame(data=np.concatenate([pairs, pair_gen]), columns=[\"x\", \"y\"])\n",
        "    df[\"label\"] = [\"real\"] * len(pairs) + [\"generated\"] * len(pair_gen)\n",
        "\n",
        "    plot = sns.jointplot(data=df, x=\"x\", y=\"y\", hue=\"label\")\n",
        "    sns.move_legend(plot.ax_joint, \"lower left\")\n",
        "    if figsize:\n",
        "        plot.fig.set_size_inches(figsize)\n",
        "    plt.axis([-1.1, 1.1, -0.1, 1.1])\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def tbparse_visual(log_dir, figsize=(12, 3)):\n",
        "    # visualization without TensorBoard for TensorBoard logs\n",
        "    clear_output()\n",
        "    reader = SummaryReader(log_dir)\n",
        "    df = reader.scalars\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    for tag in df.tag.unique():\n",
        "        if \"loss\" in tag:\n",
        "            tag_data = df.query(\"`tag` == @tag\").sort_values(by=\"step\")\n",
        "            plt.plot(tag_data.step, tag_data.value, label=tag)\n",
        "    plt.xlabel(\"step\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.grid()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjoXCYK6IuYa"
      },
      "source": [
        "–ö–æ–¥ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfWMsrUPIuYa"
      },
      "outputs": [],
      "source": [
        "class GAN(L.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        generator,\n",
        "        discriminator,\n",
        "        lr=3e-4,\n",
        "        betas=(0.9, 0.999),\n",
        "        noise_function=torch.randn,\n",
        "        latent_dim=5,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.automatic_optimization = False  # for hand made settings\n",
        "\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.real_label = 1.0\n",
        "        self.fake_label = 0.0\n",
        "        self.lr = lr\n",
        "        self.betas = betas\n",
        "        self.noise_function = noise_function\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        opt_gen = torch.optim.Adam(\n",
        "            self.generator.parameters(),\n",
        "            lr=self.lr,\n",
        "            betas=self.betas,\n",
        "        )\n",
        "        opt_disc = torch.optim.Adam(\n",
        "            self.discriminator.parameters(),\n",
        "            lr=self.lr,\n",
        "            betas=self.betas,\n",
        "        )\n",
        "        return [opt_gen, opt_disc], []\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        self.real_items, _ = batch\n",
        "        noises = self.noise_function(\n",
        "            (self.real_items.shape[0], self.latent_dim),\n",
        "            dtype=torch.float32,\n",
        "        ).to(self.device)\n",
        "\n",
        "        opt_gen, opt_disc = self.optimizers()\n",
        "        # ---------------------\n",
        "        # Train discriminator\n",
        "        # ---------------------\n",
        "        self.discriminator.zero_grad()\n",
        "        # 1. discriminator on real items\n",
        "        real_label = torch.full(\n",
        "            size=(self.real_items.shape[0], 1),\n",
        "            fill_value=self.real_label,\n",
        "            dtype=torch.float,\n",
        "        ).to(self.device)\n",
        "        disc_label = self.discriminator(self.real_items)\n",
        "        loss_disc_real = self.criterion(disc_label, real_label)\n",
        "        loss_disc_real.backward()\n",
        "\n",
        "        # 2. discriminator on fake items\n",
        "        fake_label = torch.full(\n",
        "            size=(self.real_items.shape[0], 1),\n",
        "            fill_value=self.fake_label,\n",
        "            dtype=torch.float,\n",
        "        ).to(self.device)\n",
        "        self.fake_items = self.generator(noises)\n",
        "        disc_label = self.discriminator(self.fake_items)\n",
        "        loss_disc_fake = self.criterion(disc_label, fake_label)\n",
        "        loss_disc_fake.backward()\n",
        "\n",
        "        # 3. discriminator optimizer step (on real and fake items)\n",
        "        opt_disc.step()\n",
        "        loss_disc = 0.5 * loss_disc_real + 0.5 * loss_disc_fake\n",
        "        self.log(\"loss/disc\", loss_disc, on_epoch=False, on_step=True)\n",
        "\n",
        "        # ---------------------\n",
        "        # Train generator\n",
        "        # ---------------------\n",
        "        self.generator.zero_grad()\n",
        "        self.fake_items = self.generator(noises)\n",
        "        disc_label = self.discriminator(self.fake_items)\n",
        "        loss_gen = self.criterion(disc_label, real_label)\n",
        "        loss_gen.backward()\n",
        "\n",
        "        opt_gen.step()\n",
        "        self.log(\"loss/gen\", loss_gen, on_epoch=False, on_step=True)\n",
        "\n",
        "        if (batch_idx + 1) % 1000 == 0:\n",
        "            tbparse_visual(self.logger.log_dir)\n",
        "            test_image(\n",
        "                self.fake_items.detach().cpu().numpy(),\n",
        "                self.real_items.detach().cpu().numpy(),\n",
        "                figsize=(12, 3.5),\n",
        "            )\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        tbparse_visual(self.logger.log_dir)\n",
        "        test_image(\n",
        "            self.fake_items.detach().cpu().numpy(),\n",
        "            self.real_items.detach().cpu().numpy(),\n",
        "            figsize=(12, 3.5),\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wozCT3EMIuYb"
      },
      "source": [
        "## –ò–∑–º–µ–Ω–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–£ Lightning-–º–æ–¥—É–ª—è GAN, –¥–∞–Ω–Ω–æ–≥–æ –≤—ã—à–µ, –µ—Å—Ç—å –∞—Ç—Ä–∏–±—É—Ç `noise_function`, –∫–æ—Ç–æ—Ä—ã–π –∑–∞–¥–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é, —Å –ø–æ–º–æ—â—å—é –∫–æ—Ç–æ—Ä–æ–π –±—É–¥—É—Ç —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞—Ç—å—Å—è —Å–ª—É—á–∞–π–Ω—ã–µ –≤—Ö–æ–¥–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä–∞. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ `torch.randn`."
      ],
      "metadata": {
        "id": "1DGIFaqGKJKk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGe-Qe9YIuYb"
      },
      "outputs": [],
      "source": [
        "latent_dim = 5\n",
        "batch_size = 32\n",
        "hidden_dim = 50\n",
        "epochs = 4\n",
        "\n",
        "train_loader = DataLoader(parabola, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "generator = Generator(latent_dim, hidden_dim=hidden_dim)\n",
        "discriminator = Discriminator(hidden_dim=hidden_dim)\n",
        "\n",
        "pl_model = GAN(generator, discriminator, latent_dim=latent_dim, noise_function=torch.randn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfe6sJBtIuYb"
      },
      "source": [
        "–û–±—É—á–∏—Ç–µ GAN\n",
        "(–º–µ–Ω—è—Ç—å –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–¥–æ):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrxQeEmrIuYc"
      },
      "outputs": [],
      "source": [
        "trainer = L.Trainer(\n",
        "    max_epochs=epochs,\n",
        "    logger=L.pytorch.loggers.TensorBoardLogger(save_dir=\"./z1/parabola/gaus/\"),\n",
        ")\n",
        "\n",
        "trainer.fit(model=pl_model, train_dataloaders=train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60ojkN39IuYc"
      },
      "source": [
        "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–º–µ–Ω—è—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω–æ–≥–æ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –Ω–∞ **—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ** –∏ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å.\n",
        "\n",
        "**–°–æ–≤–µ—Ç:** –ù–µ –∑–∞–±—É–¥—å—Ç–µ –∑–∞–Ω–æ–≤–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmayJKxEIuYc"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeQIFVc0IuYc"
      },
      "source": [
        "–ù–∞–ø–∏—à–∏—Ç–µ –≤—ã–≤–æ–¥ –æ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç –≤—Ö–æ–¥–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è.\n",
        "\n",
        "**–í—ã–≤–æ–¥:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P25jw7xHIuYc"
      },
      "source": [
        "## *–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: –ò–∑–º–µ–Ω–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd8VG7LmIuYd"
      },
      "source": [
        "–°–¥–µ–ª–∞–π—Ç–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ñ–∏–≥—É—Ä—ã –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–æ–π —Ñ–æ—Ä–º—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∫—Ä—É–≥–∞)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaPbS34xIuYd"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCEyEA3SIuYd"
      },
      "source": [
        "# –ó–∞–¥–∞–Ω–∏–µ 2. This Galaxy doesn't exist (Conditional GAN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYWOQc7cIuYd"
      },
      "source": [
        "–í —ç—Ç–æ–º –∑–∞–¥–∞–Ω–∏–∏ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º Conditional GAN –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã —Å–æ–∑–¥–∞–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≥–∞–ª–∞–∫—Ç–∏–∫, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª–æ. –î–ª—è —ç—Ç–æ–≥–æ –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –¥–∞—Ç–∞—Å–µ—Ç–æ–º [Galaxy10 üõ†Ô∏è[doc]](https://astronn.readthedocs.io/en/latest/galaxy10sdss.html). Galaxy10 ‚Äî –¥–∞—Ç–∞—Å–µ—Ç, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π 21785 —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ü–≤–µ—Ç–Ω—ã—Ö (RGB) –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≥–∞–ª–∞–∫—Ç–∏–∫ —Å —Ä–∞–∑–º–µ—Ä–∞–º–∏ 207√ó207, —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã—Ö –Ω–∞ 10 –∫–ª–∞—Å—Å–æ–≤.\n",
        "\n",
        "–í—ã–±–æ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –∏ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ ‚Äî —Ä–µ—Å—É—Ä—Å–æ–µ–º–∫–∞—è –∑–∞–¥–∞—á–∞, –ø–æ—ç—Ç–æ–º—É —ç—Ç–æ—Ç –∫–æ–¥ –∑–∞ –≤–∞—Å –Ω–∞–ø–∏—Å–∞–Ω. –í–∞—à–∞ –∑–∞–¥–∞—á–∞ ‚Äî –¥–æ–ø–∏—Å–∞—Ç—å –∫–æ–¥ –æ–±—É—á–µ–Ω–∏—è Conditional GAN –∏ –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∞ —Ç–∞–∫–∂–µ –æ—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ –º–µ—Ç—Ä–∏–∫–µ Inception Score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT72kB1QIuYe"
      },
      "source": [
        "## –§–æ—Ä–º–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSJ65swMIuYe"
      },
      "source": [
        "- –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≥–∞–ª–∞–∫—Ç–∏–∫–∏\n",
        "- –ó–Ω–∞—á–µ–Ω–∏—è `InceptionScore`\n",
        "- –í—ã–≤–æ–¥\n",
        "\n",
        "–ü—Ä–∏–º–µ—Ä –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/Exercises/EX13/result_2_task_ex13.png\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zras95kxIuYe"
      },
      "source": [
        "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∏–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUGx60QNIuYf"
      },
      "outputs": [],
      "source": [
        "!pip install -q astronn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iObErVWwIuYf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import lightning as L\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from tbparse import SummaryReader\n",
        "from torchvision.utils import make_grid\n",
        "from torch.nn.utils import spectral_norm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchmetrics.image.inception import InceptionScore\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from astroNN.datasets import load_galaxy10\n",
        "from astroNN.datasets.galaxy10 import Galaxy10Class\n",
        "from astroNN.datasets.galaxy10 import galaxy10cls_lookup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrphLbcdIuYg"
      },
      "source": [
        "## –î–∞—Ç–∞—Å–µ—Ç"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIQ8cYZkIuYg"
      },
      "outputs": [],
      "source": [
        "from astroNN.datasets import load_galaxy10\n",
        "from astroNN.datasets.galaxy10 import galaxy10cls_lookup\n",
        "\n",
        "\n",
        "images, labels = load_galaxy10()\n",
        "\n",
        "train_idx, test_idx = train_test_split(np.arange(labels.shape[0]), test_size=0.1)\n",
        "train_images, train_labels = (\n",
        "    images[train_idx],\n",
        "    labels[train_idx],\n",
        ")\n",
        "test_images, test_labels = images[test_idx], labels[test_idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGG28hOIIuYg"
      },
      "source": [
        "–í –¥–∞—Ç–∞—Å–µ—Ç–µ Galaxy10 –µ—Å—Ç—å 10 –∫–ª–∞—Å—Å–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NihdY26XIuYg"
      },
      "outputs": [],
      "source": [
        "from astroNN.datasets.galaxy10 import Galaxy10Class\n",
        "\n",
        "print(Galaxy10Class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6sYNNgmIuYg"
      },
      "source": [
        " –í—ã–≤–µ–¥–µ–º –ø–æ –æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –∏–∑ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5w_H455OIuYh"
      },
      "outputs": [],
      "source": [
        "def show_samples(images, titles=[]):\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=len(images), figsize=(25, 15))\n",
        "    for i, img in enumerate(images):\n",
        "        ax[i].imshow(img)\n",
        "        if len(titles) > i:\n",
        "            ax[i].set_title(titles[i])\n",
        "        ax[i].axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "\n",
        "# Get fist image in class along with class index\n",
        "class_num, first_indx = np.unique(labels, return_index=True)\n",
        "samples = images[first_indx]\n",
        "class_names = list(Galaxy10Class.values())\n",
        "show_samples(samples, class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haow8G3hIuYh"
      },
      "source": [
        "C–æ–±–µ—Ä–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ —ç—Ç–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tWXfUkaIuYh"
      },
      "outputs": [],
      "source": [
        "class GalaxyDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform):\n",
        "        super().__init__()\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, indx):\n",
        "        image = self.images[indx]\n",
        "        label = self.labels[indx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqLuNPj0IuYh"
      },
      "source": [
        "## –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_XwmjvYIuYi"
      },
      "source": [
        "RGB-–∫–∞–Ω–∞–ª—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø—Ä–∏–Ω–∏–º–∞—é—Ç –∑–Ω–∞—á–µ–Ω–∏—è **–æ—Ç 0 –¥–æ 1**. –ú—ã –º–æ–∂–µ–º –æ–±–µ—Å–ø–µ—á–∏—Ç—å —ç—Ç–æ—Ç –¥–∏–∞–ø–∞–∑–æ–Ω –∑–Ω–∞—á–µ–Ω–∏–π, —Ä–∞–∑–º–µ—Å—Ç–∏–≤ –Ω–∞ –≤—ã—Ö–æ–¥–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ **—Å–∏–≥–º–æ–∏–¥—É**.\n",
        "\n",
        "–ü—Ä–∏ —ç—Ç–æ–º –Ω–∞ **–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä**, –∫–æ—Ç–æ—Ä—ã–π —è–≤–ª—è–µ—Ç—Å—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–º, –ª—É—á—à–µ –ø–æ–¥–∞–≤–∞—Ç—å **–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è**.\n",
        "\n",
        "–ü–æ—Å—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ RGB-–∫–∞–Ω–∞–ª–∞–º. –°—á–∏—Ç–∞—Ç—å std –∫–∞–∫ —Å—Ä–µ–¥–Ω–µ–µ –æ—Ç —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π –ø–æ batch-–∞–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ. –ü–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ–º [–∏—Å—Ç–æ—á–Ω–∏–∫ ‚úèÔ∏è[blog]](https://stackoverflow.com/questions/10365119/mean-value-and-standard-deviation-of-a-very-huge-data-set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1XCPX-SIuYi"
      },
      "outputs": [],
      "source": [
        "def get_mean_and_std(dataset):\n",
        "    loader = DataLoader(dataset, batch_size=512 * 4, shuffle=False)\n",
        "    sum_channel = 0\n",
        "    squared_sum_channel = 0\n",
        "    n = len(dataset) * dataset[0][0].shape[1] * dataset[0][0].shape[2]\n",
        "    for images, labels in tqdm(loader):\n",
        "        # sum of values\n",
        "        sum_channel += images.sum(dim=(0, 2, 3))\n",
        "        # sum of squared values\n",
        "        squared_sum_channel += images.pow(exponent=2).sum(dim=(0, 2, 3))\n",
        "    mean = sum_channel / n  # E[x]\n",
        "    std = (squared_sum_channel / n - mean**2).sqrt()  # E[x^2] - (E[X])^2\n",
        "    return mean.numpy(), std.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_BVpT9BIuYi"
      },
      "source": [
        "–ú—ã –±—É–¥–µ–º –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è 64√ó64. –°–¥–µ–ª–∞–µ–º Resize –∏ –¥–æ–±–∞–≤–∏–º —Å–ª—É—á–∞–π–Ω—ã–µ –ø–æ–≤–æ—Ä–æ—Ç—ã –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥—Ä–∞–¥—É—Å–æ–≤, –∫—Ä–∞—Ç–Ω–æ–µ 90."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFU_B37KIuYj"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize(64, antialias=True),\n",
        "    ]\n",
        ")\n",
        "\n",
        "dataset = GalaxyDataset(train_images, train_labels, transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r1FE644IuYj"
      },
      "source": [
        "–ü–æ—Å—á–∏—Ç–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä–∞ (–ø–æ–≤–æ—Ä–æ—Ç –Ω–∞ –Ω–µ–µ –Ω–µ –≤–ª–∏—è–µ—Ç) –∏ —Å–æ–∑–¥–∞–¥–∏–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYK-DwzIIuYj"
      },
      "outputs": [],
      "source": [
        "mean, std = get_mean_and_std(dataset)\n",
        "normalize = transforms.Normalize(mean, std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRfhO_j2IuYk"
      },
      "source": [
        "–û–±–Ω–æ–≤–∏–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "er-aj7-YIuYk"
      },
      "outputs": [],
      "source": [
        "mean, std = get_mean_and_std(dataset)\n",
        "normalize = transforms.Normalize(mean, std)\n",
        "\n",
        "dataset.transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize(64, antialias=True),\n",
        "        normalize,\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.RandomVerticalFlip(0.5),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –£—Å–ª–æ–≤–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä"
      ],
      "metadata": {
        "id": "b796ujEVtKhd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPYXftWiIuYk"
      },
      "source": [
        "–ß—Ç–æ–±—ã –∏–∑ –æ–±—ã—á–Ω–æ–≥–æ GAN–∞ —Å–¥–µ–ª–∞—Ç—å cGAN, –Ω–∞–º –Ω—É–∂–Ω–æ –∫–∞–∫-—Ç–æ –ø–æ–¥–º–µ—à–∞—Ç—å –≤ –ª–∞—Ç–µ–Ω—Ç–Ω—ã–π –≤–µ–∫—Ç–æ—Ä –º–µ—Ç–∫—É –∫–ª–∞—Å—Å–∞. –î–ª—è —ç—Ç–æ–≥–æ –Ω—É–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤ `labels` –≤ –≤–∏–¥, —Å –∫–æ—Ç–æ—Ä—ã–º —É–º–µ–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ–π—Ä–æ—Å–µ—Ç—å, –∏, —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–≤ `embedding`, –ø–æ–¥–º–µ—à–∞—Ç—å –≤ `inputs`.\n",
        "\n",
        "–ö–æ–¥ –¥–ª—è –≤–∞—Å —É–∂–µ –Ω–∞–ø–∏—Å–∞–Ω. –ò–∑—É—á–∏—Ç–µ –µ–≥–æ, –æ–±—Ä–∞—Ç–∏–≤ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–æ–≤ –∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏ –¥–∏–∞–ø–∞–∑–æ–Ω –≤—ã—Ö–æ–¥–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "274MllCXIuYk"
      },
      "outputs": [],
      "source": [
        "class CGenerator(nn.Module):\n",
        "    \"\"\"\n",
        "    Conditional Generator\n",
        "    Args:\n",
        "        latent_dim (int): latent space size\n",
        "        image_size (int): size of the image\n",
        "        channels (int): channels of the image\n",
        "        num_classes (int): number of classes for dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        latent_dim: int = 10,\n",
        "        image_size: int = 64,\n",
        "        channels: int = 3,\n",
        "        num_classes: int = 10,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.image_size = image_size\n",
        "        self.channels = channels\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        # noise transform\n",
        "        self.init_size = self.image_size // 4\n",
        "        self.noise_transform = nn.Linear(latent_dim, 128 * self.init_size**2)\n",
        "\n",
        "        # embedding for condition\n",
        "        self.label_embedding = nn.Embedding(num_classes, 128 * self.init_size**2)\n",
        "\n",
        "        # convolution part\n",
        "        self.main = nn.Sequential(\n",
        "            nn.InstanceNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(256, 128, 3, stride=1, padding=1),\n",
        "            nn.InstanceNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor, labels: list = None) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs (tensor): input tensor into the calculation.\n",
        "            labels (tensor):  input tensor label.\n",
        "        Returns:\n",
        "            A four-dimensional tensor (batch*C*H*W).\n",
        "        \"\"\"\n",
        "\n",
        "        inputs = self.noise_transform(inputs)  # [batch x 127*init_size*init_size]\n",
        "        labels = labels.type(torch.LongTensor).to(inputs.device)\n",
        "\n",
        "        embedding = self.label_embedding(labels.view((-1, 1))).view(\n",
        "            -1, 128 * self.init_size**2\n",
        "        )  # [batch x 128*init_size*init_size]\n",
        "\n",
        "        inputs = torch.cat((inputs, embedding), dim=1).view(\n",
        "            (-1, 256, self.init_size, self.init_size)\n",
        "            # [batch x (128+128) x init_size x init_size]\n",
        "        )\n",
        "        return self.main(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTqSgy6eIuYl"
      },
      "source": [
        "–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKrv8olkIuYl"
      },
      "outputs": [],
      "source": [
        "net_g = CGenerator()\n",
        "noise = torch.randn(1, 10)\n",
        "label = torch.tensor([0])\n",
        "img = net_g(noise, label)\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –£—Å–ª–æ–≤–Ω—ã–π –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä"
      ],
      "metadata": {
        "id": "6Q8GLXRetdnt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EeOlGIVIuYl"
      },
      "source": [
        "–í –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–º cGAN –º–µ—Ç–∫—É –∫–ª–∞—Å—Å–∞ –ø–æ–¥–º–µ—à–∏–≤–∞—é—Ç –∏ –∫ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä—É.\n",
        "\n",
        "–ö–æ–¥ –¥–ª—è –≤–∞—Å —É–∂–µ –Ω–∞–ø–∏—Å–∞–Ω, –∏–∑—É—á–∏—Ç–µ –µ–≥–æ, –æ–±—Ä–∞—Ç–∏–≤ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–æ–≤ –∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏ –¥–∏–∞–ø–∞–∑–æ–Ω –≤—ã—Ö–æ–¥–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97nbsp7xIuYm"
      },
      "outputs": [],
      "source": [
        "class CDiscriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    Conditional Discriminator\n",
        "    Args:\n",
        "        image_size (int): size of the image\n",
        "        channels (int): channels of the image\n",
        "        num_classes (int): number of classes for dataset\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, image_size: int = 64, channels: int = 3, num_classes: int = 10\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding_size = image_size // 16\n",
        "        self.label_embedding = nn.Embedding(num_classes, self.embedding_size**2)\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters):\n",
        "            block = nn.Sequential(\n",
        "                nn.Conv2d(in_filters, out_filters, 3, 2, 1),\n",
        "                nn.LeakyReLU(0.2, inplace=True),\n",
        "                nn.BatchNorm2d(out_filters, 0.8),\n",
        "            )\n",
        "            return block\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            discriminator_block(channels, 16),\n",
        "            discriminator_block(16, 32),\n",
        "            discriminator_block(32, 64),\n",
        "            discriminator_block(64, 127),\n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128 * self.embedding_size**2, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs: torch.Tensor, labels: list = None) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Defines the computation performed at every call\n",
        "        Args:\n",
        "            inputs (tensor): input tensor into the calculation\n",
        "            labels (tensor): input tensor label\n",
        "        Returns:\n",
        "            A 2-dimensional tensor [batch x 1]\n",
        "        \"\"\"\n",
        "        inputs = self.main(inputs)  # [batch x 127*embedding_size**2]\n",
        "        labels = labels.type(torch.LongTensor).to(inputs.device)\n",
        "        embedding = self.label_embedding(labels.view((-1, 1))).view(\n",
        "            (-1, self.embedding_size**2)\n",
        "        )  # [batch x 1*embedding_size**2]\n",
        "\n",
        "        inputs = torch.cat(\n",
        "            (inputs, embedding), dim=1\n",
        "        )  # [batch x 128*embedding_size**2]\n",
        "        return self.classifier(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77dtsY_7IuYm"
      },
      "source": [
        "–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xjr-KlHlIuYm"
      },
      "outputs": [],
      "source": [
        "net_d = CDiscriminator()\n",
        "img = torch.randn(1, 3, 64, 64)\n",
        "label = torch.tensor([0])\n",
        "ans = net_d(img, label)\n",
        "print(ans.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQQYp27UIuYm"
      },
      "source": [
        "## –û–±—É—á–µ–Ω–∏–µ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avogpy3wIuYn"
      },
      "outputs": [],
      "source": [
        "def test_image(fake_items, real_items, figsize=(5, 5)):\n",
        "    grid_fake = (\n",
        "        make_grid(torch.tensor(fake_items[:10]), nrow=10, normalize=True)\n",
        "        .permute(1, 2, 0)\n",
        "        .numpy()\n",
        "    )\n",
        "\n",
        "    grid_real = (\n",
        "        make_grid(torch.tensor(real_items[:10]), nrow=10, normalize=True)\n",
        "        .permute(1, 2, 0)\n",
        "        .numpy()\n",
        "    )\n",
        "\n",
        "    fig, ax = plt.subplots(2, 1, figsize=figsize)\n",
        "    ax[0].imshow(grid_fake)\n",
        "    ax[0].set_axis_off()\n",
        "    ax[1].imshow(grid_real)\n",
        "    ax[1].set_axis_off()\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gav9bYI-IuYn"
      },
      "source": [
        "–í–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∫–æ–¥ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.\n",
        "\n",
        "**–°–æ–≤–µ—Ç:**\n",
        "- –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤—ã–¥–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è –æ—Ç 0 –¥–æ 1. –í —Ç–æ –≤—Ä–µ–º—è `Dataset` –≤—ã–¥–∞–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è. –ß—Ç–æ–±—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `self.normalize`.\n",
        "- –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –≤–∞–º –Ω—É–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å 2 –≤–∏–¥–∞ –º–µ—Ç–æ–∫:\n",
        " * –º–µ—Ç–∫–∏ real/fake –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ Loss —Ñ—É–Ω–∫—Ü–∏–∏,\n",
        " * –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–¥–∞—é—Ç—Å—è –≤ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –∏ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ç–æ—Ä (–¥–ª—è real –æ–±—ä–µ–∫—Ç–æ–≤ ‚Äî –ø—Ä–∏—Ö–æ–¥—è—Ç –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞, –¥–ª—è fake ‚Äî –º–æ–∂–Ω–æ –±—Ä–∞—Ç—å —Ç–µ –∂–µ, —á—Ç–æ –¥–ª—è real, –∏–ª–∏ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–ª—É—á–∞–π–Ω–æ).\n",
        "\n",
        " –ù–µ –ø—É—Ç–∞–π—Ç–µ –∏—Ö!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDkcYSVGIuYn"
      },
      "outputs": [],
      "source": [
        "class –°GAN(GAN):\n",
        "    def __init__(\n",
        "        self,\n",
        "        generator,\n",
        "        discriminator,\n",
        "        lr=3e-4,\n",
        "        betas=(0.5, 0.999),\n",
        "        noise_function=torch.randn,\n",
        "        latent_dim=10,\n",
        "        normalize=normalize,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            generator, discriminator, lr, betas, noise_function, latent_dim\n",
        "        )\n",
        "\n",
        "        self.normalize = normalize\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # Your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ScIPwhRIuYn"
      },
      "outputs": [],
      "source": [
        "seed_everything()\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –¢–µ—Å—Ç"
      ],
      "metadata": {
        "id": "mfOBXpIIughk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z17rlt-MIuYo"
      },
      "source": [
        "–†–∞—Å—Å—á–∏—Ç–∞–π—Ç–µ  `InceptionScore` –¥–ª—è –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–π (—Ç–µ—Å—Ç–æ–≤–æ–π) –≤—ã–±–æ—Ä–∫–∏ –∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.\n",
        "\n",
        "**–°–æ–≤–µ—Ç:** –æ–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ—Ç 0 –¥–æ 1 (–Ω–µ –Ω—É–∂–Ω–æ –¥–µ–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å). –ü—Ä–∏ –Ω–∞–ø–∏—Å–∞–Ω–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞, —á—Ç–æ–±—ã –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –≤ –æ–¥–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ –∏ –Ω–µ –Ω—É–∂–Ω–æ –±—ã–ª–æ –ø—Ä–æ–≤–æ–¥–∏—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é-–¥–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é, –º–æ–∂–Ω–æ —É–±—Ä–∞—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –∏–∑ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uCp1ArlIuYo"
      },
      "outputs": [],
      "source": [
        "class RunMetric(L.LightningModule):\n",
        "    def __init__(self, generator, noise_function=torch.randn, latent_dim=10):\n",
        "        super().__init__()\n",
        "        # model\n",
        "        self.generator = generator\n",
        "        self.noise_function = noise_function\n",
        "        self.latent_dim = latent_dim\n",
        "        # metrics\n",
        "        self.is_real = InceptionScore()\n",
        "        self.is_fake = InceptionScore()\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        # Your code here\n",
        "\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        # Your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGMjQ58OIuYo"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkGoRbozIuYo"
      },
      "source": [
        "–Ø–≤–ª—è–µ—Ç—Å—è –ª–∏  `InceptionScore` ‚Äú–∏–∑ –∫–æ—Ä–æ–±–∫–∏‚Äù —Ö–æ—Ä–æ—à–µ–π –º–µ—Ç—Ä–∏–∫–æ–π –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞ Galaxy10? –ß—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏?\n",
        "\n",
        "**–ù–∞–ø–∏—à–∏—Ç–µ –≤—ã–≤–æ–¥** —Å –æ—Ç–≤–µ—Ç–æ–º –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –≤—ã—à–µ:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arjg3UZZIuYo"
      },
      "source": [
        "# –ó–∞–¥–∞–Ω–∏–µ 3. –£—Å–ª–æ–≤–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNBqf9RRIuYp"
      },
      "source": [
        "–í —Ö–æ–¥–µ –ª–µ–∫—Ü–∏–∏ –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–ª–∏ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≥–∞–ª–∞–∫—Ç–∏–∫. –í —Ä–∞–º–∫–∞—Ö –¥–∞–Ω–Ω–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è –≤–∞–º –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å–¥–µ–ª–∞—Ç—å –º–æ–¥–µ–ª—å \"—É—Å–ª–æ–≤–Ω–æ–π\", —Ç–æ –µ—Å—Ç—å –Ω–∞—É—á–∏—Ç—å—Å—è –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏ –ø–æ–º–æ—â–∏ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –æ–±—ä–µ–∫—Ç—ã –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞.\n",
        "\n",
        "–°—É—â–µ—Å—Ç–≤—É—é—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –∫ –¥–æ–±–∞–≤–ª–µ–Ω–∏—é \"—É—Å–ª–æ–≤–∏—è\" –≤ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å. –†–µ–∞–ª–∏–∑—É–µ–º –Ω–∞–∏–±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–π –ø–æ–¥—Ö–æ–¥, —Å–≤—è–∑–∞–Ω–Ω—ã–π —Å –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–∞ –≤ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —à—É–º–∞."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYsk8TwVIuYp"
      },
      "source": [
        "## –§–æ—Ä–º–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
        "\n",
        "–ù–∞–±–æ—Ä —á–∏—Å–µ–ª –æ—Ç 0 –¥–æ 9, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª—å—é.\n",
        "\n",
        "–ü—Ä–∏–º–µ—Ä –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/Exercises/EX13/result_3_task_ex13.png\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfQKigctIuYq"
      },
      "source": [
        "–ò–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIF8j9ToIuYq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import lightning as L\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from torchvision import transforms\n",
        "from torch.nn import functional as F\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhSH41l3IuYq"
      },
      "source": [
        "## –î–∞—Ç–∞—Å–µ—Ç"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqCRQRgqIuYq"
      },
      "source": [
        "–ö–∞–∫ –∏–∑–≤–µ—Å—Ç–Ω–æ, –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Ç—Ä–µ–±—É—é—Ç –±–æ–ª—å—à–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–µ–º —É–ø—Ä–æ—Å—Ç–∏—Ç—å –∑–∞–¥–∞—á—É, –≤–∑—è–≤ –≤ –∫–∞—á–µ—Å—Ç–≤–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ—Å—Ç–æ–π MNIST:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIIgSBqFIuYq"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import MNIST\n",
        "\n",
        "root = \"./data\"\n",
        "\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "dataset = MNIST(root=root, train=True, transform=transform, download=True)\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZkZC2gtIuYr"
      },
      "source": [
        "## –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –±–ª–æ–∫–∏\n",
        "\n",
        "–°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –±–ª–æ–∫–∏ –≤–æ–∑—å–º–µ–º –∏–∑ –ª–µ–∫—Ü–∏–∏ (–¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –º—ã —É–±–µ—Ä–µ–º –±–ª–æ–∫–∏ `SelfAttention`):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcbeLohbIuYr"
      },
      "outputs": [],
      "source": [
        "class ResNetBlock(nn.Module):\n",
        "    def __init__(self, in_features, out_features, mid_features=None, residual=False):\n",
        "        super().__init__()\n",
        "        self.residual = residual\n",
        "        if not mid_features:\n",
        "            mid_features = out_features\n",
        "        self.conv_stack = nn.Sequential(\n",
        "            nn.Conv2d(in_features, mid_features, kernel_size=3, padding=1, bias=False),\n",
        "            nn.GroupNorm(1, mid_features),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(mid_features, out_features, kernel_size=3, padding=1, bias=False),\n",
        "            nn.GroupNorm(1, out_features),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.residual:\n",
        "            return F.gelu(x + self.conv_stack(x))\n",
        "        else:\n",
        "            return self.conv_stack(x)\n",
        "\n",
        "\n",
        "class ResizeBlock(nn.Module):\n",
        "    def __init__(self, in_features, out_features, emb_dim):\n",
        "        super().__init__()\n",
        "        # defines non-linear map from time embedding features to conv features\n",
        "        self.emb_projection = nn.Sequential(\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(emb_dim, out_features),\n",
        "        )\n",
        "\n",
        "    def add_emb(self, x, t_vector):\n",
        "        # [batch_size, time_embedding_dim] -> [batch_size, out_features]\n",
        "        emb = self.emb_projection(t_vector)\n",
        "        # [batch_size, out_features] - > [batch_size, out_features, H, W]\n",
        "        emb = emb[:, :, None, None].repeat(1, 1, x.shape[-2], x.shape[-1])\n",
        "        return x + emb\n",
        "\n",
        "    def forward(self, x):\n",
        "        pass\n",
        "\n",
        "\n",
        "class Down(ResizeBlock):\n",
        "    def __init__(self, in_features, out_features, emb_dim=256):\n",
        "        super().__init__(in_features, out_features, emb_dim)\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            ResNetBlock(in_features, in_features, residual=True),\n",
        "            ResNetBlock(in_features, out_features),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        x = self.maxpool_conv(x)\n",
        "        x = self.add_emb(x, t)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Up(ResizeBlock):\n",
        "    def __init__(self, in_features, out_features, emb_dim=256):\n",
        "        super().__init__(in_features, out_features, emb_dim)\n",
        "\n",
        "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
        "        self.conv = nn.Sequential(\n",
        "            ResNetBlock(in_features, in_features, residual=True),\n",
        "            ResNetBlock(in_features, out_features, in_features // 2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, skip_x, t):\n",
        "        x = self.up(x)\n",
        "        x = torch.cat([skip_x, x], dim=1)\n",
        "        x = self.conv(x)\n",
        "        x = self.add_emb(x, t)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqYblCfBIuYt"
      },
      "source": [
        "## Conditional denoising U-Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6QcaImTIuYu"
      },
      "source": [
        "–ü—Ä–æ—Ü–µ–¥—É—Ä–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –º–µ—Ç–æ–∫ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –ø–æ–¥—Ä–æ–±–Ω–æ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∞ –≤ [–¥–∞–Ω–Ω–æ–π –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ üéì[arxiv]](https://arxiv.org/pdf/2207.12598.pdf). –û–Ω–∞ —Å–≤–æ–¥–∏—Ç—Å—è –∫ —Å–ª–µ–¥—É—é—â–∏–º –ø—É–Ω–∫—Ç–∞–º. –ú—ã –ø–æ—Å—Ç–∞—Ä–∞–µ–º—Å—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —É–ø—Ä–æ—Å—Ç–∏—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É, —á—Ç–æ–±—ã –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –≤ —Ä–∞–º–∫–∞—Ö —Å–µ–º–∏–Ω–∞—Ä–∞. –û—Å–Ω–æ–≤–Ω—ã–µ –æ—Ç–ª–∏—á–∏—è –º–æ–¥–µ–ª–∏:\n",
        "\n",
        "- –ú–æ–¥–µ–ª—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —à—É–º–∞ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –Ω–µ —Ç–æ–ª—å–∫–æ –±–∞—Ç—á –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –±–∞—Ç—á –∏–Ω–¥–µ–∫—Å–æ–≤ –≤—Ä–µ–º–µ–Ω–∏ –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞, –Ω–æ –∏ –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–∞.\n",
        "\n",
        "  –¢–æ –µ—Å—Ç—å –∏—Å—Ö–æ–¥–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞:\n",
        "  ```\n",
        "  class UNet(nn.Module):\n",
        "\n",
        "    ...\n",
        "    def forward(self, x, t):\n",
        "       ...\n",
        "\n",
        "  ```\n",
        "  \n",
        "  –∑–∞–º–µ–Ω–µ–Ω–æ –Ω–∞:\n",
        "```\n",
        "class UNet(nn.Module):\n",
        "\n",
        "    ...\n",
        "    def forward(self, x, t, y=None):\n",
        "       ...\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JRXgjRMIuYu"
      },
      "source": [
        "- –í–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è —É—Å–ª–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏ –º—ã —Ö–æ—Ç–∏–º –ø–æ–¥–∞–≤–∞—Ç—å –≤ –Ω–µ—ë –±–∞—Ç—á–∏ –∫–∞–∫ —Å –º–µ—Ç–∫–∞–º–∏ –∫–ª–∞—Å—Å–∞, —Ç–∞–∫ –∏ –±–µ–∑ –Ω–∏—Ö. –ß—Ç–æ–±—ã –¥–æ–±–∏—Ç—å—Å—è —ç—Ç–æ–≥–æ, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–ª–æ–∫ `nn.Embedding`, —É—Å—Ç–∞–Ω–æ–≤–∏–≤ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—ã—Ö–æ–¥–∞ —Ä–∞–≤–Ω–æ–π `time_embed_dim`. –í—ã—Ö–æ–¥ `nn.Embedding` –¥–æ–ª–∂–µ–Ω —Å—É–º–º–∏—Ä–æ–≤–∞—Ç—å—Å—è —Å `pos_encoding`, –∫–æ–≥–¥–∞ `y` –Ω–µ `None`. –†–µ–∞–ª–∏–∑—É–π—Ç–µ —ç—Ç–æ –Ω–∞ –º–µ—Å—Ç–µ `# Your code here`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfajfDzdIuYu"
      },
      "source": [
        "–î–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è –º—ã —É–ø—Ä–æ—Å—Ç–∏–ª–∏ –º–æ–¥–µ–ª—å \"—Ä–∞—Å—à—É–º–ª—è—é—â–µ–≥–æ U-Net\". –í—ã –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã –≤ –≤—ã–±–æ—Ä–µ —Ç–æ–ª—å–∫–æ –æ–ø–∏—Å–∞–Ω–Ω–æ–π –≤ –ª–µ–∫—Ü–∏–∏ –º–æ–¥–µ–ª–∏ –∏ –º–æ–∂–µ—Ç–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –Ω–∞ –±–∞–∑–µ U-Net –∏–ª–∏ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —ç—Ç–æ–π."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mT_in8mqIuYu"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    r\"\"\"\n",
        "    Denoising U-Net model implementation based on arXiv:2006.11239 [cs.LG]\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_channels=1, img_size=28, time_embed_dim=256):\n",
        "        super().__init__()\n",
        "        self.num_channels = num_channels\n",
        "        self.time_dim = time_embed_dim\n",
        "        self.img_size = img_size\n",
        "\n",
        "        # class embedding\n",
        "        # Your code here\n",
        "\n",
        "        # Downsample and enlarge feature dim\n",
        "        self.inc = ResNetBlock(num_channels, 16)\n",
        "        self.down1 = Down(16, 32)\n",
        "        self.down2 = Down(32, 32)\n",
        "\n",
        "        # Keep spatial dim constant\n",
        "        self.conv_bottleneck = nn.Sequential(\n",
        "                ResNetBlock(32, 64),\n",
        "                ResNetBlock(64, 32)\n",
        "        )\n",
        "\n",
        "        # Upsample and reduce feature dim\n",
        "        # 256=128+128 from conv_bottleneck and sa2\n",
        "        self.up1 = Up(64, 16)\n",
        "        # 128=64+64 from sa4 and sa1\n",
        "        self.up2 = Up(32, 16)\n",
        "        self.outc = nn.Conv2d(16, num_channels, kernel_size=1)\n",
        "\n",
        "    def pos_encoding(self, t):\n",
        "        r\"\"\"\n",
        "        Returns embedding vector for given integer time index.\n",
        "\n",
        "        We adopt 1d Positional Encoding form arXiv:1706.03762 [cs.CL]\n",
        "        see 3.5 for more details.\n",
        "\n",
        "        PE(x,2i) = sin(x/10000^(2i/D))\n",
        "        PE(x,2i+1) = cos(x/10000^(2i/D))\n",
        "\n",
        "        Where:\n",
        "        x is a point in 1d space\n",
        "        i is an integer in [0, D/2), where D is the size of the feature dimension\n",
        "\n",
        "        Args:\n",
        "            t: Tensor, shape ``[batch_size, 1]``\n",
        "        Returns:\n",
        "            pe: Tensor, shape ``[batch_size, time_embedding_dim]``\n",
        "        \"\"\"\n",
        "\n",
        "        # placeholder for diffusion time encoding vector\n",
        "        pe = torch.zeros(t.shape[0], self.time_dim).to(t)\n",
        "\n",
        "        # factor 1/10000^(2i/D)\n",
        "        div_factors = torch.exp(\n",
        "        torch.arange(0, self.time_dim, 2)\n",
        "        * (-torch.log(torch.as_tensor(10000.0)) / self.time_dim)\n",
        "        ).to(t)\n",
        "\n",
        "        # repeat t index for each feature\n",
        "        x = t.repeat(1, self.time_dim // 2)\n",
        "\n",
        "        # sin(x/10000^(2i/D)) for even features\n",
        "        pe[:, 0::2] = torch.sin(x * div_factors)\n",
        "        # cos(x/10000^(2i/D)) for odd features\n",
        "        pe[:, 1::2] = torch.cos(x * div_factors)\n",
        "\n",
        "        return pe\n",
        "\n",
        "    def forward(self, x, t, y=None):\n",
        "        t = t.unsqueeze(-1).type(torch.float).to(x)\n",
        "        t = self.pos_encoding(t)\n",
        "\n",
        "        if y is not None:\n",
        "          # Your code here\n",
        "\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1, t)\n",
        "        x3 = self.down2(x2, t)\n",
        "\n",
        "        x3 = self.conv_bottleneck(x3)\n",
        "\n",
        "        x = self.up1(x3, x2, t)\n",
        "        x = self.up2(x, x1, t)\n",
        "        output = self.outc(x)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_Vumrm9IuYu"
      },
      "source": [
        "## –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGetWp0GIuYu"
      },
      "source": [
        "–í–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π –¥–∞–Ω–Ω—ã—Ö, –≥–¥–µ –º—ã —É—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–∞. –ù–∞ –ø–µ—Ä–≤–æ–π —ç–ø–æ—Ö–µ –æ–±—É—á–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –º–æ–¥–µ–ª–∏ –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–∞ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é $0$, –∞ –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π —ç–ø–æ—Ö–µ –æ–±—É—á–µ–Ω–∏—è, –Ω–∞–æ–±–æ—Ä–æ—Ç, –≤—Å–µ –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –ø–µ—Ä–µ–¥–∞–Ω—ã –º–æ–¥–µ–ª–∏. –î–ª—è —ç—Ç–æ–≥–æ –Ω–∞–º –Ω—É–∂–Ω–æ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∫–ª–∞—Å—Å –¥–∏—Ñ—Ñ—É–∑–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏, –¥–æ–±–∞–≤–∏–≤ –º–µ—Ç–æ–¥—É —à–∞–≥–∞ –æ–±—É—á–µ–Ω–∏—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –∏–ª–∏ –Ω–µ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–∞ –≤ –º–æ–¥–µ–ª—å."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –ª–∏–Ω–µ–π–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–∞ –æ—Ç $0$ –¥–æ $1$ –æ—Ç —ç–ø–æ—Ö–∏ –∫ —ç–ø–æ—Ö–µ. –î–ª—è —ç—Ç–æ–≥–æ –≤–∞–º –º–æ–∂–µ—Ç –ø—Ä–∏–≥–æ–¥–∏—Ç—å—Å—è —Ñ—É–Ω–∫—Ü–∏—è `np.random.choice`, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–µ–∫—É—â–µ–π —ç–ø–æ—Ö–µ `self.current_epoch` –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ —ç–ø–æ—Ö `self.trainer.max_epochs`. –†–µ–∞–ª–∏–∑—É–π—Ç–µ –∫–æ–¥ –≤ —Ç–æ—á–∫–µ `# Your code here`."
      ],
      "metadata": {
        "id": "WOAVOGPfxE88"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpPWzzMzIuYv"
      },
      "outputs": [],
      "source": [
        "class DiffusionGenerativeModel(L.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        path,\n",
        "        num_noise_steps=1000,\n",
        "        beta_start=1e-4,\n",
        "        beta_end=0.02,\n",
        "        img_size=28,\n",
        "        lr=0.001,\n",
        "        save_images=False,\n",
        "        save_progress=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.path = Path(path)\n",
        "        self.num_noise_steps = num_noise_steps\n",
        "        self.beta_start = beta_start\n",
        "        self.beta_end = beta_end\n",
        "        self.img_size = img_size\n",
        "        self.lr = lr\n",
        "        self.save_images = save_images\n",
        "        self.save_progress = save_progress\n",
        "\n",
        "        # diffusion process linear noise schedule\n",
        "        self.beta = self._get_noise_schedule()\n",
        "        self.alpha = 1.0 - self.beta\n",
        "        # \\hat{\\alpha}_{i-1} = \\prod_{j=0}^{i-1} \\alpha_j\n",
        "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
        "\n",
        "        # init optimizer and loss for training\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr)\n",
        "        return optimizer\n",
        "\n",
        "    def _get_noise_schedule(self):\n",
        "        return torch.linspace(self.beta_start, self.beta_end, self.num_noise_steps)\n",
        "\n",
        "    def _noise_images_batch(self, x, t):\n",
        "        # \\mu_i = \\sqrt{\\hat{\\alpha}_i}\n",
        "        mu = torch.sqrt(self.alpha_hat[t])[:, None, None, None].to(self.device)\n",
        "        # \\sigma_i = \\sqrt{1 - \\hat{\\alpha}_i}\n",
        "        sigma = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None].to(self.device)\n",
        "\n",
        "        standard_normal_noise = torch.randn_like(x).to(self.device)\n",
        "        noised_image_batch = mu * x + sigma * standard_normal_noise\n",
        "        return noised_image_batch, standard_normal_noise\n",
        "\n",
        "    def _get_timestams_batch(self):\n",
        "        return torch.randint(low=1, high=self.num_noise_steps, size=(self.batch_size,))\n",
        "\n",
        "    def generate_images_batch(self, labels=None):\n",
        "        # start from pure noise batch\n",
        "        x = torch.randn((self.batch_size, 1, self.img_size, self.img_size)).to(\n",
        "            self.device\n",
        "        )\n",
        "        # and apply self.num_noise_steps denoising steps with model\n",
        "        for t_i in tqdm(reversed(range(0, self.num_noise_steps)), position=0):\n",
        "            # Build tensor with timestamp index. Same for each element in batch\n",
        "            t = torch.full((self.batch_size,), t_i).long().to(self.device)\n",
        "            if labels is None:\n",
        "                labels = (\n",
        "                    torch.randint(low=0, high=10, size=(self.batch_size,))\n",
        "                    .long()\n",
        "                    .to(self.device)\n",
        "                )\n",
        "            else:\n",
        "                labels = labels.long()\n",
        "            # predict noise on current timestamp\n",
        "            with torch.inference_mode():\n",
        "                pred_noise = self.model(x, t, labels).detach()\n",
        "\n",
        "            # restore noise parametrs on current timestamp\n",
        "            alpha = self.alpha[t.to(\"cpu\")][:, None, None, None].to(self.device)\n",
        "            alpha_hat = self.alpha_hat[t.to(\"cpu\")][:, None, None, None].to(self.device)\n",
        "            beta = self.beta[t.to(\"cpu\")][:, None, None, None].to(self.device)\n",
        "\n",
        "            # partialy denoise batch of images\n",
        "            x = x - (1.0 - alpha) / (1 - alpha_hat).sqrt() * pred_noise\n",
        "            x = (1 / alpha.sqrt()) * x\n",
        "\n",
        "            if self.save_progress and t_i % 20 == 0:\n",
        "                prog_x = x.clamp(0, 1)\n",
        "                prog_x = (prog_x * 255).type(torch.uint8)\n",
        "                self._save_img(imgs=prog_x, path=self.path / \"progress\" / f\"{t_i}.jpg\")\n",
        "            # add appropriate amount of noise for next step if any\n",
        "            if t_i > 0:\n",
        "                z = torch.randn_like(x).to(self.device)\n",
        "                x = x + beta.sqrt() * z\n",
        "\n",
        "        # clip x to valid 0..255 image range\n",
        "        x = x.clamp(0, 1)\n",
        "        x = (x * 255).type(torch.uint8)\n",
        "        if self.save_progress:\n",
        "            self._save_img(imgs=x, path=self.path / \"progress\" / f\"{t_i}.jpg\")\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # unpack data\n",
        "        images, labels = batch\n",
        "        self.batch_size = images.shape[0]\n",
        "        t = self._get_timestams_batch()\n",
        "\n",
        "        labels = labels.long()\n",
        "        # prep batch of noised images\n",
        "        noised_images, target_noise = self._noise_images_batch(images, t)\n",
        "\n",
        "        # estimate noise with U-Net\n",
        "        # Your code here\n",
        "\n",
        "        # optimize model to fit target noise\n",
        "        loss = self.criterion(predicted_noise, target_noise)\n",
        "        self.log(\"loss\", loss, prog_bar=True, on_epoch=True, on_step=False)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def _save_img(self, imgs, path):\n",
        "        image_grid = make_grid(imgs)\n",
        "        # convert to numpy\n",
        "        ndarr = image_grid.permute(1, 2, 0).to(\"cpu\").numpy()\n",
        "        # and save\n",
        "        im = Image.fromarray(ndarr)\n",
        "        im.save(path)\n",
        "        plt.imshow(ndarr)\n",
        "        plt.show()\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        if self.save_images:\n",
        "            generated_images = self.generate_images_batch()\n",
        "            self._save_img(\n",
        "                imgs=generated_images,\n",
        "                path=self.path / f\"model_{self.current_epoch}.jpg\",\n",
        "            )\n",
        "\n",
        "    def predict_step(self, batch, batch_idx, dataloader_idx=0, labels=None):\n",
        "        images, labels = batch\n",
        "        self.batch_size = images.shape[0]\n",
        "        return self.generate_images_batch(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8jkOlFLIuYv"
      },
      "source": [
        "–ò –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDvMT2fNIuYv"
      },
      "outputs": [],
      "source": [
        "seed_everything()\n",
        "path = \"/content/diffusion/\"\n",
        "batch_size = 128\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=2\n",
        ")\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath=path,\n",
        "    save_last=True,\n",
        "    every_n_epochs=1,\n",
        "    save_top_k=1,\n",
        "    monitor=\"loss\",\n",
        "    filename=\"best\",\n",
        "    mode=\"min\",\n",
        ")\n",
        "\n",
        "model = UNet()\n",
        "ddpm = DiffusionGenerativeModel(\n",
        "    model,\n",
        "    path,\n",
        "    save_images=False,\n",
        "    save_progress=False,\n",
        ")\n",
        "\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=20,\n",
        "    callbacks=[checkpoint_callback],\n",
        "    log_every_n_steps=100,\n",
        "    logger=L.pytorch.loggers.TensorBoardLogger(save_dir=path),\n",
        ")\n",
        "\n",
        "trainer.fit(model=ddpm, train_dataloaders=train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb3nWPfxIuYv"
      },
      "source": [
        "–ë—É–¥–µ–º —Å—á–∏—Ç–∞—Ç—å, —á—Ç–æ –∑–∞–¥–∞–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ, –µ—Å–ª–∏ –º—ã –Ω–∞—É—á–∏–ª–∏—Å—å –∑–∞–¥–∞–≤–∞—Ç—å –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤ (–¥–∞–∂–µ –µ—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–µ –∏–¥–µ–∞–ª–µ–Ω –∏–∑-–∑–∞ –ø—Ä–æ—Å—Ç–æ–π –º–æ–¥–µ–ª–∏ –∏ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è). –ü–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —á–∏—Å–ª–∞ –æ—Ç $0$ –¥–æ $9$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "504EBqq8IuYw"
      },
      "outputs": [],
      "source": [
        "labels = torch.arange(start=0, end=10, step=1)\n",
        "\n",
        "damp_set = torch.utils.data.TensorDataset(labels, labels)\n",
        "\n",
        "gen_loader = torch.utils.data.DataLoader(\n",
        "    damp_set, batch_size=10, shuffle=False, num_workers=2\n",
        ")  # just for image num\n",
        "\n",
        "generated_images = trainer.predict(ddpm, gen_loader)[0]\n",
        "\n",
        "image_grid = make_grid(generated_images, nrow=10)\n",
        "# convert to numpy\n",
        "ndarr = image_grid.permute(1, 2, 0).to(\"cpu\").numpy()\n",
        "# and show\n",
        "image = Image.fromarray(ndarr)\n",
        "\n",
        "fig = plt.figure(figsize=(14, 5))\n",
        "plt.imshow(image)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AMOvLs1IuYw"
      },
      "source": [
        "# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ\n",
        "\n",
        "–ú–æ–∂–µ—Ç–µ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Å –ø–æ–º–æ—â—å—é –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ [Diffusers üõ†Ô∏è[doc]](https://huggingface.co/docs/diffusers/index) –∏ –ø–æ—Ä–∞–¥–æ–≤–∞—Ç—å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}