{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bonvech/MSU-AI/blob/main/Bonvech_EX15_RL_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq_Q1hInNb7i"
      },
      "source": [
        "# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –∫–æ–¥"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZk9Hw3HNb7l"
      },
      "source": [
        "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∏–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NiG9CAfjNb7m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "311888e3-3587-40db-b26d-755b7370f2ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/953.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m102.4/953.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m553.0/953.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m952.3/953.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q gymnasium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7QtMgaMLNb7n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "\n",
        "from torch import nn\n",
        "from gym import Env, spaces\n",
        "from itertools import product\n",
        "from collections import deque\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57V-PaUwNb7o"
      },
      "source": [
        "–ß—Ç–æ–±—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–ª–∏—Å—å, –∑–∞—Ñ–∏–∫—Å–∏—Ä—É–µ–º seeds:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7c_7LirsNb7p"
      },
      "outputs": [],
      "source": [
        "def set_random_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "set_random_seed(42)\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcVZrxbBNb7p"
      },
      "source": [
        "# –ó–∞–¥–∞–Ω–∏–µ 1. –ù–∞–ø–∏—Å–∞–Ω–∏–µ —Å—Ä–µ–¥—ã –¥–ª—è –∏–≥—Ä—ã –≤ –∫—Ä–µ—Å—Ç–∏–∫–∏-–Ω–æ–ª–∏–∫–∏"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxIooQicNb7p"
      },
      "source": [
        "–í —ç—Ç–æ–º –∑–∞–¥–∞–Ω–∏–∏ –≤—ã –¥–æ–ª–∂–Ω—ã:\n",
        "\n",
        "- –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é —Å—Ä–µ–¥—É –¥–ª—è –∏–≥—Ä—ã –≤ –∫—Ä–µ—Å—Ç–∏–∫–∏ –Ω–æ–ª–∏–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ `gymnasium.Env`, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤ –¥—Ä—É–≥–∏—Ö –∑–∞–¥–∞–Ω–∏—è—Ö.\n",
        "- –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–±–æ—Ç—É —Å—Ä–µ–¥—ã –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ –∏–≥—Ä—ã –¥–≤—É—Ö —Å–ª—É—á–∞–π–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN2P0VvVNb7p"
      },
      "source": [
        "## –§–æ—Ä–º–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
        "* –°–æ–±—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞—é—â–∞—è —Å—Ä–µ–¥–∞ `TicTacToeEnv`.\n",
        "* –ò–≥—Ä–∞—é—â–∏–µ —Å–ª—É—á–∞–π–Ω—ã–µ –∞–≥–µ–Ω—Ç—ã.\n",
        "* –ü–æ—Å—á–∏—Ç–∞–Ω–Ω—ã–π –≤–∏–Ω—Ä–µ–π—Ç –¥–ª—è `'X'` –¥–ª—è –∏–≥—Ä—ã —Å–ª—É—á–∞–π–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤:\n",
        "\n",
        "    ```\n",
        "X wins in 58.53% games\n",
        "    ```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySBgIJeiNb7q"
      },
      "source": [
        "## –°—Ä–µ–¥–∞ –¥–ª—è –∏–≥—Ä—ã –≤ –∫—Ä–µ—Å—Ç–∏–∫–∏-–Ω–æ–ª–∏–∫–∏\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faPvNTb8Nb7q"
      },
      "source": [
        "**–û–ø–∏—Å–∞–Ω–∏–µ —Å—Ä–µ–¥—ã:**\n",
        "\n",
        "1. –ò–≥—Ä–æ–≤–æ–µ –ø–æ–ª–µ –∏–º–µ–µ—Ç —Ä–∞–∑–º–µ—Ä 3√ó3, –∫–æ—Ç–æ—Ä–æ–µ –ø–æ —Ö–æ–¥—É –∏–≥—Ä—ã –±—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω—è—Ç—å—Å—è –º–∞—Ä–∫–µ—Ä–∞–º–∏ –∏–≥—Ä–æ–∫–æ–≤ `'X'` –∏ `'0'`. –í –∫–ª–∞—Å—Å–µ –Ω–∏–∂–µ –æ—Ç—Ä–∏—Å–æ–≤–∫–∞ –∏–≥—Ä–æ–≤–æ–≥–æ –ø–æ–ª—è —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –≤ –º–µ—Ç–æ–¥–µ `render`.\n",
        "\n",
        "    –ü—Ä–∏–º–µ—Ä –∏–≥—Ä–æ–≤–æ–≥–æ –ø–æ–ª—è:\n",
        "\n",
        "    ```\n",
        "0|X|0\n",
        "_|X|0\n",
        "X|_|_\n",
        "    ```\n",
        "2. –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ä–µ–¥—ã –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è –≤–µ–∫—Ç–æ—Ä–æ–º (—Å–ø–∏—Å–∫–æ–º) –∏–∑ 9 —á–∏—Å–µ–ª, –≤ –∫–æ—Ç–æ—Ä–æ–º 0 –æ–±–æ–∑–Ω–∞—á–∞–µ—Ç –Ω–µ–∑–∞–Ω—è—Ç—É—é —è—á–µ–π–∫—É, 1 ‚Äî —è—á–µ–π–∫—É, –∑–∞–Ω—è—Ç—É—é `'X'`, –∏ ‚àí1 ‚Äî —è—á–µ–π–∫—É, –∑–∞–Ω—è—Ç—É—é `'0'`. –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ä–µ–¥—ã —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ –∞—Ç—Ä–∏–±—É—Ç–µ –∫–ª–∞—Å—Å–∞ `self.cells`.\n",
        "\n",
        "    –ü—Ä–∏–º–µ—Ä —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å—Ä–µ–¥—ã –¥–ª—è –∏–≥—Ä–æ–≤–æ–≥–æ –ø–æ–ª—è –≤—ã—à–µ:\n",
        "    ```\n",
        "[-1, 1, -1, 0, 1, -1, 1, 0, 0]\n",
        "    ```\n",
        "3. –í –∞—Ç—Ä–∏–±—É—Ç–µ `self.player` —Ö—Ä–∞–Ω–∏—Ç—Å—è `X` –∏–ª–∏ `0` ‚Äî —Å–∏–º–≤–æ–ª –∏–≥—Ä–æ–∫–∞, –∫–æ—Ç–æ—Ä—ã–π —Å–µ–π—á–∞—Å —Ö–æ–¥–∏—Ç (–º–µ–Ω—è–µ—Ç—Å—è –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å—Ä–µ–¥—ã).\n",
        "\n",
        "4. –í –º–µ—Ç–æ–¥ `step` –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è `action` ‚Äî –Ω–æ–º–µ—Ä —è—á–µ–π–∫–∏, –∫–æ—Ç–æ—Ä—É—é –∏–≥—Ä–æ–∫ —Ö–æ—á–µ—Ç –∏–∑–º–µ–Ω–∏—Ç—å. –ê–≥–µ–Ω—Ç –º–æ–∂–µ—Ç –ø–æ—Å—Ç–∞–≤–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–∞—Ä–∫–µ—Ä —Ç–æ–ª—å–∫–æ –≤ –Ω–µ–∑–∞–Ω—è—Ç—É—é —è—á–µ–π–∫—É –ø–æ—Å—Ä–µ–¥—Å—Ç–≤–æ–º –ø–µ—Ä–µ–¥–∞—á–∏ –Ω–æ–º–µ—Ä–∞ —è—á–µ–π–∫–∏ –≤ —Å—Ä–µ–¥—É.\n",
        "\n",
        "5. –ò–≥—Ä–∞ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è (`self.done = True`) –≤ –¥–≤—É—Ö —Å–ª—É—á–∞—è—Ö: –ø–æ–±–µ–¥–∞ –æ–¥–Ω–æ–≥–æ –∏–∑ –∏–≥—Ä–æ–∫–æ–≤ (–ø—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è –º–µ—Ç–æ–¥–æ–º `self.check_for_win`) –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø—É—Å—Ç—ã—Ö –∫–ª–µ—Ç–æ–∫ –Ω–∞ –ø–æ–ª–µ (–ø—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è –º–µ—Ç–æ–¥–æ–º `self.check_for_draw`).\n",
        "\n",
        "6. –ù–∞–≥—Ä–∞–¥–∞ –¥–æ–ª–∂–Ω–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å—Å—è –∑–∞ –ø–æ–±–µ–¥—É `'X'` –≤ —Ä–∞–∑–º–µ—Ä–µ +1 –æ—á–∫–∞, –∑–∞ –ø–æ–±–µ–¥—É `'0'`, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ, ‚àí1. –í —Å–ª—É—á–∞–µ –Ω–∏—á—å–µ–π –∏ –Ω–µ—Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π –Ω–∞–≥—Ä–∞–¥–∞ —Ä–∞–≤–Ω–∞ 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP3gL-x-Nb7r"
      },
      "source": [
        "–ó–∞–ø–æ–ª–Ω–∏—Ç–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∫–æ–¥–∞ `# Your code here`. –ü–æ–º–Ω–∏—Ç–µ, —á—Ç–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ `self.action_space`, –∑–∞–ø–æ–ª–Ω—è–µ–º–æ–µ –∏–≥—Ä–æ–∫–∞–º–∏, [–¥–∏—Å–∫—Ä–µ—Ç–Ω–æ üõ†Ô∏è[doc]](https://gymnasium.farama.org/api/spaces/fundamental/#discrete)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "EKGQEJliNb7r"
      },
      "outputs": [],
      "source": [
        "class TicTacToeEnv(Env):\n",
        "    def __init__(self):\n",
        "        # Define default variable\n",
        "        self.cells = [0 for i in range(9)]  # environment state\n",
        "        self.player = \"X\"  # current player (changes every step)\n",
        "        self.done = False  # is the game over\n",
        "        self.winner = None  # who is the winner\n",
        "\n",
        "        # Symbols for rendering\n",
        "        self.markers = {1: \"X\", 0: \"_\", -1: \"0\"}\n",
        "\n",
        "        # Space https://gymnasium.farama.org/api/spaces/fundamental\n",
        "        self.action_space = spaces.Discrete(9)  # Your code here\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Bring game to initial state, define default variables.\n",
        "        \"\"\"\n",
        "        # Your code here\n",
        "        # Define default variable\n",
        "        self.cells = [0 for i in range(9)]  # environment state\n",
        "        self.player = \"X\"  # current player (changes every step)\n",
        "        self.done = False  # is the game over\n",
        "        self.winner = None  # who is the winner\n",
        "\n",
        "\n",
        "    def render(self):\n",
        "        \"\"\"\n",
        "        –†rint game board.\n",
        "        \"\"\"\n",
        "        cells = [self.markers[x] for x in self.cells]\n",
        "\n",
        "        for j in range(0, 9, 3):\n",
        "            print(\"|\".join([cells[i] for i in range(j, j + 3)]))\n",
        "\n",
        "    def legal_actions(self):\n",
        "        \"\"\"\n",
        "        Check for actions available: check free cells\n",
        "        \"\"\"\n",
        "        return [ind for ind, value in enumerate(self.cells) if value == 0]\n",
        "\n",
        "    def check_for_win(self, cells):\n",
        "        \"\"\"\n",
        "        Check that there is any win combination on the board.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        cells: list\n",
        "            Environment state\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "            bool\n",
        "            True if win, False in over cases\n",
        "        \"\"\"\n",
        "        # Your code here\n",
        "        is_win = False\n",
        "        ##  vertical\n",
        "        if any(abs(sum(cells[i::3])) == 3 for i in range(3)):\n",
        "            is_win = True\n",
        "        ##  horisontal\n",
        "        elif any(abs(sum(cells[3*i:3*i+3:])) == 3 for i in range(3)):\n",
        "            is_win = True\n",
        "        ##  diagonal\n",
        "        elif abs(sum(cells[0::4])) == 3 or abs(sum(cells[2:7:2])) == 3:\n",
        "            is_win = True\n",
        "        return is_win\n",
        "\n",
        "\n",
        "    def check_for_draw(self, cells):\n",
        "        \"\"\"\n",
        "        Checking that the board is completely filled out.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        cells: list\n",
        "            Environment state\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "            bool\n",
        "            True if the board is completely filled out, False in over cases\n",
        "        \"\"\"\n",
        "        if 0 not in cells:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Player input process\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        action: int\n",
        "            number of cell for change\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        observation: list\n",
        "            New environment state\n",
        "        reward: int\n",
        "            Reward: 1 if win of 'X', -1 if win of '0', 0 in othrer cases\n",
        "        self.done: bool\n",
        "            Game over flag\n",
        "        self.player: 'X' or '0'\n",
        "            Player who takes the next step\n",
        "        \"\"\"\n",
        "        # Check that action is possible\n",
        "        assert self.action_space.contains(action), \"impossible action\"\n",
        "        # Check that cell is empty\n",
        "        assert (\n",
        "            action in self.legal_actions()\n",
        "        ), \"not legal action\"\n",
        "\n",
        "        # Fill self.cells[action] depends on on whose turn (self.player) it is\n",
        "        self.cells[action] = 1 if self.player == \"X\" else -1 # Your code here\n",
        "\n",
        "        observation = self.cells.copy()# Your code here\n",
        "\n",
        "        # Check that there is any win combination on the board\n",
        "        self.done = self.check_for_win(self.cells)  # Your code here\n",
        "\n",
        "        if self.done and self.player == \"X\":\n",
        "            reward = 1\n",
        "            self.winner = \"X\"\n",
        "\n",
        "        elif self.done and self.player == \"0\":\n",
        "            reward = -1\n",
        "            self.winner = \"0\"\n",
        "\n",
        "        else:\n",
        "            # Checking that the board is completely filled out\n",
        "            self.done = self.check_for_draw(self.cells)\n",
        "            reward = 0\n",
        "            self.winner = None\n",
        "\n",
        "        # Toggle players\n",
        "        if self.player == \"X\":\n",
        "            self.player = \"0\"\n",
        "        else:\n",
        "            self.player = \"X\"\n",
        "\n",
        "        return observation, reward, self.done, self.player"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## –ü—Ä–æ–≤–µ—Ä–∏–º —Ñ—É–Ω–∫—Ü–∏—é –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–±–µ–¥—ã\n",
        "from itertools import product\n",
        "\n",
        "\n",
        "def check_for_win(cells):\n",
        "        \"\"\"\n",
        "        Check that there is any win combination on the board.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        cells: list\n",
        "            Environment state\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "            bool\n",
        "            True if win, False in over cases\n",
        "        \"\"\"\n",
        "        # Your code here\n",
        "        is_win = False\n",
        "        ##  vertical\n",
        "        if any(abs(sum(cells[i::3])) == 3 for i in range(3)):\n",
        "            #print([sum(cells[i::3]) for i in range(3)])\n",
        "            is_win = True\n",
        "        ##  horisontal\n",
        "        elif any(abs(sum(cells[3*i:3*i+3:])) == 3 for i in range(3)):\n",
        "            print([sum(cells[3*i:3*i+3:]) for i in range(3)])\n",
        "            #print(1)\n",
        "            is_win = True\n",
        "        ##  diagonal\n",
        "        if abs(sum(cells[0::4])) == 3 or abs(sum(cells[2:7:2])) == 3:\n",
        "            print(sum(cells[0::4]), sum(cells[2:7:2]))\n",
        "            is_win = True\n",
        "        return is_win\n",
        "\n",
        "def render(cells):\n",
        "        \"\"\"\n",
        "        –†rint game board.\n",
        "        \"\"\"\n",
        "        markers = {1: \"X\", 0: \"_\", -1: \"0\"}\n",
        "        cells = [markers[x] for x in cells]\n",
        "\n",
        "        for j in range(0, 9, 3):\n",
        "            print(\"|\".join([cells[i] for i in range(j, j + 3)]))\n",
        "\n",
        "\n",
        "n = 0\n",
        "for cells in product([-1,0,1], repeat=9):\n",
        "     n += 1\n",
        "     if n == 5: break\n",
        "     render(cells)\n",
        "     print(check_for_win(cells))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VZltIWkwG0X",
        "outputId": "bd7951cd-9f60-465f-b558-e486301e5527"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0|0|0\n",
            "0|0|0\n",
            "0|0|0\n",
            "-3 -3\n",
            "True\n",
            "0|0|0\n",
            "0|0|0\n",
            "0|0|_\n",
            "-2 -3\n",
            "True\n",
            "0|0|0\n",
            "0|0|0\n",
            "0|0|X\n",
            "-1 -3\n",
            "True\n",
            "0|0|0\n",
            "0|0|0\n",
            "0|_|0\n",
            "-3 -3\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLXSJn3RNb7r"
      },
      "source": [
        "## –°–ª—É—á–∞–π–Ω—ã–π –∞–≥–µ–Ω—Ç"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNhOrHUGNb7s"
      },
      "source": [
        "–†–µ–∞–ª–∏–∑—É–π—Ç–µ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –≤—ã–±–∏—Ä–∞–µ—Ç –¥–µ–π—Å—Ç–≤–∏–µ —Å–ª—É—á–∞–π–Ω—ã–º –æ–±—Ä–∞–∑–æ–º –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "g_GQBzpPNb7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62e6bcf3-c74a-4836-efbe-ddb8cdf0891d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "class RandomAgent:\n",
        "    def __init__(self, mark=\"X\"):\n",
        "        self.mark = mark\n",
        "\n",
        "    def get_action(self, env):\n",
        "        \"\"\"\n",
        "        Sample random LEGAL action from action space\n",
        "        (use env.legal_actions and random.choice)\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        action: int\n",
        "            number of cell for change\n",
        "        \"\"\"\n",
        "        # Your code here\n",
        "        action = random.choice(env.legal_actions())\n",
        "\n",
        "        return action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "UXQOVPjsNb7s"
      },
      "outputs": [],
      "source": [
        "ttt = TicTacToeEnv()\n",
        "\n",
        "x_agent = RandomAgent(\"X\")\n",
        "o_agent = RandomAgent(\"0\")\n",
        "\n",
        "rand_players = {\"X\": x_agent, \"0\": o_agent}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ttt.player"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "EyM5koQS5OBH",
        "outputId": "a6702d7f-5ba9-44d7-bf5c-53251d66f4b0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'X'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9qyQ5nQNb7s"
      },
      "source": [
        "–í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –∏–≥—Ä—É –º–µ–∂–¥—É –¥–≤—É–º—è —Å–ª—É—á–∞–π–Ω—ã–º–∏ –∞–≥–µ–Ω—Ç–∞–º–∏:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "mrj8-ZCSNb7t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b75406be-d1f3-4378-f6e0-7cb009862324"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_|X|_\n",
            "_|_|_\n",
            "_|_|_\n",
            "\n",
            "\n",
            "_|X|_\n",
            "_|_|_\n",
            "_|0|_\n",
            "\n",
            "\n",
            "_|X|_\n",
            "X|_|_\n",
            "_|0|_\n",
            "\n",
            "\n",
            "_|X|_\n",
            "X|_|0\n",
            "_|0|_\n",
            "\n",
            "\n",
            "_|X|_\n",
            "X|X|0\n",
            "_|0|_\n",
            "\n",
            "\n",
            "_|X|0\n",
            "X|X|0\n",
            "_|0|_\n",
            "\n",
            "\n",
            "_|X|0\n",
            "X|X|0\n",
            "X|0|_\n",
            "\n",
            "\n",
            "_|X|0\n",
            "X|X|0\n",
            "X|0|0\n",
            "\n",
            "\n",
            "0 wins! Reward is -1\n"
          ]
        }
      ],
      "source": [
        "ttt.reset()\n",
        "\n",
        "while not ttt.done:\n",
        "    # which agent from `rand_players` is playing (use `ttt.player` info)\n",
        "    player = rand_players[ttt.player] # Your code here\n",
        "    # action of this agent\n",
        "    action = player.get_action(ttt) # Your code here\n",
        "    # step\n",
        "    state, reward, done, player = ttt.step(action) # Your code here\n",
        "    ttt.render()\n",
        "    print(\"\\n\")\n",
        "print(f\"{ttt.winner} wins! Reward is {reward}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu-wI72cNb7t"
      },
      "source": [
        "## –í–∏–Ω—Ä–µ–π—Ç –¥–ª—è 'X' –¥–ª—è —Å–ª—É—á–∞–π–Ω—ã—Ö –∞–≥–µ–Ω—Ç–æ–≤"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_PEZMeINb7t"
      },
      "source": [
        "–î–∞–≤–∞–π—Ç–µ —Å–¥–µ–ª–∞–µ–º –±–µ–π–∑–ª–∞–π–Ω, —Å –∫–æ—Ç–æ—Ä—ã–º –º—ã –±—É–¥–µ–º —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–≥—Ä—ã –∞–≥–µ–Ω—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã—Ö –º—ã –±—É–¥–µ–º –æ–±—É—á–∞—Ç—å. –î–ª—è —ç—Ç–æ–≥–æ –ø–æ—Å—á–∏—Ç–∞–µ–º, –≤ –∫–∞–∫–æ–º –ø—Ä–æ—Ü–µ–Ω—Ç–µ —Å–ª—É—á–∞–µ–≤ `X` –≤—ã–∏–≥—Ä—ã–≤–∞–µ—Ç –Ω–∞ 100000 –∏–≥—Ä–∞—Ö –º–µ–∂–¥—É —Å–ª—É—á–∞–π–Ω—ã–º–∏ –∏–≥—Ä–æ–∫–∞–º–∏, –∏ –¥–∞–ª—å—à–µ –±—É–¥–µ–º –ø—Ä–æ–±–æ–≤–∞—Ç—å —É–ª—É—á—à–∏—Ç—å —ç—Ç–æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "YjdiZCeXNb7t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e88d421-e7b3-4fcd-d084-f2d82f422929"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X wins in 58.53% games\n"
          ]
        }
      ],
      "source": [
        "wins = {\"X\": 0, \"0\": 0}\n",
        "\n",
        "for i in range(100_000):\n",
        "    ttt.reset()\n",
        "\n",
        "    while not ttt.done:\n",
        "        player = rand_players[ttt.player]\n",
        "        action = player.get_action(ttt)\n",
        "\n",
        "        state, reward, done, player = ttt.step(action)\n",
        "\n",
        "    if ttt.winner is not None:\n",
        "        wins[ttt.winner] += 1\n",
        "\n",
        "print(f'X wins in {round((wins[\"X\"]/100_000)*100, 2)}% games')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0_zhutaNb7u"
      },
      "source": [
        "# –ó–∞–¥–∞–Ω–∏–µ 2. –û–±—É—á–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ –∏–≥—Ä–µ –≤ –∫—Ä–µ—Å—Ç–∏–∫–∏-–Ω–æ–ª–∏–∫–∏ —Å –ø–æ–º–æ—â—å—é Q-learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZPZv0-6Nb7u"
      },
      "source": [
        "–°–æ–∑–¥–∞–π—Ç–µ –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –∏–≥—Ä—ã –≤ –∫—Ä–µ—Å—Ç–∏–∫–∏-–Ω–æ–ª–∏–∫–∏ –∏ –æ–±—É—á–∏—Ç–µ –µ–≥–æ —Å –ø–æ–º–æ—â—å—é Q-learning, –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –∂–∞–¥–Ω–æ–≥–æ –∏ $\\varepsilon$-–∂–∞–¥–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIj6iqUQNb7u"
      },
      "source": [
        "## –§–æ—Ä–º–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
        "\n",
        "1. –û–±—É—á–µ–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é Q-learning –∞–≥–µ–Ω—Ç—ã, –∏–≥–∞—é—â–∏–µ –∑–∞ `'X'`:\n",
        "- –∂–∞–¥–Ω—ã–π,\n",
        "- $\\varepsilon$-–∂–∞–¥–Ω—ã–π.\n",
        "2. –ü–æ—Å—á–∏—Ç–∞–Ω–Ω—ã–µ –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ –≤–∏–Ω—Ä–µ–π—Ç—ã –ø—Ä–∏ –∏–≥—Ä–µ –ø—Ä–æ—Ç–∏–≤ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞, –∏–≥—Ä–∞—é—â–µ–≥–æ –∑–∞ `'0'`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HadW239QNb7v"
      },
      "source": [
        "## –ö–æ–¥ Q-learning –∞–≥–µ–Ω—Ç–∞\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z443qhf9Nb7v"
      },
      "source": [
        "–í —ç—Ç–æ–π —á–∞—Å—Ç–∏ –∑–∞–¥–∞–Ω–∏—è –≤–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Q-learning –∞–≥–µ–Ω—Ç–∞.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu_pKmfPNb7v"
      },
      "source": [
        "–í–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –±—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–∏—Ç—å `# Your code here`:\n",
        "- –º–µ—Ç–æ–¥ `set_states`: –Ω—É–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –∏–∑ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π ‚àí1, 0 –∏ 1 –≤–æ–∑–º–æ–∂–Ω—ã–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å—Ä–µ–¥—ã –ø–µ—Ä–µ–¥ —Ö–æ–¥–æ–º `‚ÄòX‚Äô` (`‚ÄòX‚Äô` –≤—Å–µ–≥–¥–∞ —Ö–æ–¥–∏—Ç –ø–µ—Ä–≤—ã–º, –ø–æ—ç—Ç–æ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ 1 –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Å—Ä–µ–¥—ã –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ä–∞–≤–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É ‚àí1) –∏ –ø–µ—Ä–µ–¥ —Ö–æ–¥–æ–º `‚Äô0‚Äô` (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ 1 –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Å—Ä–µ–¥—ã –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–∞ –æ–¥–∏–Ω –±–æ–ª—å—à–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ ‚àí1).\n",
        "- –º–µ—Ç–æ–¥ `set_Q_table`: –Ω—É–∂–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–ª—É—á–∞–π–Ω—ã–º–∏ —á–∏—Å–ª–∞–º–∏ Q-–∑–Ω–∞—á–µ–Ω–∏—è –≤—Å–µ—Ö –ª–µ–≥–∞–ª—å–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π (–ª–µ–≥–∞–ª—å–Ω–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—É—Å—Ç—ã—Ö –∫–ª–µ—Ç–æ–∫) –∏–∑ —ç—Ç–∏—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π.\n",
        "- –º–µ—Ç–æ–¥ `get_action`: –Ω—É–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ –∏–ª–∏ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∞–≥–µ–Ω—Ç–∞ –∏ –∑–Ω–∞—á–µ–Ω–∏—è `epsilon`.\n",
        "- –º–µ—Ç–æ–¥ `update_Q`: –Ω—É–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ—Å–Ω–æ–≤–Ω—É—é —Ñ–æ—Ä–º—É–ª—É Q-learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b8xv8adNb7v"
      },
      "source": [
        "–û—Å–Ω–æ–≤–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞ Q-learning:\n",
        "\n",
        "$$Q(s,a) = Q(s,a)+Œ±(R^a_{s} + \\gamma\\max_{a'}Q(s',a') -Q(s,a)),$$\n",
        "\n",
        "–≥–¥–µ $s$ ‚Äî —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ä–µ–¥—ã `state` –≤ –Ω–∞—á–∞–ª–µ —Ö–æ–¥–∞ –∞–≥–µ–Ω—Ç–∞, $a$ ‚Äî –¥–µ–π—Å—Ç–≤–∏–µ `action` –∞–≥–µ–Ω—Ç–∞ –Ω–∞ –¥–∞–Ω–Ω–æ–º —Ö–æ–¥–µ, $Q(s,a)$ ‚Äî –∑–Ω–∞—á–µ–Ω–∏–µ Q-table `self.Q[current_state][action]` –¥–ª—è —Å–æ—Å—Ç–æ—è–Ω–∏—è $s$ –∏ –¥–µ–π—Å—Ç–≤–∏—è $a$, $R^a_{s}$ ‚Äî –Ω–∞–≥—Ä–∞–¥–∞ `reward` –∑–∞ –¥–µ–π—Å—Ç–≤–∏–µ `a` –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è `s`, $s'$ ‚Äî —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ä–µ–¥—ã –ø–æ—Å–ª–µ —Ö–æ–¥–∞ –∏–≥—Ä–æ–∫–∞ –∏ –µ–≥–æ –æ–ø–ø–æ–Ω–µ–Ω—Ç–∞, $a'$ ‚Äî —Å–ª–µ–¥—É—é—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ –∏–≥—Ä–æ–∫–∞, $Œ±$ ‚Äî —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è, $\\gamma$ ‚Äî –¥–∏—Å–∫–æ–Ω—Ç –∑–∞ –¥–ª–∏–Ω–Ω—É—é –∏–≥—Ä—É."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF8VEXunNb7w"
      },
      "source": [
        "**–°–æ–≤–µ—Ç:**\n",
        "- –ü—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ Q-–∑–Ω–∞—á–µ–Ω–∏–π (–º–µ—Ç–æ–¥ `update_Q`) —É—á—Ç–∏—Ç–µ, —á—Ç–æ —Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏–≥—Ä—ã –Ω–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ Q-—Ç–∞–±–ª–∏—Ü–µ (–∏–∑ –Ω–µ–≥–æ —É–∂–µ –Ω–µ–ª—å–∑—è –¥–µ–ª–∞—Ç—å —Ö–æ–¥) –∏, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ, –¥–ª—è —Å–æ—Å—Ç–æ—è–Ω–∏–π, –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â–∏—Ö –µ–º—É, $\\max_{a'}Q(s',a')$ –±—É–¥–µ—Ç —Ä–∞–≤–Ω–æ –Ω—É–ª—é.\n",
        "- –ü—Ä–∏ –ø–æ–±–µ–¥–µ `'X'` –≤—ã–¥–∞–µ—Ç—Å—è –Ω–∞–≥—Ä–∞–¥–∞ +1, –∞ –≤ —Å–ª—É—á–∞–µ –ø–æ–±–µ–¥—ã `'0'` ‚Äî –Ω–∞–≥—Ä–∞–¥–∞ ‚àí1. –ê–≥–µ–Ω—Ç, –∏–≥—Ä–∞—é—â–∏–π `'X',` –¥–æ–ª–∂–µ–Ω –≤—ã–±–∏—Ä–∞—Ç—å –¥–µ–π—Å—Ç–≤–∏–µ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º Q-–∑–Ω–∞—á–µ–Ω–∏–µ–º, –∞ `'0'` ‚Äî —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º Q-–∑–Ω–∞—á–µ–Ω–∏–µ–º.\n",
        "- –ü—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ Q-–∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –¥–µ–π—Å—Ç–≤–∏–π –∏–∑ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è —É—á—Ç–∏—Ç–µ, —á—Ç–æ $s'$ –±—É–¥–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º –∏–≥—Ä–æ–≤–æ–≥–æ –ø–æ–ª—è –Ω–µ –ø–æ—Å–ª–µ —Ö–æ–¥–∞ –∏–≥—Ä–æ–∫–∞, –∞ –ø–æ—Å–ª–µ —Ö–æ–¥–∞ –æ–ø–ø–æ–Ω–µ–Ω—Ç–∞."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = set(product(*[list(range(-1, 2)) for _ in range(9)]))\n",
        "n = 0\n",
        "for state in states:\n",
        "        Q = {ind: random.gauss(0, 0.1) for ind, value in enumerate(state) if value == 0}\n",
        "        print(state, Q)\n",
        "        print(max(Q.values()), [key for key in Q.keys() if Q[key] == max(Q.values())][0])\n",
        "        n += 1\n",
        "        if n > 10:\n",
        "            break\n",
        "print(n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8RRs2O358Bmw",
        "outputId": "1cdd7fa6-c317-4a72-c0e3-272c552a39d1"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, -1, 0, 0, 0, 0, -1, 1, 1) {0: 0.0697467324821126, 2: 0.025923313373021024, 3: -0.12129859185931094, 4: -0.12872298825332829, 5: -0.016558518628655906}\n",
            "0.0697467324821126 0\n",
            "(0, 0, 0, 0, 0, 0, 1, -1, 1) {0: -0.09381693629544519, 1: 0.06719523985355359, 2: 0.023421464773831814, 3: -0.1528972695676295, 4: 0.044269457494967315, 5: 0.07243218643565856}\n",
            "0.07243218643565856 5\n",
            "(-1, 0, 0, 0, 0, -1, 1, -1, 0) {1: 0.08475369944422217, 2: -0.02815348804800883, 3: 0.04174534019251815, 4: -0.08514403773428691, 8: 0.03183752841942881}\n",
            "0.08475369944422217 1\n",
            "(0, 1, 0, -1, 1, -1, -1, 0, 1) {0: 0.036660858756808544, 2: 0.1569731830333102, 7: 0.10503723489063997}\n",
            "0.1569731830333102 2\n",
            "(0, 1, 0, 1, 0, -1, 1, 1, -1) {0: -0.009258558647252639, 2: -0.0019829997649381827, 4: 0.04304966297782046}\n",
            "0.04304966297782046 4\n",
            "(1, 1, -1, 0, 1, -1, -1, 0, 0) {3: 0.06527901427696305, 7: -0.06917983257965622, 8: -0.05950840169625088}\n",
            "0.06527901427696305 3\n",
            "(1, 1, 0, -1, -1, -1, 1, 0, 1) {2: 0.2954643457576239, 7: -0.06763236139267875}\n",
            "0.2954643457576239 2\n",
            "(0, -1, -1, 1, 1, 1, 1, -1, 0) {0: -0.21871274075270586, 8: 0.022544964552299707}\n",
            "0.022544964552299707 8\n",
            "(1, -1, 1, -1, 1, 1, 0, 1, 0) {6: -0.061670067226792386, 8: -0.09366963342641749}\n",
            "-0.061670067226792386 6\n",
            "(-1, 0, 0, 1, 0, -1, 0, 1, 0) {1: 0.0840348009524894, 2: 0.18938022874558127, 4: 0.014538504450143666, 6: 0.1282076724972845, 8: 0.07866110677943228}\n",
            "0.18938022874558127 2\n",
            "(-1, 1, -1, 0, 0, 0, 1, 0, -1) {3: -0.1571460817450386, 4: 0.14582426781944086, 5: -0.10108956819942903, 7: 0.021355812957128004}\n",
            "0.14582426781944086 4\n",
            "11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "id": "URTB0BEoNb7w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6070fa3f-e124-4c00-c2cf-2e6d3037934b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "from itertools import product\n",
        "\n",
        "\n",
        "class QTableAgent:\n",
        "    def __init__(\n",
        "            self, alpha=0.05, gamma=0.9, mark=\"X\", epsilon=0.,\n",
        "            epsilon_off=True\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        alpha: float\n",
        "            learning rate\n",
        "        gamma: float\n",
        "            discount coefficient\n",
        "        mark: str\n",
        "            'X' or '0' - player symbol\n",
        "        epsilon: float\n",
        "            epsilon for epsilon-greedy agent\n",
        "        epsilon_off: boolean\n",
        "            if True -'greedy' learning strategy or inference,\n",
        "            if False 'epsilon-greedy' learning strategy\n",
        "        \"\"\"\n",
        "        self.mark = mark\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_off = epsilon_off\n",
        "\n",
        "        # Get possible for self.mark environment states\n",
        "        self.states = self.set_states()\n",
        "        print((0,0,0,0,0,0,0,0,0) in states)\n",
        "        # Init Q-table\n",
        "        self.Q = self.set_Q_table()\n",
        "        #print((0,0,0,0,0,0,0,0,0) in Q.keys())\n",
        "        #print(\"Q in init:\", self.Q)\n",
        "\n",
        "\n",
        "    def set_states(self):\n",
        "        \"\"\"\n",
        "        Set possible for self.mark environment states\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        states: set\n",
        "            Set of possible for self.mark environment states\n",
        "        \"\"\"\n",
        "        # Set of all possible marker compositions\n",
        "        #states = set(product(*[list(range(-1, 2)) for _ in range(9)]))\n",
        "        states = set(product([-1, 0, 1], repeat=9))\n",
        "        # Subset of states for X player\n",
        "        # contains states in which both players took equal number of actions\n",
        "        # (since X goes first)\n",
        "        if self.mark == \"X\": # select with condition\n",
        "            states = {tuple(state) for state in states if sum(state) == 0} # Your code here\n",
        "\n",
        "        # Subset of states for 0 player\n",
        "        # contains states in which X player took one more action than 0 player\n",
        "        # (since 0 goes second)\n",
        "\n",
        "        elif self.mark == \"0\": # select with condition\n",
        "            states = {state for state in states if sum(state) == 1} # Your code here\n",
        "        return states\n",
        "\n",
        "\n",
        "    def set_Q_table(self):\n",
        "        \"\"\"\n",
        "        Init Q-table.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Q: dict\n",
        "            Q-table[state][action] for possible states and actions with\n",
        "            random gauss (mean=0, sigma=0.1)\n",
        "        \"\"\"\n",
        "        Q = {}\n",
        "        # Match legal actions for each possible action in each state with\n",
        "        # random initial number\n",
        "        for state in self.states:\n",
        "            #print(state, {ind: random.gauss(0, 0.1) for ind, value in enumerate(state) if value == 0})\n",
        "            Q[state] =   {ind: random.gauss(0, 0.1) for ind, value in enumerate(state) if value == 0} # Your code here\n",
        "        #print(\"QQ in set_Q_table\", Q)\n",
        "        return Q\n",
        "\n",
        "\n",
        "    def get_action(self, env):\n",
        "        \"\"\"\n",
        "        Sample optimal or random action.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        env: TicTacToeEnv\n",
        "            environment\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        action: int\n",
        "            number of cell for change\n",
        "        \"\"\"\n",
        "        state = tuple(env.cells)\n",
        "        rand = random.uniform(0, 1)\n",
        "        #print(state)\n",
        "        #print(\"Q: \", self.Q.keys())\n",
        "\n",
        "        if self.epsilon_off or rand >= self.epsilon:\n",
        "            # Sample optimal action (based on greediness)\n",
        "            if self.mark == \"X\":\n",
        "                action = [key for key in self.Q[state].keys() if self.Q[state][key] == max(self.Q[state].values())][0] # Your code here\n",
        "            else:\n",
        "                action = [key for key in self.Q[state].keys() if self.Q[state][key] == min(self.Q[state].values())][0] # Your code here\n",
        "        else:\n",
        "            # Sample random  action\n",
        "            #print(\"AAAAAAA\", list(self.Q[state]))\n",
        "            action = random.choice(list(self.Q[state])) # Your code here\n",
        "\n",
        "        return action\n",
        "\n",
        "    def update_Q(self, current_state, action, next_state, reward, done):\n",
        "        \"\"\"\n",
        "        Q-table update.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        current_state: list\n",
        "            Current environment state\n",
        "        action: int\n",
        "            Current agent action\n",
        "        next_state: list\n",
        "            Environment state after agent action and opponent action\n",
        "        reward: int\n",
        "            Reward\n",
        "        done: bool\n",
        "            Game over flag\n",
        "        \"\"\"\n",
        "        current_state = tuple(current_state)\n",
        "        if not done:\n",
        "            next_state = tuple(next_state)\n",
        "            next_state_value = max(self.Q[next_state].values())\n",
        "        else:\n",
        "            next_state_value = 0\n",
        "\n",
        "        # Q-learning update formula\n",
        "        # Your code here\n",
        "        self.Q[current_state][action] = self.Q[current_state][action] \\\n",
        "                + self.alpha * (reward + self.gamma * next_state_value - self.Q[current_state][action])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOqz94hbNb7x"
      },
      "source": [
        "## –û–±—É—á–µ–Ω–∏–µ –∂–∞–¥–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ `'X'`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLScGLOYNb7x"
      },
      "source": [
        "–û–±—É—á–∏—Ç–µ –∞–≥–µ–Ω—Ç–∞, –∏–≥—Ä–∞—é—â–µ–≥–æ –∑–∞ `X`, –ø—Ä–∏–¥–µ—Ä–∂–∏–≤–∞—é—â–µ–≥–æ—Å—è –∂–∞–¥–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏, –ø—Ä–æ—Ç–∏–≤ **—Å–ª—É—á–∞–π–Ω–æ–≥–æ** –∞–≥–µ–Ω—Ç–∞, –∏–≥—Ä–∞—é—â–µ–≥–æ –∑–∞ `0`, –Ω–∞ 1 –º–∏–ª–ª–∏–æ–Ω–µ –∏–≥—Ä –∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ –∏—Ö –≤–∏–Ω—Ä–µ–π—Ç—ã –º–µ–∂–¥—É —Å–æ–±–æ–π –∏ —Å –±–µ–π–∑–ª–∞–π–Ω–æ–º."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwFDl1a7Nb7x"
      },
      "source": [
        "**–°–æ–≤–µ—Ç:**\n",
        "- –ü—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —É—á—Ç–∏—Ç–µ, —á—Ç–æ $s'$ –±—É–¥–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º –∏–≥—Ä–æ–≤–æ–≥–æ –ø–æ–ª—è –Ω–µ –ø–æ—Å–ª–µ —Ö–æ–¥–∞ –∏–≥—Ä–æ–∫–∞, –∞ –ø–æ—Å–ª–µ —Ö–æ–¥–∞ –æ–ø–ø–æ–Ω–µ–Ω—Ç–∞.\n",
        "- –ü–æ–º–Ω–∏—Ç–µ, —á—Ç–æ `list` –≤ python —è–≤–ª—è–µ—Ç—Å—è [–∏–∑–º–µ–Ω—è–µ–º—ã–º —Ç–∏–ø–æ–º –¥–∞–Ω–Ω—ã—Ö ‚úèÔ∏è[blog]](https://realpython.com/python-mutable-vs-immutable-types/). –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `.copy()`, —á—Ç–æ–±—ã –∏–∑–æ–ª–∏—Ä–æ–≤–∞—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ä–µ–¥—ã, –ø–æ–¥–∞–≤–∞–µ–º–æ–µ –∞–≥–µ–Ω—Ç—É."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "id": "LQMQGcuVNb7y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90cc94b4-64d0-4a84-b240-890d5908d0b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "ttt = TicTacToeEnv()\n",
        "\n",
        "x_agent = QTableAgent(0.05, 0.9, \"X\", epsilon=0.1, epsilon_off=True)\n",
        "\n",
        "o_agent = RandomAgent(\"0\")\n",
        "\n",
        "players = {\"X\": x_agent, \"0\": o_agent}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "id": "1OsfZxllNb7y"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "for i in tqdm(range(1_000_000)):\n",
        "    ttt.reset()\n",
        "    while not ttt.done:\n",
        "        player = players[ttt.player]\n",
        "        if player.mark == \"X\":\n",
        "            action_x = player.get_action(ttt)  # Your code here\n",
        "            current_state = ttt.cells.copy() # Your code here\n",
        "            state, reward, done, _ = ttt.step(action_x) # Your code here\n",
        "            if done:\n",
        "                players[\"X\"].update_Q(current_state, action_x, 0, reward, done) # Your code here\n",
        "        else:\n",
        "            action_o = player.get_action(ttt) # Your code here\n",
        "            next_state, reward, done, _ = ttt.step(action_o) # Your code here\n",
        "\n",
        "            players[\"X\"].update_Q(current_state, action_x, next_state, reward, done) # Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zKIo4ADNb7y"
      },
      "source": [
        "–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –≤–∏–Ω—Ä–µ–π—Ç:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "id": "Ufm7r908Nb7y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b69bcc7-4dce-4175-b5e1-0212a4e4deb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X wins in 86.43% games\n",
            "CPU times: user 8.92 s, sys: 44.2 ms, total: 8.96 s\n",
            "Wall time: 9.07 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "wins = {\"X\": 0, \"0\": 0}\n",
        "\n",
        "for i in range(100_000):\n",
        "    ttt.reset()\n",
        "\n",
        "    while not ttt.done:\n",
        "        player = players[ttt.player]\n",
        "        action = player.get_action(ttt)\n",
        "\n",
        "        state, reward, done, player = ttt.step(action)\n",
        "\n",
        "    if ttt.winner is not None:\n",
        "        wins[ttt.winner] += 1\n",
        "\n",
        "print(f'X wins in {round((wins[\"X\"]/100000)*100, 2)}% games')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66XIW2OHNb7y"
      },
      "source": [
        "## –û–±—É—á–µ–Ω–∏–µ $\\varepsilon$-–∂–∞–¥–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞ `'X'`:\n",
        "\n",
        "–û–±—É—á–∏—Ç–µ –∞–≥–µ–Ω—Ç–∞, –∏–≥—Ä–∞—é—â–µ–≥–æ –∑–∞ `X`, –ø—Ä–∏–¥–µ—Ä–∂–∏–≤–∞—é—â–µ–≥–æ—Å—è $\\varepsilon$-–∂–∞–¥–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏, –ø—Ä–æ—Ç–∏–≤ **—Å–ª—É—á–∞–π–Ω–æ–≥–æ** –∞–≥–µ–Ω—Ç–∞, –∏–≥—Ä–∞—é—â–µ–≥–æ –∑–∞ `0`, –Ω–∞ 1 –º–∏–ª–ª–∏–æ–Ω–µ –∏–≥—Ä –∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ –∏—Ö –≤–∏–Ω—Ä–µ–π—Ç—ã –º–µ–∂–¥—É —Å–æ–±–æ–π –∏ —Å –±–µ–π–∑–ª–∞–π–Ω–æ–º."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {
        "id": "F0thDnKWNb74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7073856-c761-455c-d5fd-d8f9603bd73f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "ttt = TicTacToeEnv()\n",
        "\n",
        "x_agent = QTableAgent(0.05, 0.9, \"X\", epsilon=0.1, epsilon_off=False)\n",
        "o_agent = RandomAgent(\"0\")\n",
        "\n",
        "players = {\"X\": x_agent, \"0\": o_agent}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {
        "id": "cv7bEbbXNb74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "54a8e58f7e44465195f2cf03ca6c438b",
            "5ffb633566a84822b0f2602d26191b6a",
            "8df750255bed411f8f5f29b70228d889",
            "527244dd2e784b0f9c54ab6142dc148d",
            "fc710d83b2cc4c86bfc3ed5d80d89b32",
            "9658f0a63d9043febc6c7bf7ee366f09",
            "bb624ba7e8714ba98815a17773344ddc",
            "b3a80319a0cc455fa79cd91f3cf6dc76",
            "e61c3275cc164936a9e502cc4305214d",
            "a341afd1843443458832f2fe0d95628c",
            "e2df5208016c40be88da20f3fb858c5c"
          ]
        },
        "outputId": "bbf811f3-7824-40ae-eb38-983ceeac9978"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1000000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54a8e58f7e44465195f2cf03ca6c438b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "for i in tqdm(range(1_000_000)):\n",
        "\n",
        "    ttt.reset()\n",
        "    while not ttt.done:\n",
        "        player = players[ttt.player]\n",
        "        if player.mark == \"X\":\n",
        "            action_x = player.get_action(ttt) # Your code here\n",
        "            current_state = ttt.cells.copy()  # Your code here\n",
        "            state, reward, done, _ = ttt.step(action_x) # Your code here\n",
        "            if done:\n",
        "                players[\"X\"].update_Q(current_state, action_x, 0, reward, done) # Your code here\n",
        "        else:\n",
        "            action_o = player.get_action(ttt)# Your code here\n",
        "            next_state, reward, done, _ = ttt.step(action_o) # Your code here\n",
        "\n",
        "            players[\"X\"].update_Q(current_state, action_x, next_state, reward, done)  # Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKUYtmkpNb74"
      },
      "source": [
        "–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –≤–∏–Ω—Ä–µ–π—Ç. –û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ç–æ, —á—Ç–æ –º—ã **–≤—ã–∫–ª—é—á–∞–µ–º –ø—Ä–∏–º–µ—à–∏–≤–∞–Ω–∏–µ —Å–ª—É—á–∞–π–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –º–æ–¥–µ–ª–∏**. –ë–µ–∑ —ç—Ç–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ –±—É–¥–µ—Ç —Å–∏–ª—å–Ω–æ –∑–∞–Ω–∏–∂–µ–Ω–æ!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {
        "id": "-FfEjvHxNb75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd0a687a-e3c9-43b1-df97-83633f6fc8e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X wins in 99.25% games\n"
          ]
        }
      ],
      "source": [
        "wins = {\"X\": 0, \"0\": 0}\n",
        "players[\"X\"].epsilon_off = True\n",
        "\n",
        "for i in range(100_000):\n",
        "    ttt.reset()\n",
        "\n",
        "    while not ttt.done:\n",
        "        player = players[ttt.player]\n",
        "        action = player.get_action(ttt)\n",
        "\n",
        "        state, reward, done, player = ttt.step(action)\n",
        "\n",
        "    if ttt.winner is not None:\n",
        "        wins[ttt.winner] += 1\n",
        "\n",
        "print(f'X wins in {round((wins[\"X\"]/100_000)*100, 2)}% games')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88cH7Ym-Nb75"
      },
      "source": [
        "## –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å—Ä–∞–∑–∏—Ç—å—Å—è —Å –≤–∞—à–∏–º –æ–±—É—á–µ–Ω–Ω—ã–º –∞–≥–µ–Ω—Ç–æ–º\n",
        "\n",
        "–ú–æ–∂–µ—Ç–µ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å—Ä–∞–∑–∏—Ç—å—Å—è —Å –≤–∞—à–∏–º –æ–±—É—á–µ–Ω–Ω—ã–º –∞–≥–µ–Ω—Ç–æ–º.\n",
        "–í –∫–∞—á–µ—Å—Ç–≤–µ –≤–≤–æ–¥–∞ –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏–±–æ —Ä—É—á–Ω–æ–π –≤–≤–æ–¥, –ª–∏–±–æ —Å–ª—É—á–∞–π–Ω—ã–π:\n",
        "\n",
        "*   `human_action = int(input())  # manual input`\n",
        "*   `human_action = np.random.choice(ttt.legal_actions())`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "HdvyeuOjNb75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93d30fe9-d2f1-4fba-981e-96fb72f746e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_|_|_\n",
            "_|_|_\n",
            "_|_|_\n",
            "\n",
            "\n",
            "It's X turn\n",
            "_|_|_\n",
            "_|X|_\n",
            "_|_|_\n",
            "\n",
            "\n",
            "_|_|_\n",
            "_|X|_\n",
            "_|_|_\n",
            "\n",
            "\n",
            "It's 0 turn\n",
            "chose action: [0, 1, 2, 3, 5, 6, 7, 8]\n",
            "0\n",
            "0|_|_\n",
            "_|X|_\n",
            "_|_|_\n",
            "\n",
            "\n",
            "0|_|_\n",
            "_|X|_\n",
            "_|_|_\n",
            "\n",
            "\n",
            "It's X turn\n",
            "0|_|_\n",
            "_|X|_\n",
            "_|X|_\n",
            "\n",
            "\n",
            "0|_|_\n",
            "_|X|_\n",
            "_|X|_\n",
            "\n",
            "\n",
            "It's 0 turn\n",
            "chose action: [1, 2, 3, 5, 6, 8]\n",
            "1\n",
            "0|0|_\n",
            "_|X|_\n",
            "_|X|_\n",
            "\n",
            "\n",
            "0|0|_\n",
            "_|X|_\n",
            "_|X|_\n",
            "\n",
            "\n",
            "It's X turn\n",
            "0|0|_\n",
            "_|X|_\n",
            "X|X|_\n",
            "\n",
            "\n",
            "0|0|_\n",
            "_|X|_\n",
            "X|X|_\n",
            "\n",
            "\n",
            "It's 0 turn\n",
            "chose action: [2, 3, 5, 8]\n",
            "2\n",
            "0|0|0\n",
            "_|X|_\n",
            "X|X|_\n",
            "\n",
            "\n",
            "0 wins! Reward is -1\n"
          ]
        }
      ],
      "source": [
        "ttt.reset()\n",
        "\n",
        "while not ttt.done:\n",
        "    ttt.render()\n",
        "    print(\"\\n\")\n",
        "    print(f\"It's {ttt.player} turn\")\n",
        "    if ttt.player == \"X\":\n",
        "        action = players[\"X\"].get_action(ttt)\n",
        "        state, reward, done, player = ttt.step(action)\n",
        "\n",
        "        ttt.render()\n",
        "        print(\"\\n\")\n",
        "        continue\n",
        "    else:\n",
        "        print(f\"chose action: {ttt.legal_actions()}\")\n",
        "        human_action = int(input())  # manual input\n",
        "        #human_action = np.random.choice(ttt.legal_actions())\n",
        "        state, reward, done, player = ttt.step(human_action)\n",
        "\n",
        "        ttt.render()\n",
        "        print(\"\\n\")\n",
        "\n",
        "print(f\"{ttt.winner} wins! Reward is {reward}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xtZZCDjNb76"
      },
      "source": [
        "# –ó–∞–¥–∞–Ω–∏–µ 3. –û–±—É—á–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞ –∏–≥—Ä–µ –≤ –∫—Ä–µ—Å—Ç–∏–∫–∏-–Ω–æ–ª–∏–∫–∏ –ø—Ä–∏ –ø–æ–º–æ—â–∏ DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D3MA6ltNb78"
      },
      "source": [
        "–û–±—É—á–∏—Ç–µ —Å –ø–æ–º–æ—â—å—é Deep Q-learning –∞–≥–µ–Ω—Ç–∞ –∏–≥—Ä–µ –≤ –∫—Ä–µ—Å—Ç–∏–∫–∏-–Ω–æ–ª–∏–∫–∏."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erSAqd8vNb79"
      },
      "source": [
        "## –§–æ—Ä–º–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
        "–û–±—É—á–µ–Ω–Ω—ã–π —Å –ø–æ–º–æ—â—å—é Deep Q-learning –∞–≥–µ–Ω—Ç, –∏–≥–∞—é—â–∏–π –∑–∞ `'X'`, —Å –≤–∏–Ω—Ä–µ–π—Ç–æ–º –ø—Ä–æ—Ç–∏–≤ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞, –∏–≥—Ä–∞—é—â–µ–≥–æ –∑–∞ `'0'`, ~85%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEPjlrl-Nb79"
      },
      "source": [
        "## –ö–æ–¥ DQN –∞–≥–µ–Ω—Ç–∞"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "823U1iHyNb79"
      },
      "source": [
        "–î–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è experience replay –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `deque` [‚úèÔ∏è[blog]](https://proproprogs.ru/structure_data/std-ochered-collectionsdeque-na-python)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j8eHDO0Nb7-"
      },
      "source": [
        "–í —ç—Ç–æ–π —á–∞—Å—Ç–∏ –∑–∞–¥–∞–Ω–∏—è –≤–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å DQN –∞–≥–µ–Ω—Ç–∞.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD94pA6LNb7-"
      },
      "source": [
        "–í–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –±—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–∏—Ç—å `# Your code here`:\n",
        "- –º–µ—Ç–æ–¥ `set_Q_network`: –Ω—É–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Å–µ—Ç–∏. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–µ—Ç–∏ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —É—Å—Ç—Ä–æ–µ–Ω–∞ —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º: –Ω–∞ –≤—Ö–æ–¥ –ø—Ä–∏–Ω–∏–º–∞—é—Ç—Å—è 9 –∑–Ω–∞—á–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—é –∏–≥—Ä–æ–≤–æ–≥–æ –ø–æ–ª—è, –Ω–∞ –≤—ã—Ö–æ–¥ –≤—ã–¥–∞—é—Ç—Å—è 9 –∑–Ω–∞—á–µ–Ω–∏–π, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç Q-–∑–Ω–∞—á–µ–Ω–∏—è–º –¥–ª—è 9 –≤–æ–∑–º–æ–∂–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π, —Å–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏ ‚Äî –Ω–∞ –≤–∞—à –≤—ã–±–æ—Ä, –ø–æ—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å —Ä–∞–∑–Ω—ã–º–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º–∏.\n",
        "- –º–µ—Ç–æ–¥ `get_action`: –Ω—É–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤—ã–±–æ—Ä –ª—É—á—à–µ–≥–æ –∏–ª–∏ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∞–≥–µ–Ω—Ç–∞ –∏ –∑–Ω–∞—á–µ–Ω–∏—è `epsilon`. –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `env.legal_actions()`.\n",
        "- –º–µ—Ç–æ–¥ `update_target_network`: –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–µ—Ç–∏ `self.Q_net`(–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è) –≤ —Å–µ—Ç—å `self.target_net` (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è Q-–∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è —Å–ª–µ–¥—É—é—â–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è $s'$). –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `state_dict()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7vpZKmeNb7-"
      },
      "source": [
        "<center><img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/Exercises/EX15/dqn_loss.png\" alt=\"Drawing\" width=\"800\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLrBxRRZNb7_"
      },
      "source": [
        "**–°–æ–≤–µ—Ç:** –æ–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –Ω–µ –≤—Å–µ 9 –∑–Ω–∞—á–µ–Ω–∏–π –±—É–¥—É—Ç –¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π, —É—á—Ç–∏—Ç–µ —ç—Ç–æ –≤ –º–µ—Ç–æ–¥–µ `get_action`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EU-ZltfmNb7_"
      },
      "outputs": [],
      "source": [
        "from collections import deque\n",
        "\n",
        "\n",
        "class DQNAgent(nn.Module):\n",
        "    def __init__(\n",
        "        self, gamma=0.9, mark=\"X\", memory_size=10000, epsilon=0.,\n",
        "        epsilon_off=True\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        alpha: float\n",
        "            learning rate\n",
        "        gamma: float\n",
        "            discount coefficient\n",
        "        mark: str\n",
        "            'X' or '0' - player symbol\n",
        "        memory_size: int\n",
        "            size of memory buffer\n",
        "        epsilon: float\n",
        "            epsilon for epsilon-greedy agent\n",
        "        epsilon_off: boole\n",
        "            if True -'greedy' learning strategy or inference,\n",
        "            if False 'epsilon-greedy' learning strategy\n",
        "        \"\"\"\n",
        "        super(DQNAgent, self).__init__()\n",
        "        self.mark = mark\n",
        "        self.gamma = torch.tensor(gamma, dtype=float)\n",
        "        self.epsilon = epsilon\n",
        "        self.epsilon_off = epsilon_off\n",
        "\n",
        "        # Experience replay\n",
        "        self.exp_replay = deque(maxlen=memory_size)\n",
        "        # Q-Network (for learning and Q(s, a))\n",
        "        self.Q_net = self.set_Q_network()\n",
        "        # Target-Network (for Q(s', a'))\n",
        "        self.target_net = self.set_Q_network()\n",
        "        self.update_target_network()\n",
        "\n",
        "    def set_Q_network(self):\n",
        "        \"\"\"Set Q_net architecture.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Q_net: nn.Sequential\n",
        "            Q_net architecture\n",
        "        \"\"\"\n",
        "        Q_net = nn.Sequential( # Your code here\n",
        "        return Q_net\n",
        "\n",
        "    def forward(self, states):\n",
        "        \"\"\"Forward pass.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        states: list, np.array or torch.Tensor [batch_size, 9]\n",
        "            batch of environment states at the beginning of the agent's action\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Q_vals: torch.Tensor [batch_size, 9]\n",
        "            Q-vals for all 9 action (not all of this action legal)\n",
        "        \"\"\"\n",
        "        states = torch.Tensor(states)\n",
        "        Q_vals = self.Q_net(states)\n",
        "        return Q_vals\n",
        "\n",
        "    def get_action(self, Q_vals, env):\n",
        "        \"\"\"\n",
        "        Sample optimal or random legal action.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        Q_vals: torch.Tensor [batch_size, 9]\n",
        "            Q-vals for all 9 action (not all of this action legal)\n",
        "        env: TicTacToeEnv\n",
        "            environment\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        action: int\n",
        "            number of cell for change\n",
        "        \"\"\"\n",
        "        state = torch.Tensor(env.cells)\n",
        "        # Get legal action from env, transform to torch.int64 tensor\n",
        "\n",
        "        legal_actions = # Your code here\n",
        "\n",
        "        index = torch.zeros(9, dtype=bool)\n",
        "        index[legal_actions.to(torch.int64)] = True\n",
        "        rand = random.uniform(0, 1)\n",
        "        if self.epsilon_off or rand >= self.epsilon:\n",
        "            # Sample optimal action\n",
        "            if self.mark == \"X\":\n",
        "                best_q = # Your code here\n",
        "            else:\n",
        "                best_q = # Your code here\n",
        "            action = torch.logical_and(Q_vals == best_q, index).nonzero()[0].item()\n",
        "\n",
        "        else:\n",
        "            # Sample random action\n",
        "            action =  # Your code here\n",
        "\n",
        "        return int(action)\n",
        "\n",
        "    def add_to_memory(self, current_state, action, next_state, reward, done):\n",
        "        \"\"\"Add data to experience replay.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        current_state: torch.Tensor [batch_size, 9]\n",
        "            Current environment state\n",
        "        action: int\n",
        "            Current agent action\n",
        "        next_state: torch.Tensor [batch_size, 9]\n",
        "            Environment state after agent action and opponent action\n",
        "        reward: int\n",
        "            Reward\n",
        "        done: bool\n",
        "            Game over flag\n",
        "        \"\"\"\n",
        "        self.exp_replay.append((current_state, action, next_state, reward, done))\n",
        "\n",
        "    def update_target_network(self):\n",
        "        \"\"\"Use Q_net parameters to update target_net.\"\"\"\n",
        "        # Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVW43RBUNb8A"
      },
      "source": [
        "## –ö–æ–¥ –æ–±—É—á–µ–Ω–∏—è"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0Xwhx_hNb8A"
      },
      "source": [
        "–†–µ–∞–ª–∏–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é, —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—é—â—É—é TD Loss:\n",
        "$$ L = { 1 \\over N} \\sum_i [ Q_{\\theta}(s,a) - Q_\\text{reference}(s,a) ] ^2 $$\n",
        "\n",
        "–° Q-reference, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º –∫–∞–∫:\n",
        "\n",
        "$$ \\large Q_\\text{reference}(s,a) = R^a_{s} + \\gamma \\cdot \\max_{a'} Q_\\text{target}(s', a'), $$\n",
        "\n",
        "–≥–¥–µ:\n",
        "* $R^a_{s}$ ‚Äî –Ω–∞–≥—Ä–∞–¥–∞ `reward` –∑–∞ –¥–µ–π—Å—Ç–≤–∏–µ `a` –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è `s`,\n",
        "* $Q_\\text{target}(s',a')$ ‚Äî $Q$-–∑–Ω–∞—á–µ–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã `next_states` –∏ —Å–ª–µ–¥—É—é—â–µ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è, –≤—ã—á–∏—Å–ª–µ–Ω–Ω–æ–µ `agent.target_net`,\n",
        "* $s, a, s'$ ‚Äî —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ `states`, –¥–µ–π—Å—Ç–≤–∏–µ `actions` –∏ —Å–ª–µ–¥—É—é—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ `next_states`,\n",
        "* $\\gamma$ ‚Äî –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è `agent.gamma`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqTNHB63Nb8B"
      },
      "source": [
        "**–°–æ–≤–µ—Ç:**\n",
        "- –ü—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ $Q_\\text{reference}(s,a)$ `reference_q` —É—á—Ç–∏—Ç–µ, —á—Ç–æ —Ç–µ—Ä–º–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏–≥—Ä—ã –Ω–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ Q-—Ç–∞–±–ª–∏—Ü–µ (–∏–∑ –Ω–µ–≥–æ —É–∂–µ –Ω–µ–ª—å–∑—è –¥–µ–ª–∞—Ç—å —Ö–æ–¥) –∏, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ, –¥–ª—è —Å–æ—Å—Ç–æ—è–Ω–∏–π, –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â–∏—Ö –µ–º—É, $\\max_{a'} Q_\\text{target}(s', a')$ –±—É–¥–µ—Ç —Ä–∞–≤–Ω–æ –Ω—É–ª—é (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `is_not_done`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "di3FYVVYNb8B"
      },
      "outputs": [],
      "source": [
        "def compute_td_loss(batch, agent):\n",
        "    states = torch.tensor(np.array([x[0] for x in batch]), dtype=torch.float)\n",
        "    actions = torch.tensor(np.array([x[1] for x in batch]), dtype=torch.int64)\n",
        "    next_states = torch.tensor(np.array([x[2] for x in batch]), dtype=torch.float)\n",
        "    rewards = torch.tensor(np.array([x[3] for x in batch]), dtype=torch.int64)\n",
        "    is_not_done = 1 - torch.tensor(np.array([x[4] for x in batch]), dtype=torch.int64)\n",
        "\n",
        "    q_vals = # Your code here\n",
        "    current_q = # Your code here\n",
        "    target_q = # Your code here\n",
        "    reference_q = # Your code here\n",
        "    loss = # Your code here\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWmcsTfSNb8B"
      },
      "source": [
        "–†–µ–∞–ª–∏–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é, –≤—ã–¥–∞—é—â—É—é –≤–∏–Ω—Ä–µ–π—Ç –∏–≥—Ä–æ–∫–∞ –Ω–∞ 10–∫ –∏–≥—Ä–∞—Ö (–Ω–µ –∑–∞–±—ã–≤–∞–µ–º –≤—ã–∫–ª—é—á–∞—Ç—å –ø—Ä–∏–º–µ—à–∏–≤–∞–Ω–∏–µ —Å–ª—É—á–∞–π–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –º–æ–¥–µ–ª–∏):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQTn6V4_Nb8B"
      },
      "outputs": [],
      "source": [
        "def get_winrate():\n",
        "    wins = {\"X\": 0, \"0\": 0}\n",
        "    players[\"X\"].epsilon_off = True\n",
        "\n",
        "    for i in range(10_000):\n",
        "        ttt.reset()\n",
        "\n",
        "        while not ttt.done:\n",
        "            player = players[ttt.player]\n",
        "            if player.mark == \"0\":\n",
        "                action = player.get_action(ttt)\n",
        "            else:\n",
        "                q_vals = player(ttt.cells)\n",
        "                action = player.get_action(q_vals, ttt)\n",
        "\n",
        "            state, reward, done, player = ttt.step(action)\n",
        "\n",
        "        if ttt.winner is not None:\n",
        "            wins[ttt.winner] += 1\n",
        "    wr = (wins[\"X\"] / 10000) * 100\n",
        "    print(f\"X wins in {round(wr, 2)}% games\")\n",
        "    return wr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyYHr5IjNb8C"
      },
      "outputs": [],
      "source": [
        "target_wr = 85.0\n",
        "\n",
        "ttt = TicTacToeEnv()\n",
        "\n",
        "x_agent = DQNAgent(gamma=0.8, mark=\"X\", epsilon=0.2, epsilon_off=False)\n",
        "o_agent = RandomAgent(\"0\")\n",
        "\n",
        "players = {\"X\": x_agent, \"0\": o_agent}\n",
        "\n",
        "opt = torch.optim.Adam(players[\"X\"].Q_net.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St4cANmRNb8C"
      },
      "source": [
        "–î–∞–ª–µ–µ –º—ã –æ–±—É—á–∏–º –∏–≥—Ä–æ–∫–∞ `X` –ø—Ä–æ—Ç–∏–≤ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –∏–≥—Ä–æ–∫–∞ `0`. –ó–∞–¥–∞—á–∞ ‚Äî –¥–æ–±–∏—Ç—å—Å—è –≤–∏–Ω—Ä–µ–π—Ç–∞ ~85%.\n",
        "\n",
        "–ü—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è —Å—Ç—Ä–æ–∏—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:\n",
        "* –≤–æ –≤—Ä–µ–º—è –æ–¥–Ω–æ–≥–æ —ç–ø–∏–∑–æ–¥–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –ø—Ä–æ—Ç—è–∂–µ–Ω–∏–∏ 50 –∏–≥—Ä —Å–æ–±–∏—Ä–∞–µ—Ç—Å—è –∏–≥—Ä–æ–≤–æ–π –æ–ø—ã—Ç –≤ –±—É—Ñ–µ—Ä –ø–∞–º—è—Ç–∏ –∞–≥–µ–Ω—Ç–∞, –∞ –∏–º–µ–Ω–Ω–æ —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ, –¥–µ–π—Å—Ç–≤–∏–µ –∏–∑ –Ω–µ–≥–æ, —Å–ª–µ–¥—É—é—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ, –Ω–∞–≥—Ä–∞–¥–∞ –∏ —Ñ–ª–∞–≥ –∫–æ–Ω—Ü–∞ —ç–ø–∏–∑–æ–¥–∞;\n",
        "* –∏–∑ –ø–∞–º—è—Ç–∏ –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è —Å–ª—É—á–∞–π–Ω—ã–π –±–∞—Ç—á –∏ –æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è –≤–µ—Å–∞ Q-—Å–µ—Ç–∏;\n",
        "* –ø–æ—Å–ª–µ –∫–∞–∂–¥—ã—Ö 50 –ø–æ–¥–æ–±–Ω—ã—Ö —ç–ø–∏–∑–æ–¥–æ–≤ –æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è –≤–µ—Å–∞ target network, —Å–ª–µ–¥–∏—Ç–µ –∑–∞ –∏–∑–º–µ–Ω–µ–Ω–∏–µ–º –≤–∏–Ω—Ä–µ–π—Ç–∞ –ø–æ—Å–ª–µ –∫–∞–∂–¥—ã—Ö 500 —ç–ø–∏–∑–æ–¥–æ–≤.\n",
        "\n",
        "–í–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –ø—Ä–æ–ø—É—Å–∫ `# Your code here`, –≤ –∫–æ—Ç–æ—Ä–æ–º –∑–∞–ø–æ–ª–Ω—è–µ—Ç—Å—è –±—É—Ñ–µ—Ä –ø–∞–º—è—Ç–∏ –∞–≥–µ–Ω—Ç–∞."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAf2eKnUNb8C"
      },
      "source": [
        "**–°–æ–≤–µ—Ç:**\n",
        "- –ü—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —É—á—Ç–∏—Ç–µ, —á—Ç–æ $s'$ –±—É–¥–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ–º –∏–≥—Ä–æ–≤–æ–≥–æ –ø–æ–ª—è –Ω–µ –ø–æ—Å–ª–µ —Ö–æ–¥–∞ –∏–≥—Ä–æ–∫–∞, –∞ –ø–æ—Å–ª–µ —Ö–æ–¥–∞ –æ–ø–ø–æ–Ω–µ–Ω—Ç–∞.\n",
        "- –û–±—É—á–µ–Ω–∏–µ RL-–º–æ–¥–µ–ª–∏ –Ω–µ—É—Å—Ç–æ–π—á–∏–≤–æ. –ù–µ–±–æ–ª—å—à–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å–µ—Ç–∏ –∏–ª–∏ –¥–∞–∂–µ [–≤—ã–±–æ—Ä seed ‚úèÔ∏è[blog]](https://www.alexirpan.com/2018/02/14/rl-hard.html) –º–æ–≥—É—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –ø–æ–º–µ–Ω—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2aT2WlvNb8D"
      },
      "outputs": [],
      "source": [
        "clear_output()\n",
        "\n",
        "for j in range(10_000):\n",
        "    for i in range(50):\n",
        "        # Your code here\n",
        "\n",
        "    batch = random.sample(players[\"X\"].exp_replay, 128)\n",
        "\n",
        "    opt.zero_grad()\n",
        "    loss = compute_td_loss(batch, players[\"X\"])\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(players[\"X\"].Q_net.parameters(), 1.0)\n",
        "    opt.step()\n",
        "\n",
        "    if j % 50 == 0:\n",
        "        players[\"X\"].update_target_network()\n",
        "\n",
        "    if j % 500 == 0:\n",
        "        wr = get_winrate()\n",
        "\n",
        "    if wr > target_wr:\n",
        "        break\n",
        "        if players[\"X\"].epsilon > 0:\n",
        "            players[\"X\"].epsilon -= 0.005"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "54a8e58f7e44465195f2cf03ca6c438b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ffb633566a84822b0f2602d26191b6a",
              "IPY_MODEL_8df750255bed411f8f5f29b70228d889",
              "IPY_MODEL_527244dd2e784b0f9c54ab6142dc148d"
            ],
            "layout": "IPY_MODEL_fc710d83b2cc4c86bfc3ed5d80d89b32"
          }
        },
        "5ffb633566a84822b0f2602d26191b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9658f0a63d9043febc6c7bf7ee366f09",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_bb624ba7e8714ba98815a17773344ddc",
            "value": "100%"
          }
        },
        "8df750255bed411f8f5f29b70228d889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3a80319a0cc455fa79cd91f3cf6dc76",
            "max": 1000000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e61c3275cc164936a9e502cc4305214d",
            "value": 1000000
          }
        },
        "527244dd2e784b0f9c54ab6142dc148d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a341afd1843443458832f2fe0d95628c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e2df5208016c40be88da20f3fb858c5c",
            "value": "‚Äá1000000/1000000‚Äá[01:36&lt;00:00,‚Äá10528.57it/s]"
          }
        },
        "fc710d83b2cc4c86bfc3ed5d80d89b32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9658f0a63d9043febc6c7bf7ee366f09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb624ba7e8714ba98815a17773344ddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3a80319a0cc455fa79cd91f3cf6dc76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e61c3275cc164936a9e502cc4305214d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a341afd1843443458832f2fe0d95628c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2df5208016c40be88da20f3fb858c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}