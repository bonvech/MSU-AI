{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bonvech/MSU-AI/blob/main/EX09_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmM-kXNV-5Yr"
      },
      "source": [
        "# Вспомогательный код"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSWklmPi-5Yt"
      },
      "source": [
        "Чтобы результаты экспериментов воспроизводились, зафиксируем seed's:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wV59lHhW-5Yv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def set_random_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "set_random_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_cb3d7K-5Yx"
      },
      "source": [
        "Для выполнения задания рекомендуется использовать среду с аппаратным ускорителем GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DQLVIfs-5Yx"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kPPOAEB-5Yx"
      },
      "source": [
        "# Задание 1. Прогнозирование временного ряда"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l3KMo3L-5Yy"
      },
      "source": [
        "Используя код из лекции, попробуйте обучить GRU с размерностью скрытого состояния `hidden_size=20` на следующих периодичных данных и визуализируйте результат."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxgoVy4J-5Yy"
      },
      "source": [
        "Импорт необходимых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqt5EmW0-5Yy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV3MVVLT-5Yz"
      },
      "source": [
        "Генерация данных для прогнозирования:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1uqU7UB-5Yz"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "total_length = 1000\n",
        "for i in range(total_length):\n",
        "    data.append(\n",
        "        math.sin(i / 2) + math.cos((i) / 6) + i / 100 + (random.random() - 0.5) / 2\n",
        "    )\n",
        "\n",
        "dataset = pd.DataFrame(data={\"timestamps\": range(total_length), \"values\": data})\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76hdis8H-5Y0"
      },
      "source": [
        "Выведем временной ряд:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcQCxJ0B-5Y0"
      },
      "outputs": [],
      "source": [
        "def simple_display(data, xticks, label=None):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.plot(xticks, data, label=label)\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm7C16Zq-5Y1"
      },
      "outputs": [],
      "source": [
        "data = dataset[\"values\"]\n",
        "simple_display(data=data, xticks=dataset[\"timestamps\"], label=\"Initial data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peWxni3_-5Y1"
      },
      "source": [
        "Пользуясь примером прогнозирования временного ряда с помощью рекуррентной нейронной сети из лекции, постройте прогнозирующую модель.\n",
        "\n",
        "Шаги, которые необходимо совершить:\n",
        "1. Разбиение на train-val-test.\n",
        "2. Предобработка данных.\n",
        "3. Создание и обучение модели.\n",
        "4. Получение предсказаний и расчет метрик качества."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcLSQ9EI-5Y1"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIZ--4bh-5Y2"
      },
      "source": [
        "## Формат результата"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2RNYglI-5Y2"
      },
      "source": [
        "1. Графики предсказания модели:\n",
        "- для обучающих и валидационных данных в режиме \"forced prediction\",\n",
        "- для тестовых данных в режиме \"rolling prediction\".\n",
        "\n",
        "Пример графиков:\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/Exercises/EX09/result_1_1_task_ex09.png\" width=\"800\">\n",
        "\n",
        "2. Оценка качества предсказаний, полученных в режимах, описанных выше, для обучающих, валидационных и тестовых данных.\n",
        "\n",
        "3. Графики предсказания модели для обучающих, валидационных и тестовых данных в режиме \"rolling prediction\". Для тестовых данных получить предсказание, как минимум, еще на одну длину тестовых данных.\n",
        "\n",
        "Пример графиков:\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/Exercises/EX09/result_2_1_task_ex09.png\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcNwe4-e-5Y2"
      },
      "source": [
        "# Задание 2. Генерация фамилий"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3B3jW8I-5Y3"
      },
      "source": [
        "Возьмите следующий набор данных и, используя код из лекции, создайте рекуррентную сеть для генерации фамилий. Подумайте, как получить разные фамилии, начинающиеся на одну и ту же букву."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdDR-jh_-5Y3"
      },
      "source": [
        "Импорт необходимых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5ALY0AK-5Y3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahsIV5Ka-5Y3"
      },
      "source": [
        "Загрузка данных:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tmyRsm9-5Y4"
      },
      "outputs": [],
      "source": [
        "!wget -q https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/surnames.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKSvD2O1-5Y4"
      },
      "outputs": [],
      "source": [
        "with open(\"surnames.txt\", encoding=\"utf-8\") as s_file:\n",
        "    surnames_list = [line.strip().lower() for line in s_file.readlines()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zta5sNNe-5Y4"
      },
      "outputs": [],
      "source": [
        "print(f\"Total number of surnames: {len(surnames_list)}\")\n",
        "print(\"First 10 samples:\")\n",
        "pprint(surnames_list[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4euw9be_-5Y5"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJGcGN6P-5Y5"
      },
      "source": [
        "## Формат результата"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icmMXOoM-5Y5"
      },
      "source": [
        "Модель, генерирующая фамилии по первой букве.\n",
        "\n",
        "Пример:\n",
        "\n",
        "а — Аркова\n",
        "\n",
        "б — Банова\n",
        "\n",
        "в — Варенков\n",
        "\n",
        "г — Гаранков"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtyXVWxo-5Y6"
      },
      "source": [
        "# Задание 3. Прогнозирование многомерного временного ряда"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR1Omp6I-5Y6"
      },
      "source": [
        "Попробуйте свои силы в анализе многомерных данных. Особенностью таких задач является то, что признаки не являются независимыми и разумно анализировать их одновременно.\n",
        "\n",
        "В качестве датасета предлагаем [курс биткоина 🛠️[doc]](https://finance.yahoo.com/quote/BTC-USD/history?period1=1410912000&period2=1642118400&interval=1d&filter=history&frequency=1d&includeAdjustedClose=true).\n",
        "\n",
        "Рекомендуем использовать модель LSTM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77yxNuKP-5Y6"
      },
      "source": [
        "Установка и импорт необходимых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1oQ91tL-5Y6"
      },
      "outputs": [],
      "source": [
        "!pip install -q lightning\n",
        "!pip install -q pmdarima"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2TJtqoy-5Y7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import torch\n",
        "import random\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightning as L\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datetime import timedelta\n",
        "from pmdarima.arima import auto_arima\n",
        "from lightning.pytorch import Trainer\n",
        "from torchmetrics import MetricCollection\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from torchmetrics.regression import MeanSquaredError\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "from lightning.pytorch.loggers import TensorBoardLogger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viP4x4Dj-5Y8"
      },
      "source": [
        "##Загрузка и изучение данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bgXPJH_-5Y8"
      },
      "outputs": [],
      "source": [
        "!wget -q https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/BTC-USD.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ksg47e03-5Y8"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"BTC-USD.csv\", index_col=\"Date\", parse_dates=True)\n",
        "dataset.drop(columns=[\"Adj Close\"], inplace=True)\n",
        "dataset.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hPelidp-5Y9"
      },
      "source": [
        "У нас есть ежедневные исторические данные о ценах:\n",
        "\n",
        "* `Open` — цена открытия,\n",
        "* `High` — верхняя цена,\n",
        "* `Low` — нижняя цена,\n",
        "* `Volume` — объём торгов.\n",
        "\n",
        "Наша цель — взять некоторую последовательность из четырех признаков (скажем, за 100 предыдущих дней) и спрогнозировать целевую переменную `Close` на следующие 50 дней."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFUo4in3-5Y9"
      },
      "source": [
        "Визуализируем целевую переменную."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kBlIAEo-5Y_"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (12, 3)\n",
        "\n",
        "plt.plot(dataset[\"Close\"])\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Price (USD)\")\n",
        "plt.title(\"Bitcoin price over time\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-RVYc5d-5Y_"
      },
      "source": [
        "Посмотрим, какие тут представлены признаки, на основе которых будем предсказывать цену."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tr88FPg-5Y_"
      },
      "outputs": [],
      "source": [
        "dataset.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yeSrM93-5ZA"
      },
      "source": [
        "Видим единственное значение-всплеск в ряде `Volume`. Из-за такой разницы в масштабе даже толком не видно ничего. Заменим это значение на соседнее."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZgsfqOt-5ZA"
      },
      "outputs": [],
      "source": [
        "idx_max = dataset[\"Volume\"].idxmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rwoCXcf-5ZA"
      },
      "outputs": [],
      "source": [
        "prev_value = dataset[dataset.index < idx_max].tail(1)[\"Volume\"][0]\n",
        "dataset = dataset.replace(dataset[\"Volume\"][idx_max], prev_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqHUQj8o-5ZA"
      },
      "source": [
        "Визуализируем оставшиеся признаки. Здесь отчётливо видно, что поведение ряда после 2021 года качественно поменялось."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxYq0nwH-5ZB"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05OP3Hik-5ZB"
      },
      "source": [
        "Сейчас мы исследуем левую часть ряда, до 2021. И попробуем предсказать поведение цены на несколько месяцев вперёд несколькими способами, начиная с быстрых прикидок и заканчивая рекуррентной моделью."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dn0OYIyQ-5ZB"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "from pmdarima.arima import auto_arima\n",
        "\n",
        "train_start = datetime.datetime(2018, 1, 1)\n",
        "train_end = datetime.datetime(2019, 12, 31)\n",
        "\n",
        "val_start = datetime.datetime(2020, 1, 1)\n",
        "val_end = datetime.datetime(2020, 6, 1)\n",
        "\n",
        "test_start = datetime.datetime(2020, 6, 2)\n",
        "test_end = datetime.datetime(2020, 12, 31)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdSq7m-C-5ZC"
      },
      "outputs": [],
      "source": [
        "train_data = dataset.query(\"(`Date` >= @train_start) & (`Date` <= @train_end)\")\n",
        "val_data = dataset.query(\"(`Date` >= @val_start) & (`Date` <= @val_end)\")\n",
        "test_data = dataset.query(\"(`Date` >= @test_start) & (`Date` <= @test_end)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEn4wvuj-5ZC"
      },
      "source": [
        "##SARIMA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPBd8yaZ-5ZC"
      },
      "source": [
        "Начнём с того, что попробуем по целевому показателю предсказать самого себя, то есть, как и раньше, работаем с одномерным временным рядом."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prsjfrO8-5ZD"
      },
      "outputs": [],
      "source": [
        "train_data = train_data[\"Close\"]\n",
        "val_data = val_data[\"Close\"]\n",
        "test_data = test_data[\"Close\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7k16pk6-5ZD"
      },
      "source": [
        "Сразу ограничим количество итераций алгоритма оптимизации модели значением 20 для экономиии времени. В реальной задаче, разумеется, имеет смысл поставить число побольше.\n",
        "\n",
        "Стартовые параметры взяты по умолчанию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgP4Ge9K-5ZE"
      },
      "outputs": [],
      "source": [
        "stepwise_model = auto_arima(\n",
        "    train_data,\n",
        "    start_p=1,\n",
        "    start_q=1,\n",
        "    max_p=3,\n",
        "    max_q=3,\n",
        "    m=12,\n",
        "    start_P=0,\n",
        "    seasonal=True,\n",
        "    d=1,\n",
        "    D=1,\n",
        "    trace=True,\n",
        "    error_action=\"ignore\",\n",
        "    suppress_warnings=True,\n",
        "    stepwise=True,\n",
        "    maxiter=20,  # default 50\n",
        ")\n",
        "print(stepwise_model.aic())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muFXnCPH-5ZE"
      },
      "outputs": [],
      "source": [
        "print(stepwise_model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYC-lAZX-5ZF"
      },
      "source": [
        "Предскажите вперёд на промежутке валидационных и тестовых данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvuWkByi-5ZF"
      },
      "outputs": [],
      "source": [
        "start_data = # Your code here\n",
        "\n",
        "future_forecast = stepwise_model.predict(start=start_data, n_periods=# Your code here)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E8E-eOL-5ZG"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(train_data, label=\"Train\")\n",
        "plt.plot(val_data, label=\"Val\")\n",
        "plt.plot(test_data, label=\"Test\")\n",
        "plt.plot(future_forecast, color=\"blue\", label=\"Predicted\")\n",
        "\n",
        "plt.title(\"ARIMA with optimal parameters\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WI0FaZLg-5ZG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(val_data, future_forecast[: len(val_data)]))\n",
        "print(\"RMSE: \" + str(rmse))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ6JF8Cy-5ZG"
      },
      "source": [
        "➕ Baseline. Можно предсказывать на сколь угодно далеко в будущее.\n",
        "\n",
        "➖ Получилось не очень качественно."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TStGbvjN-5ZG"
      },
      "source": [
        "##SARIMAX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZbqv-x0-5ZH"
      },
      "source": [
        "Попробуем воспользоваться оставшимися признаками, чтобы уточнить предсказание.\n",
        "\n",
        "Теперь мы подаём не только `Y`, но и `X`, то есть решаем регрессионную задачу."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAKOHRWk-5ZH"
      },
      "outputs": [],
      "source": [
        "train_data = dataset.query(\"(`Date` >= @train_start) & (`Date` <= @train_end)\")\n",
        "val_data = dataset.query(\"(`Date` >= @val_start) & (`Date` <= @val_end)\")\n",
        "test_data = dataset.query(\"(`Date` >= @test_start) & (`Date` <= @test_end)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcs6b6kE-5ZH"
      },
      "outputs": [],
      "source": [
        "stepwise_model = auto_arima(\n",
        "    y=train_data[\"Close\"],\n",
        "    X=train_data.drop(columns=[\"Close\"]),\n",
        "    start_p=1,\n",
        "    start_q=1,\n",
        "    max_p=3,\n",
        "    max_q=3,\n",
        "    m=12,\n",
        "    start_P=0,\n",
        "    seasonal=True,\n",
        "    d=1,\n",
        "    D=1,\n",
        "    trace=True,\n",
        "    error_action=\"ignore\",\n",
        "    suppress_warnings=True,\n",
        "    stepwise=True,\n",
        "    maxiter=20,  # default 50\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHpfrUUB-5ZH"
      },
      "source": [
        "Для предсказания в функцию `predict` теперь нужно подать признаки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "beJH7emJ-5ZI"
      },
      "outputs": [],
      "source": [
        "start_data = # Your code here\n",
        "future_forecast_val = stepwise_model.predict(X = # Your code here, start=start_data, n_periods=# Your code here)\n",
        "\n",
        "start_data = # Your code here\n",
        "future_forecast_test = stepwise_model.predict(X = # Your code here, start=start_data, n_periods=# Your code here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9l0ROKn-5ZI"
      },
      "source": [
        "Здесь есть особенность в том, что начальные индексы по времени `future_forecast_val` и `future_forecast_test` совпадут. Поэтому для визуализации мы сдвинем на размер валидации, т.е. на 153 дня."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VS45xutO-5ZI"
      },
      "outputs": [],
      "source": [
        "future_forecast_test.index = future_forecast_test.index.shift(153, freq=\"D\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPeJFDoY-5ZI"
      },
      "source": [
        "Проверим, что даты сдвинулись:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evLdJY17-5ZJ"
      },
      "outputs": [],
      "source": [
        "future_forecast_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--MMA85A-5ZJ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(train_data[\"Close\"], label=\"Train\")\n",
        "plt.plot(val_data[\"Close\"], label=\"Val\")\n",
        "plt.plot(test_data[\"Close\"], label=\"Test\")\n",
        "plt.plot(future_forecast_val, label=\"Predicted Val\")\n",
        "plt.plot(future_forecast_test, label=\"Predicted Test\")\n",
        "\n",
        "\n",
        "plt.title(\"ARIMA with optimal parameters\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2uccX6b-5ZK"
      },
      "outputs": [],
      "source": [
        "rmse = np.sqrt(mean_squared_error(val_data[\"Close\"], future_forecast_val))\n",
        "print(\"RMSE: \" + str(rmse))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrbIYwV7-5ZL"
      },
      "source": [
        "Ошибка уменьшилась примерно вдвое."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPUk4jnO-5ZL"
      },
      "source": [
        "Фишка SARIMAX в том, что мы можем придумывать дополнительные признаки и подавать их в ту же модель, просто добавляя столбцы в таблице в `pandas`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUlsEOE4-5ZL"
      },
      "source": [
        "Придумайте какой-нибудь признак, который хотя бы немного уменьшит ошибку на валидации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qOLlYff-5ZM"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO9f_Q06-5ZN"
      },
      "source": [
        "Обучите модель на расширенном датасете."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyax1wRH-5ZO"
      },
      "outputs": [],
      "source": [
        "stepwise_model = auto_arima(\n",
        "    y=train_data[\"Close\"],\n",
        "    X=train_data.drop(columns=[\"Close\"]),\n",
        "    start_p=1,\n",
        "    start_q=1,\n",
        "    max_p=3,\n",
        "    max_q=3,\n",
        "    m=12,\n",
        "    start_P=0,\n",
        "    seasonal=True,\n",
        "    d=1,\n",
        "    D=1,\n",
        "    trace=True,\n",
        "    error_action=\"ignore\",\n",
        "    suppress_warnings=True,\n",
        "    stepwise=True,\n",
        "    maxiter=20,  # default 50\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBcTGld8-5ZO"
      },
      "source": [
        "Предскажите вперёд. Не забудьте подправить даты на тесте."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pvpwa4Ue-5ZO"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuaQ8qjC-5ZP"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(train_data[\"Close\"], label=\"Train\")\n",
        "plt.plot(val_data[\"Close\"], label=\"Val\")\n",
        "plt.plot(test_data[\"Close\"], label=\"Test\")\n",
        "plt.plot(future_forecast_val, label=\"Predicted Val\")\n",
        "plt.plot(future_forecast_test, label=\"Predicted Test\")\n",
        "\n",
        "\n",
        "plt.title(\"ARIMA with optimal parameters\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZcOwPTA-5ZP"
      },
      "outputs": [],
      "source": [
        "rmse = np.sqrt(mean_squared_error(val_data[\"Close\"], future_forecast_val))\n",
        "print(\"RMSE: \" + str(rmse))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keJwF9xL-5ZP"
      },
      "source": [
        "Мы смогли улучшить качество путём конструирования признаков."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJbOn1Ga-5ZQ"
      },
      "source": [
        "С помощью относительно простой линейной модели мы можем получить приемлемое качество. Если уделить ещё больше времени конструированию признаков или дать больше итераций подбора модели, качество будет ещё выше. Возможно, конкретно ваша задача на этом этапе уже может считаться решённой. Не беритесь сразу за обучение нелинейных моделей."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "➕ Получилось довольно качественно.\n",
        "\n",
        "➖ Не можем предсказывать будущие значения. Решение регрессионной задачи есть только там, где уже есть признаки."
      ],
      "metadata": {
        "id": "fq-4f83ucFY6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWkREBfe-5ZR"
      },
      "source": [
        "##Нелинейная модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIy1XkmO-5ZR"
      },
      "source": [
        "❗ Экспериментируя с Auto-ARIMA, вы могли к этому моменту заполнить бОльшую часть оперативной памяти. Если это так, перезагрузите среду.\n",
        "\n",
        "💥 Основная цель этой части – дать вам практику работы со сложным многомерными данными из реального мира. При неудачных параметрах качество предсказания модели может оказаться хуже, чем у SARIMAX. Если модель сможет верно оценить поведение данных в будущем, этого уже достаточно. Дальнейшее улучшение – вопрос перебора параметров и машинного времени."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzRQ6VIM-5ZR"
      },
      "source": [
        "Теперь воспользуемся нелинейной моделью. Адаптируем код из лекции для работы с многомерными данными.\n",
        "\n",
        "Загрузим заново данные и поделим на подвыборки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mre6e6fu-5ZS"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"BTC-USD.csv\", index_col=\"Date\", parse_dates=True)\n",
        "dataset.drop(columns=[\"Adj Close\"], inplace=True)\n",
        "dataset.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKNm0mt1-5ZS"
      },
      "source": [
        "### Разбиение на train-val-test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITWpUzbh-5ZS"
      },
      "source": [
        "Здесь мы дополнительно вынуждены отрезать часть начальных данных, ибо такое поведение ряда далее не наблюдается."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xy0kHj0-5ZS"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "# train_start = datetime.datetime(2018, 1, 1)\n",
        "train_start = datetime.datetime(2019, 1, 1)\n",
        "train_end = datetime.datetime(2019, 12, 31)\n",
        "\n",
        "val_start = datetime.datetime(2020, 1, 1)\n",
        "val_end = datetime.datetime(2020, 6, 1)\n",
        "\n",
        "test_start = datetime.datetime(2020, 6, 2)\n",
        "test_end = datetime.datetime(2020, 12, 31)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dGoi-f9-5ZT"
      },
      "outputs": [],
      "source": [
        "train_data = dataset.query(\"(`Date` >= @train_start) & (`Date` <= @train_end)\")\n",
        "val_data = dataset.query(\"(`Date` >= @val_start) & (`Date` <= @val_end)\")\n",
        "test_data = dataset.query(\"(`Date` >= @test_start) & (`Date` <= @test_end)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKFX7yQR-5ZT"
      },
      "outputs": [],
      "source": [
        "print(train_data.shape)\n",
        "print(val_data.shape)\n",
        "print(test_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k5L0hRQ-5ZU"
      },
      "source": [
        "Для каждой части данных (train, val, и test) запишем в словарь временные метки и исходные данные."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2bak9IS-5ZU"
      },
      "outputs": [],
      "source": [
        "split = {\"train\": {}, \"val\": {}, \"test\": {}}\n",
        "\n",
        "for part, data_part in zip(split, [train_data, val_data, test_data]):\n",
        "    split[part][\"timestamps\"] = data_part.index\n",
        "    split[part][\"data\"] = data_part.values  # Close is #3 column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgdsKd-p-5ZU"
      },
      "source": [
        "Проверим размеры:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TpjTAu_-5ZV"
      },
      "outputs": [],
      "source": [
        "print(split[\"test\"][\"data\"].shape)\n",
        "print(split[\"val\"][\"data\"].shape)\n",
        "print(split[\"train\"][\"data\"].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG_ZNZ2e-5ZV"
      },
      "source": [
        "Отобразим разделенные данные:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cns2-wHV-5ZV"
      },
      "outputs": [],
      "source": [
        "def initial_data_display(split):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    for part in split:\n",
        "        plt.plot(split[part][\"timestamps\"], split[part][\"data\"][:, 3], label=part)\n",
        "    plt.title(\"Initial data\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "initial_data_display(split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Fu3oTbP-5ZV"
      },
      "source": [
        "###Устранение тренда"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRvlIxG7-5ZW"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "class TimeSeriesTransform:\n",
        "    def __init__(self, apply_log=False):\n",
        "        self.slope = None\n",
        "        self.apply_log = apply_log\n",
        "\n",
        "    def fit(self, train_data: np.ndarray):\n",
        "        data = train_data\n",
        "        if self.apply_log:\n",
        "            data = np.log(data + 1)  # to avoid log(0)\n",
        "\n",
        "        x = np.arange(len(data))\n",
        "        x_centered = x - x.mean()\n",
        "\n",
        "        data_centered = data - data.mean(axis=0)\n",
        "        # print (data_centered.shape)\n",
        "\n",
        "        slopes = []\n",
        "        for i in range(data_centered.shape[1]):\n",
        "            reg = LinearRegression(fit_intercept=False).fit(\n",
        "                x_centered.reshape(-1, 1), data_centered[:, i].reshape(-1, 1)\n",
        "            )\n",
        "            slopes.append(reg.coef_[0])\n",
        "\n",
        "        self.slope = slopes\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, data: np.ndarray, window_size: int):\n",
        "        if self.slope is None:\n",
        "            raise ValueError(\"call fit before transform\")\n",
        "\n",
        "        if self.apply_log:\n",
        "            data = np.log(data + 1)  # to avoid log(0)\n",
        "\n",
        "        x = np.arange(len(data))\n",
        "        x_centered = x - x.mean()\n",
        "        trend = self.slope * x_centered\n",
        "\n",
        "        anchor_value = data[window_size]\n",
        "        data_centered = data - data.mean(axis=0)\n",
        "        data_detrended = data_centered - trend.T\n",
        "        return anchor_value, data_detrended\n",
        "\n",
        "    def inverse_transform(self, anchor_value: float, data_detrended: np.ndarray):\n",
        "        if self.slope is None:\n",
        "            raise ValueError(\"call fit before inverse_transform\")\n",
        "\n",
        "        x = np.arange(len(data_detrended))\n",
        "        x_centered = x - x.mean()\n",
        "        trend = self.slope * x_centered\n",
        "\n",
        "        trend = trend.T\n",
        "        data = np.squeeze(data_detrended) + trend\n",
        "\n",
        "        data = (\n",
        "            data\n",
        "            - np.array([data[0, :]] * len(data))\n",
        "            + np.array([anchor_value] * len(data))\n",
        "        )\n",
        "        if self.apply_log:\n",
        "            data = np.exp(data) - 1\n",
        "        return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gVig1ZK-5ZX"
      },
      "source": [
        "Сохраним опорные точки (`anchor_value`) для каждой из подвыборок, чтобы знать, в каком масштабе нужно добавлять тренд в дальнейшем при вызове `inverse_transform`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAkyK8LR-5ZX"
      },
      "outputs": [],
      "source": [
        "window_size = # Your code here\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbLdIKJj-5ZY"
      },
      "source": [
        "Отобразим преобразованные данные, на которых теперь можно обучать, валидировать и тестировать нейронную сеть:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GEYi9yy-5ZY"
      },
      "outputs": [],
      "source": [
        "def transformed_data_display(split):\n",
        "    for i in range(5):\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        for part in split:\n",
        "            plt.plot(\n",
        "                split[part][\"timestamps\"],\n",
        "                split[part][\"data_transformed\"][:, i],\n",
        "                label=part,\n",
        "            )\n",
        "        plt.title(\"Transformed data\")\n",
        "        plt.legend()\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "transformed_data_display(split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwiu1tYi-5ZY"
      },
      "source": [
        "###Создание датасета"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hrf0cA3K-5ZZ"
      },
      "source": [
        "Создадим датасет: будем обучать нейронную сеть по последовательности из `seq_len` элементов предсказывать `seq_len + 1`-й."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kk1PE5i9-5ZZ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qNOX10K-5ZZ"
      },
      "source": [
        "Для каждой части данных создадим `DataSet` и `DataLoader`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "By8Wyatj-5Za"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U5jW33b-5Za"
      },
      "source": [
        "Проверим размеры и количество батчей во всех подвыборках:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBeDTwsv-5Zb"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdabaDD5-5Zb"
      },
      "source": [
        "###Создание модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPKjcVSt-5Zb"
      },
      "source": [
        "Рекомендуем использовать модель LSTM.\n",
        "\n",
        "Здесь вы сможете попробовать сделать вашу модель более мощной, так как данные усложнились. Учтите, что теперь у вас многомерный ряд, а значит размеры входа и выхода изменились."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6YrbLxO-5Zc"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7giBQtE-5Zc"
      },
      "source": [
        "Проверим, что входные данные одного батча проходят через модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhHOiTFF-5Zc"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzvDvu4w-5Zd"
      },
      "source": [
        "###Получение предсказаний"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQjbACmW-5Zd"
      },
      "outputs": [],
      "source": [
        "def forced_predict(model, split, part):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    model.eval()\n",
        "    dataset = split[part][\"dataset\"]\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataset:\n",
        "            out = model(x)\n",
        "            y_true.append(y.tolist())\n",
        "            y_pred.append(out.tolist())\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    transform = split[\"train\"][\"transform\"]\n",
        "    y_true = transform.inverse_transform(split[part][\"anchor_value\"], y_true)\n",
        "    y_pred = transform.inverse_transform(split[part][\"anchor_value\"], y_pred)\n",
        "\n",
        "    return y_true, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMjhVxWW-5Zd"
      },
      "outputs": [],
      "source": [
        "def rolling_predict(model, split, part, forecast_horizon):\n",
        "    y_pred = []\n",
        "    model.eval()\n",
        "    dataset = split[part][\"dataset\"]\n",
        "    x, _ = dataset[0]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(forecast_horizon):\n",
        "            out = model(x).view(-1, 1)  # for concatenation shape compatibility\n",
        "            y_pred.append(out.tolist())\n",
        "            # drop first element and add new prediction\n",
        "            x = torch.cat([x[1:, :], out.T], dim=0)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    transform = split[\"train\"][\"transform\"]\n",
        "    y_pred = transform.inverse_transform(split[part][\"anchor_value\"], y_pred)\n",
        "\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-53u-Sc-5Ze"
      },
      "source": [
        "Для проверки получим предсказания необученной модели: в режиме \"forced prediction\" для обучающих и валидационных данных и в режиме \"rolling prediction\" для тестовых."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGoX7Zc7-5Zf"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDgGkmFN-5Zf"
      },
      "source": [
        "Отобразим актуальные и предсказанные данные."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPzPLuxw-5Zf"
      },
      "outputs": [],
      "source": [
        "from datetime import timedelta\n",
        "\n",
        "\n",
        "def display_pred_with_rolling_test(\n",
        "    split, show_only_target=False, post_test=False, dataset=dataset\n",
        "):\n",
        "    for i in range(5):\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        if show_only_target:\n",
        "            i = 3  # show Close column\n",
        "        for part in split:\n",
        "            timestamps = split[part][\"timestamps\"][window_size:]\n",
        "            real_data = split[part][\"y_true\"][:, i]\n",
        "            pred_data = split[part][\"y_pred\"][:, i]\n",
        "\n",
        "            if part in (\"train\", \"val\"):\n",
        "\n",
        "                plt.plot(timestamps, real_data, label=f\"{part}/real\")\n",
        "                plt.plot(timestamps, pred_data, label=f\"{part}/predicted\")\n",
        "\n",
        "            if part == \"test\":\n",
        "                plt.plot(timestamps, real_data, label=f\"{part}/real\")\n",
        "                # difference from the lecture code\n",
        "                future_timestamps = pd.date_range(\n",
        "                    timestamps[0],\n",
        "                    timestamps[0] + timedelta(days=(len(pred_data)) - 1),\n",
        "                    freq=\"D\",\n",
        "                )\n",
        "                plt.plot(future_timestamps, pred_data, label=f\"{part}/predicted\")\n",
        "\n",
        "        # difference from the lecture code\n",
        "        if post_test:\n",
        "            future_timestamps = pd.date_range(\n",
        "                timestamps[-1],\n",
        "                timestamps[-1] + timedelta(days=(len(pred_data))),\n",
        "                freq=\"D\",\n",
        "            )\n",
        "            furure_data = dataset[\"Close\"][\n",
        "                timestamps[-1] : timestamps[-1] + timedelta(days=(len(pred_data)))\n",
        "            ]\n",
        "            plt.plot(future_timestamps, furure_data, label=\"real future data\")\n",
        "\n",
        "        plt.title(\"Real vs Predicted\")\n",
        "        plt.legend()\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "        if show_only_target:\n",
        "            return  # show Close column\n",
        "\n",
        "\n",
        "display_pred_with_rolling_test(split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sn_1y-Q4-5Zg"
      },
      "source": [
        "Оценим ошибку RMSE для предсказаний необученной модели (только для целевой переменной)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFhQGw0V-5Zg"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4IN4_Ms-5Zg"
      },
      "source": [
        "###Обучение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WonrAuTT-5Zh"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "from torchmetrics import MetricCollection\n",
        "from torchmetrics.regression import MeanSquaredError\n",
        "\n",
        "class TimeSeriesPipeline(L.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        exp_name=\"baseline\",\n",
        "        criterion=nn.MSELoss(),\n",
        "        optimizer_class=,# Your code here\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer_class = optimizer_class\n",
        "        metrics = MetricCollection([MeanSquaredError()])\n",
        "        self.train_metrics = metrics.clone(postfix=\"/train\")\n",
        "        self.valid_metrics = metrics.clone(postfix=\"/val\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = self.optimizer_class(\n",
        "            self.model.parameters()\n",
        "        )\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        out = self.model(x)\n",
        "        loss = self.criterion(out, y)\n",
        "        self.log(\"Loss/train\", loss, prog_bar=True)\n",
        "        self.train_metrics.update(out, y)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y = torch.squeeze(y)\n",
        "        out = self.model(x)\n",
        "        loss = self.criterion(out, y)\n",
        "        self.log(\"Loss/val\", loss, prog_bar=True)\n",
        "        self.valid_metrics.update(out, y)\n",
        "\n",
        "    def on_training_epoch_end(self):\n",
        "        train_metrics = self.train_metrics.compute()\n",
        "        self.log_dict(train_metrics)\n",
        "        self.train_metrics.reset()\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        valid_metrics = self.valid_metrics.compute()\n",
        "        self.log_dict(valid_metrics)\n",
        "        self.valid_metrics.reset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_wD-F30-5Zh"
      },
      "source": [
        "Создадим пайплайн и запустим обучение с сохранением лучшей модели по минимальному MSE на валидационной выборке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7gtidOn-5Zh"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9cS6TeK-5Zi"
      },
      "source": [
        "#### Восстановление модели из контрольной точки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nn5vIbaM-5Zi"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUQIUksa-5Zi"
      },
      "source": [
        "## Предсказания обученной модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sHNVCcs-5Zj"
      },
      "source": [
        "Получим и отобразим предсказания обученной модели: в режиме \"forced prediction\" для обучающих и валидационных данных и в режиме \"rolling prediction\" для тестовых."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTjQIbOg-5Zj"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "\n",
        "display_pred_with_rolling_test(split, show_only_target=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1Nspj5D-5Zj"
      },
      "source": [
        "Посчитайте RMSE для целевой переменной."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7pnXRLi-5Zk"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQWMB1Ap-5Zk"
      },
      "source": [
        "На валидации мы добились меньшей ошибки, чем была с SARIMAX. Однако в режиме \"rolling prediction\" картина не такая хорошая. Однако то, что верно предсказано резкое повышение ряда, является хорошим результатом."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUfGThSW-5Zl"
      },
      "source": [
        "Также мы можем получить предсказания в режиме \"rolling prediction\" и для обучающих и валидационных данных. Для примера также получим предсказания на тестовых данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksOAS6zX-5Zl"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "\n",
        "display_pred_with_rolling_test(\n",
        "    split, show_only_target=True, post_test=True, dataset=dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_JPoSee-5Zm"
      },
      "source": [
        "Если вы добились верной оценки поведения модели в будущем, это можно считать достаточным результатом.\n",
        "\n",
        "Для того, чтобы улучшить качество предсказания и приблизиться к качеству, как в первом задании, можно попробовать сделать более сложную модель (размер вектора hidden в рекуррентном слое, количество таких слоёв, дополнительные линейные слои, тип оптимизатора).\n",
        "\n",
        "Главная сложность: сами данные, которые меняют своё поведение во времени. Причём иногда очень сильно и внезапно."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "➕ Можем предсказывать сколь угодно далеко. Качество лучше, чем у SARIMA.\n",
        "\n",
        "➖ Долго, муторно, можем вовсе не подобрать подходящую модель."
      ],
      "metadata": {
        "id": "kltJCiaHcb-6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Выводы:**\n",
        "\n",
        "1. SARIMA используется в качестве baseline.\n",
        "2. SARIMAX предсказывает неплохо, но только там, где есть признаки. Для предсказания дальше нужно снова возвращаться к SARIMA (или реализовывать цикл, SARIMA будет каждый раз переобучаться на новые, предсказанные данные).\n",
        "3. Нейросеть работает на любом промежутке времени, но сложность разработки может быть крайне высокой."
      ],
      "metadata": {
        "id": "tcK73Zu7ccRK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU6x985e-5Zm"
      },
      "source": [
        "## Формат результата"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXihiusJ-5Zm"
      },
      "source": [
        "Графики предсказаний, RMSE для оценки качества предсказания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTYP9L17-5Zn"
      },
      "source": [
        "# Задание 4*. Посимвольная генерация текста"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLAxcJJe-5Zn"
      },
      "source": [
        "Возьмите произведение Гете \"Фауст\" и обучите на нем LSTM-модель для посимвольной генерации текста. Вместо one-hot кодирования используйте `nn.Embedding` [🛠️[doc]](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html). При обучении игнорируйте знаки препинания и номера страниц.\n",
        "\n",
        "[[doc] 🛠️ Word Embeddings Tutorial](https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY81ig-Y-5Zo"
      },
      "source": [
        "Импорт необходимых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxBv-0oo-5Zo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiXeAAxA-5Zo"
      },
      "source": [
        "Загрузка данных:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3cumL4g-5Zo"
      },
      "outputs": [],
      "source": [
        "!wget -q https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/Faust.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdCpay1T-5Zp"
      },
      "outputs": [],
      "source": [
        "with open(\"Faust.txt\") as text_file:\n",
        "    faust_text = \"\".join(text_file.readlines())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtAhGcYD-5Zp"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5u0JR7d-5Zp"
      },
      "source": [
        "## Формат результата"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj9-NeJb-5Zp"
      },
      "source": [
        "Сгенерерированный текст\n",
        "\n",
        "Пример текста:\n",
        "\n",
        "\"все все от бесстыдные старой\n",
        "\n",
        "все в нем получше все стремленья\n",
        "\n",
        "поддержки с собой в сердце воздух своей\n",
        "\n",
        "и в вечной страсти восстанет свой предлог\n",
        "\n",
        "привет вам слуга в сладком страшней стране\n",
        "\n",
        "и в мире все вражда станет станет\n",
        "\n",
        "в поле на пользу своим воспоминанья\"\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}